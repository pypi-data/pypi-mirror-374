{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellRake Example Workflow\n",
    "\n",
    "When using **CellRake** to identify the cells on a fluorescence image, it is essential to train a model to determine which segmentations correspond to cells and which do not. To achieve this objective, we will train a machine-learning classifier using a set of input images.\n",
    "\n",
    "We will start by importing the necessary packages for our analysis, including the functions from `cellrake`. Ensure that:\n",
    "\n",
    "- You have correctly installed `cellrake` in your Conda environment following the instructions in [README.md](../README.md).\n",
    "- You are running this notebook with the `cellrake` environment (top right corner of the notebook if you are using VSCode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellrake.main import CellRake\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize project\n",
    "\n",
    "We need to start by initializing the class with two directories:\n",
    "\n",
    "- Image folder (`image_folder`): where your TIFF images are located.\n",
    "- Project directory (`project_dir`): where results will be stored.\n",
    "\n",
    "You can also pass a third optional argument (`segmented_data`), which corresponds to a Python dictionary of already segmented images. This will skip the segmentation step on your `image_folder` and will use the `segmented_data` for the training and analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_project = CellRake(\n",
    "    image_folder=Path(\"./sample_images\"),\n",
    "    project_dir=Path(\"./tutorial_project\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a model\n",
    "\n",
    "When running the `.train(threshold_rel, model_type, samples)` method, CellRake will:\n",
    "\n",
    "- Segment images into potential cells (ROIs).\n",
    "- Extract features (intensity, texture, shape).\n",
    "- Ask you to manually label a few ROIs.\n",
    "- Use label spreading to assign pseudo-labels to similar ROIs.\n",
    "- Train a classifier: Random Forest, Support Vector Machine, Extra-Trees, or Logistic Regression.\n",
    "- Report training & test metrics.\n",
    "\n",
    "Key arguments:\n",
    "- `threshold_rel`: controls sensitivity of segmentation (0–1).\n",
    "- `model_type`: choose classifier (\"rf\" = Random Forest by default).\n",
    "- `samples`: number of ROIs you will manually label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_project.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the model is stored in `my_tdt_project.model` and metrics in `my_tdt_project.metrics`. We will also have the plots and data files downloaded in our `project_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_project.model # Access your trained model\n",
    "tutorial_project.metrics # Access your training performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving the model and segmentation\n",
    "\n",
    "After training, we can save both the `model`and the `segmented_data` in your `project_dir`. This way, we will be able to load them later or in another session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_project.save_model('sample_rf_model') # We can save it using a customed name\n",
    "tutorial_project.save_segmentation('sample_segmented') # We can save it using a customed name\n",
    "\n",
    "tutorial_project.load_model('sample_rf_model')\n",
    "tutorial_project.load_segmentation('sample_segmented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run analysis\n",
    "\n",
    "Once the model is trained (or loaded), we can analyze our images. We can use a new folder of images (`image_folder`) or, if defined, a `segmented_data` dictionary. When running the `.analyze(threshold_rel, cmap)` method, CellRake will:\n",
    "\n",
    "- Segment the images (or reuse a segmented dictionary if already defined).\n",
    "- The trained model classifies the ROIs.\n",
    "- Results are exported to your project_dir:\n",
    "    - Images of the identified cells.\n",
    "    - `cell_counts.csv`:  number of positive cells per image.\n",
    "    - `cell_features.csv`: extracted features (intensity, area, etc.) per ROI.\n",
    "\n",
    "Key arguments:\n",
    "- `threshold_rel`: segmentation sensitivity in case segmentation takes place.\n",
    "- `cmap` → colormap for visualization (\"Reds\", \"Blues\", etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_project.analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, results are also available as attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_project.counts # Access the pd.DataFrame with the count results\n",
    "tutorial_project.features # Access the pd.DataFrame with the feature extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellrake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
