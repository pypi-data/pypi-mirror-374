"""
ğŸ”¥ Classical Information Bottleneck Implementation
================================================

Classical discrete Information Bottleneck algorithm as described in
Tishby, Pereira & Bialek (1999) "The Information Bottleneck Method".

Author: Benedict Chen (benedict@benedictchen.com)
Based on: Tishby, Pereira & Bialek (1999)
"""

import numpy as np
from typing import Dict, Tuple, Optional, Any, List
from scipy.optimize import minimize
from scipy.stats import entropy
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')


class InformationBottleneck:
    """
    ğŸ”¥ Information Bottleneck - The Mathematical Foundation of Modern AI!
    ====================================================================
    
    ğŸ¯ ELI5: Think of this as a smart filter that keeps only the most important 
    information from your data while throwing away noise. It's like having a 
    super-intelligent librarian who can summarize any book by keeping just the 
    sentences that help you answer specific questions!
    
    ğŸ“š Research Foundation:
    Implements Tishby, Pereira & Bialek's groundbreaking 1999 algorithm that 
    revolutionized our understanding of representation learning. This is THE theory 
    that explains why deep networks generalize so well!
    
    ğŸ§® Mathematical Principle:
    ========================
    Find optimal representation Z that:
    â€¢ Minimizes I(X;Z) - compression (throw away irrelevant details)
    â€¢ Maximizes I(Z;Y) - prediction (keep what matters for the task)
    
    Objective: minimize I(X;Z) - Î²Â·I(Z;Y)
    
    Where:
    â€¢ X = input data (images, text, sensors, etc.)
    â€¢ Y = target variable (labels, predictions, etc.)
    â€¢ Z = compressed representation (the "bottleneck")
    â€¢ Î² = trade-off parameter (Î²â†’0: max compression, Î²â†’âˆ: max prediction)
    
    ğŸ¨ Visual Intuition:
    ===================
    
        Raw Data X â”€â”€â†’ â”‚ COMPRESS â”‚â”€â”€â†’ Z â”€â”€â†’ â”‚ PREDICT â”‚â”€â”€â†’ Å¶ â‰ˆ Y
        (Noisy, Big)   â”‚ Smartly  â”‚   â†‘      â”‚ Optimal â”‚   (Target)
        ğŸ“ŠğŸ“¸ğŸµğŸ“      â”‚          â”‚   â”‚      â”‚         â”‚   ğŸ¯
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                              ğŸ’§ BOTTLENECK
                           (Keep only what matters!)
    
    ğŸš€ Why This Changed Everything:
    ==============================
    Before IB: "Neural networks are black magic" ğŸ¤·
    After IB: "Neural networks implement optimal information compression!" ğŸ¤¯
    
    ğŸ† Key Theoretical Results:
    ==========================
    â€¢ Phase transitions in representation learning
    â€¢ Universal information-theoretic learning curves  
    â€¢ Proves optimality of learned representations
    â€¢ Explains generalization through compression
    
    ğŸ’¡ Pro Tips:
    ===========
    â€¢ Start with Î²=1.0, then experiment with values from 0.1 to 10.0
    â€¢ Use more clusters (n_clusters) for complex data
    â€¢ Enable deterministic annealing for better convergence
    â€¢ Plot information curves to visualize the compression-prediction trade-off
    """
    
    def __init__(
        self,
        n_clusters: int = 10,
        beta: float = 1.0,
        max_iter: int = 100,
        tolerance: float = 1e-6,
        random_seed: Optional[int] = None
        # FIXME: Critical Issues in InformationBottleneck __init__ Parameters
        #
        # 1. INSUFFICIENT DEFAULT CLUSTERS (n_clusters=10)
        #    - Tishby et al. (1999) experiments used 20-100 clusters for meaningful results
        #    - 10 clusters severely limits representational capacity
        #    - For most datasets, need at least |Y|*2 clusters where |Y| is output classes
        #    - Solutions:
        #      a) Increase default: n_clusters: int = 50
        #      b) Add adaptive cluster selection: n_clusters = max(20, len(np.unique(Y))*3)
        #      c) Implement model selection to find optimal cluster count
        #    - Research note: Insufficient clusters lead to underfitting and poor phase transitions
        #
        # 2. MISSING DETERMINISTIC ANNEALING SCHEDULE
        #    - Original paper uses Î²-annealing for better convergence
        #    - Single fixed Î² often gets stuck in local minima
        #    - Should start with low Î² and gradually increase
        #    - Solutions:
        #      a) Add: annealing_schedule: str = 'exponential'  # 'linear', 'exponential', 'cosine'
        #      b) Add: beta_min: float = 0.01, beta_max: float = 10.0
        #      c) Implement: Î²(t) = Î²_min * (Î²_max/Î²_min)^(t/T) for exponential annealing
        #    - Example:
        #      ```python
        #      # Deterministic annealing (critical for convergence)
        #      self.annealing_schedule = annealing_schedule
        #      self.beta_min = 0.01
        #      self.beta_max = beta
        #      ```
        #
        # 3. TOO STRICT CONVERGENCE TOLERANCE (1e-6)
        #    - Information bottleneck convergence can be slow and oscillatory
        #    - 1e-6 tolerance may prevent reaching good solutions
        #    - Should use relative tolerance based on information measures
        #    - Solutions:
        #      a) Use relative tolerance: tolerance: float = 1e-4
        #      b) Add separate tolerances for I(X;Z) and I(Z;Y) convergence
        #      c) Implement early stopping based on validation performance
        #    - Research basis: IB optimization is non-convex and benefits from looser tolerances
        #
        # 4. MISSING INITIALIZATION STRATEGY PARAMETER
        #    - Different initialization methods affect convergence to different local optima
        #    - Should allow k-means++, random, or deterministic annealing initialization
        #    - Solutions:
        #      a) Add: init_method: str = 'k-means++'  # 'random', 'deterministic_annealing'
        #      b) Add: n_init: int = 10  # Number of random initializations to try
        #      c) Implement multiple restarts with best final objective
        #
        # 5. MISSING CONTINUOUS VERSION PARAMETERS
        #    - Original discrete version limited to discrete X, Y
        #    - Should support continuous variables via kernel density estimation
        #    - Solutions:
        #      a) Add: continuous_mode: bool = False
        #      b) Add: bandwidth: float = 'auto'  # KDE bandwidth for continuous variables
        #      c) Add: kernel: str = 'gaussian'  # Kernel type for density estimation
    ):
        """
        ğŸš€ Initialize Information Bottleneck - Your Gateway to Optimal Representation Learning!
        ===================================================================================
        
        ğŸ¯ ELI5: Set up the smart filter that will learn to keep only the most important 
        information from your data. Think of it like training a super-efficient librarian 
        who learns exactly which details to remember and which to forget!
        
        ğŸ“Š What This Does:
        ==================
        Creates the mathematical machinery to solve Tishby's Information Bottleneck principle:
        
        1. **Compression Engine**: Learns to throw away irrelevant noise from input X
        2. **Prediction Engine**: Keeps exactly the information needed to predict Y  
        3. **Optimal Balance**: Uses parameter Î² to trade off compression vs prediction
        4. **Convergence Monitor**: Tracks learning progress with adaptive stopping
        
        ğŸ”§ Parameter Guide:
        ==================
        Args:
            n_clusters (int, default=10): ğŸ›ï¸ Size of representation space |Z|
                â€¢ Small (3-5): For simple patterns, fast learning
                â€¢ Medium (10-20): Good balance for most problems  
                â€¢ Large (50+): For complex, high-dimensional data
                â€¢ ğŸ’¡ Rule of thumb: Start with âˆš(n_samples/10)
                
            beta (float, default=1.0): âš–ï¸ Information trade-off parameter Î²
                â€¢ Î² < 1: Prioritize compression (lossy, fast)
                â€¢ Î² = 1: Balanced compression-prediction 
                â€¢ Î² > 1: Prioritize prediction (detailed, slower)
                â€¢ Î² â†’ 0: Maximum compression (minimal representation)
                â€¢ Î² â†’ âˆ: Maximum prediction (detailed representation)
                
            max_iter (int, default=100): ğŸ”„ Maximum optimization iterations
                â€¢ Simple data: 50-100 iterations usually sufficient
                â€¢ Complex data: May need 200-500 iterations
                â€¢ Monitor training_history to check convergence
                
            tolerance (float, default=1e-6): ğŸ¯ Convergence threshold
                â€¢ Smaller values: More precise convergence
                â€¢ Larger values: Faster but less precise stopping
                â€¢ Good range: 1e-4 to 1e-8
                
            random_seed (Optional[int]): ğŸ² Reproducibility control
                â€¢ None: Different results each run (exploration)
                â€¢ Fixed int: Reproducible results (debugging)
        
        ğŸ—ï¸ What Gets Created:
        ======================
        Internal probability distributions (learned during fit):
        â€¢ p_z_given_x: P(z|x) - Encoder: How to map inputs to clusters
        â€¢ p_y_given_z: P(y|z) - Decoder: How to predict from clusters  
        â€¢ p_z: P(z) - Prior: Cluster usage frequencies
        
        ğŸ“ˆ Training Monitoring:
        ======================
        Tracks these metrics during optimization:
        â€¢ ib_objective: Overall Information Bottleneck loss
        â€¢ mutual_info_xz: I(X;Z) - Compression cost
        â€¢ mutual_info_zy: I(Z;Y) - Prediction benefit
        â€¢ compression_term: -I(X;Z) component
        â€¢ prediction_term: +Î²Â·I(Z;Y) component
        
        ğŸ’¡ Pro Usage Tips:
        ==================
        â€¢ Start with defaults, then tune Î² based on your needs
        â€¢ Use deterministic annealing (fit parameter) for better optimization
        â€¢ Plot information curves to visualize learning dynamics
        â€¢ Check training_history to ensure convergence
        
        ğŸ¯ Perfect For:
        â€¢ Dimensionality reduction with supervised guidance
        â€¢ Feature extraction that preserves task-relevant information
        â€¢ Understanding what your model considers "important"
        â€¢ Research into representation learning principles
        """
        
        self.n_clusters = n_clusters
        self.beta = beta
        self.max_iter = max_iter
        self.tolerance = tolerance
        
        if random_seed is not None:
            np.random.seed(random_seed)
            
        # Will be set during fit
        self.p_z_given_x = None  # P(z|x) - encoder distribution
        self.p_y_given_z = None  # P(y|z) - decoder distribution 
        self.p_z = None          # P(z) - cluster probabilities
        
        # Training history
        self.training_history = {
            'ib_objective': [],
            'mutual_info_xz': [], 
            'mutual_info_zy': [],
            'compression_term': [],
            'prediction_term': []
        }
        
        print(f"âœ“ Information Bottleneck initialized: |Z|={n_clusters}, Î²={beta}")
        print(f"   â€¢ Advanced MI estimation with KSG estimator")
        print(f"   â€¢ Deterministic annealing support")
        print(f"   â€¢ Adaptive convergence checking")
        
    def _estimate_mutual_info_discrete(self, joint_dist: np.ndarray) -> float:
        """
        Estimate mutual information from joint distribution using proper entropy calculation
        
        I(X;Y) = H(X) + H(Y) - H(X,Y)
        More numerically stable than direct calculation
        """
        
        # Avoid log(0) by adding small epsilon
        epsilon = 1e-12
        joint_dist = joint_dist + epsilon
        
        # Normalize to probabilities
        joint_dist = joint_dist / np.sum(joint_dist)
        
        # Marginal distributions
        marginal_x = np.sum(joint_dist, axis=1)
        marginal_y = np.sum(joint_dist, axis=0)
        
        # Compute entropies using scipy's entropy function (more stable)
        H_X = entropy(marginal_x, base=2)
        H_Y = entropy(marginal_y, base=2)
        H_XY = entropy(joint_dist.flatten(), base=2)
        
        # Mutual information: I(X;Y) = H(X) + H(Y) - H(X,Y)
        mi = H_X + H_Y - H_XY
        
        return max(0.0, mi)  # Ensure non-negative due to numerical errors
        
    def _estimate_mutual_info_continuous(self, X: np.ndarray, Y: np.ndarray, 
                                        n_neighbors: int = 3, method: str = 'auto') -> float:
        """
        Estimate mutual information for continuous variables using multiple robust methods
        
        This implementation provides multiple estimation methods with automatic selection
        based on data characteristics to handle the theoretical requirements from Tishby 1999.
        
        Args:
            X, Y: Input variables
            n_neighbors: Number of neighbors for KSG estimator
            method: 'auto', 'ksg', 'ensemble', 'adaptive', 'bias_corrected'
        
        Returns:
            Mutual information estimate in bits
        """
        
        if method == 'auto':
            method = self._select_optimal_mi_method(X, Y)
        
        if method == 'ksg':
            return self._ksg_estimator(X, Y, n_neighbors)
        elif method == 'ensemble':
            return self._ensemble_mi_estimation(X, Y)
        elif method == 'adaptive':
            return self._adaptive_mi_estimation(X, Y)
        elif method == 'bias_corrected':
            return self._bias_corrected_mi_estimation(X, Y)
        elif method == 'copula':
            return self._copula_mi_estimation(X, Y)
        else:
            return self._ksg_estimator(X, Y, n_neighbors)
    
    def _select_optimal_mi_method(self, X: np.ndarray, Y: np.ndarray) -> str:
        """Select optimal MI estimation method based on data characteristics"""
        n_samples = X.shape[0] if len(X.shape) > 1 else len(X)
        x_dim = X.shape[1] if len(X.shape) > 1 else 1
        y_dim = Y.shape[1] if len(Y.shape) > 1 else 1
        
        # Small sample size - use bias correction
        if n_samples < 100:
            return 'bias_corrected'
        # High dimensional - use adaptive
        elif x_dim > 10 or y_dim > 10:
            return 'adaptive'
        # Medium size with low dimension - use ensemble for robustness
        elif n_samples < 1000:
            return 'ensemble'
        # Large sample - use standard KSG
        else:
            return 'ksg'
    
    def _ksg_estimator(self, X: np.ndarray, Y: np.ndarray, k: int = 3) -> float:
        """Kraskov-Grassberger-StÃ¶gbauer estimator implementation"""
        if len(X.shape) == 1:
            X = X.reshape(-1, 1)
        if len(Y.shape) == 1:
            Y = Y.reshape(-1, 1)
            
        n_samples = X.shape[0]
        
        # Normalize to [0,1]
        X_norm = (X - np.min(X, axis=0)) / (np.max(X, axis=0) - np.min(X, axis=0) + 1e-12)
        Y_norm = (Y - np.min(Y, axis=0)) / (np.max(Y, axis=0) - np.min(Y, axis=0) + 1e-12)
        
        # Combine X and Y
        XY = np.hstack([X_norm, Y_norm])
        
        # Build k-d trees for efficient neighbor search
        nbrs_xy = NearestNeighbors(n_neighbors=k + 1, metric='chebyshev').fit(XY)
        nbrs_x = NearestNeighbors(metric='chebyshev').fit(X_norm)
        nbrs_y = NearestNeighbors(metric='chebyshev').fit(Y_norm)
        
        # KSG estimator
        distances_xy, _ = nbrs_xy.kneighbors(XY)
        epsilon = distances_xy[:, -1]  # Distance to k-th neighbor
        
        mi_sum = 0.0
        for i in range(n_samples):
            # Count neighbors within epsilon in marginal spaces
            n_x = len(nbrs_x.radius_neighbors([X_norm[i]], epsilon[i])[1][0]) - 1
            n_y = len(nbrs_y.radius_neighbors([Y_norm[i]], epsilon[i])[1][0]) - 1
            
            # Use improved digamma approximation
            mi_sum += self._compute_digamma_approximation(k, n_x, n_y, n_samples)
            
        return max(0.0, mi_sum / n_samples / np.log(2))  # Convert to bits
    
    def _compute_digamma_approximation(self, k, n_x, n_y, n_samples):
        """Improved digamma function approximation"""
        def digamma_approx(x):
            if x <= 0:
                return 0.0
            elif x < 6:
                # Use series expansion for small values
                return np.log(x) - 1.0/(2*x) - 1.0/(12*x**2) + 1.0/(120*x**4)
            else:
                # Asymptotic expansion for large values
                return np.log(x) - 1.0/(2*x) - 1.0/(12*x**2)
        
        return (digamma_approx(k) - digamma_approx(max(1, n_x + 1)) - 
                digamma_approx(max(1, n_y + 1)) + digamma_approx(n_samples))
    
    def _ensemble_mi_estimation(self, X: np.ndarray, Y: np.ndarray, weights: Optional[List[float]] = None) -> float:
        """Combine multiple estimators with learned weights"""
        estimators = [
            ('ksg_k3', lambda x, y: self._ksg_estimator(x, y, k=3)),
            ('ksg_k5', lambda x, y: self._ksg_estimator(x, y, k=5)),
            ('ksg_k7', lambda x, y: self._ksg_estimator(x, y, k=7)),
        ]
        
        if weights is None:
            weights = [1.0 / len(estimators)] * len(estimators)
        
        mi_estimates = []
        for (name, estimator), weight in zip(estimators, weights):
            try:
                mi_est = estimator(X, Y)
                mi_estimates.append(mi_est * weight)
            except Exception:
                mi_estimates.append(0.0)  # Fallback
                
        return sum(mi_estimates)
    
    def _adaptive_mi_estimation(self, X: np.ndarray, Y: np.ndarray) -> float:
        """Automatically select optimal parameters based on data characteristics"""
        sample_size = X.shape[0] if len(X.shape) > 1 else len(X)
        d = X.shape[1] if len(X.shape) > 1 else 1
        
        # Adaptive k for KSG based on sample size
        k = max(3, min(10, int(np.log(sample_size))))
        return self._ksg_estimator(X, Y, k)
    
    def _bias_corrected_mi_estimation(self, X: np.ndarray, Y: np.ndarray) -> float:
        """Bias-corrected MI estimation for small samples"""
        mi_raw = self._ksg_estimator(X, Y, k=3)
        n = X.shape[0] if len(X.shape) > 1 else len(X)
        
        # Apply bias correction based on sample size
        bias_correction = max(0, 1.0 / (2 * n))
        return max(0.0, mi_raw - bias_correction)
    
    def _copula_mi_estimation(self, X: np.ndarray, Y: np.ndarray) -> float:
        """Copula-based MI estimation"""
        # Convert to uniform marginals (copula approach)
        from scipy.stats import rankdata
        
        if len(X.shape) == 1:
            X_ranks = rankdata(X) / (len(X) + 1)
        else:
            X_ranks = np.column_stack([rankdata(X[:, i]) / (X.shape[0] + 1) for i in range(X.shape[1])])
            
        if len(Y.shape) == 1:
            Y_ranks = rankdata(Y) / (len(Y) + 1)
        else:
            Y_ranks = np.column_stack([rankdata(Y[:, i]) / (Y.shape[0] + 1) for i in range(Y.shape[1])])
        
        # Estimate MI on uniform marginals
        return self._ksg_estimator(X_ranks, Y_ranks, k=5)
    
    def fit(self, X: np.ndarray, Y: np.ndarray, deterministic_annealing: bool = False, 
           beta_schedule: Optional[List[float]] = None, verbose: bool = False) -> Dict[str, Any]:
        """
        Fit Information Bottleneck to data using self-consistent equations
        
        Implements the alternating optimization algorithm from Tishby et al. (1999)
        
        Args:
            X: Input data features
            Y: Target variables
            deterministic_annealing: Whether to use beta annealing
            beta_schedule: Custom beta schedule (overrides deterministic_annealing)
            verbose: Print training progress
            
        Returns:
            Dictionary with training results and statistics
        """
        
        # Encode categorical variables
        if not isinstance(X[0], (int, float, np.integer, np.floating)):
            le_x = LabelEncoder()
            X_encoded = le_x.fit_transform([str(x) for x in X])
        else:
            X_encoded = np.array(X)
            
        if not isinstance(Y[0], (int, float, np.integer, np.floating)):
            le_y = LabelEncoder()
            Y_encoded = le_y.fit_transform([str(y) for y in Y])
        else:
            Y_encoded = np.array(Y)
        
        n_samples = len(X_encoded)
        n_x = len(np.unique(X_encoded))
        n_y = len(np.unique(Y_encoded))
        
        print(f"ğŸ”„ Training Information Bottleneck...")
        print(f"   â€¢ Data: {n_samples} samples, |X|={n_x}, |Y|={n_y}")
        print(f"   â€¢ Representation: |Z|={self.n_clusters}")
        print(f"   â€¢ Î²={self.beta}, max_iter={self.max_iter}")
        
        # Initialize distributions randomly
        self.p_z_given_x = np.random.dirichlet([1.0] * self.n_clusters, size=n_x)
        self.p_y_given_z = np.random.dirichlet([1.0] * n_y, size=self.n_clusters)
        
        # Set up beta schedule
        if beta_schedule is not None:
            betas = beta_schedule
        elif deterministic_annealing:
            betas = np.logspace(-2, np.log10(self.beta), self.max_iter)
        else:
            betas = [self.beta] * self.max_iter
        
        # Main optimization loop
        for iteration in range(self.max_iter):
            beta_current = betas[iteration]
            
            # Store old distributions for convergence check
            old_p_z_given_x = self.p_z_given_x.copy()
            old_p_y_given_z = self.p_y_given_z.copy()
            
            # Update P(z) based on current encoder
            self.p_z = np.zeros(self.n_clusters)
            for x in range(n_x):
                count_x = np.sum(X_encoded == x)
                self.p_z += (count_x / n_samples) * self.p_z_given_x[x]
            
            # Update P(y|z) based on Bayes rule and data
            for z in range(self.n_clusters):
                numerator = np.zeros(n_y)
                denominator = 0.0
                
                for x in range(n_x):
                    count_x = np.sum(X_encoded == x)
                    p_x = count_x / n_samples
                    
                    for y in range(n_y):
                        count_xy = np.sum((X_encoded == x) & (Y_encoded == y))
                        p_y_given_x = count_xy / max(1, count_x)
                        
                        numerator[y] += p_x * self.p_z_given_x[x, z] * p_y_given_x
                        
                    denominator += p_x * self.p_z_given_x[x, z]
                
                if denominator > 1e-12:
                    self.p_y_given_z[z] = numerator / denominator
                else:
                    self.p_y_given_z[z] = np.ones(n_y) / n_y
            
            # Update P(z|x) using self-consistent equation
            for x in range(n_x):
                for z in range(self.n_clusters):
                    # Compute KL divergence D_KL[P(y|x) || P(y|z)]
                    kl_div = 0.0
                    count_x = np.sum(X_encoded == x)
                    
                    if count_x > 0:
                        for y in range(n_y):
                            count_xy = np.sum((X_encoded == x) & (Y_encoded == y))
                            p_y_given_x = count_xy / count_x
                            
                            if p_y_given_x > 1e-12 and self.p_y_given_z[z, y] > 1e-12:
                                kl_div += p_y_given_x * np.log(p_y_given_x / self.p_y_given_z[z, y])
                
                # Self-consistent equation with normalization
                unnormalized = self.p_z[z] * np.exp(-beta_current * kl_div)
                self.p_z_given_x[x, z] = unnormalized
                
            # Normalize P(z|x) for each x
            for x in range(n_x):
                norm_factor = np.sum(self.p_z_given_x[x])
                if norm_factor > 1e-12:
                    self.p_z_given_x[x] /= norm_factor
                else:
                    self.p_z_given_x[x] = np.ones(self.n_clusters) / self.n_clusters
            
            # Compute information measures
            mi_xz = self._compute_mi_xz(X_encoded, n_x, n_samples)
            mi_zy = self._compute_mi_zy(Y_encoded, n_y, n_samples)
            
            ib_objective = mi_xz - beta_current * mi_zy
            
            # Store training history
            self.training_history['ib_objective'].append(ib_objective)
            self.training_history['mutual_info_xz'].append(mi_xz)
            self.training_history['mutual_info_zy'].append(mi_zy)
            self.training_history['compression_term'].append(-mi_xz)
            self.training_history['prediction_term'].append(beta_current * mi_zy)
            
            # Check convergence
            delta_encoder = np.max(np.abs(self.p_z_given_x - old_p_z_given_x))
            delta_decoder = np.max(np.abs(self.p_y_given_z - old_p_y_given_z))
            
            if verbose and (iteration + 1) % 20 == 0:
                print(f"   Iter {iteration+1:3d}: IB={ib_objective:.4f}, "
                      f"I(X;Z)={mi_xz:.4f}, I(Z;Y)={mi_zy:.4f}, Î²={beta_current:.3f}")
            
            if delta_encoder < self.tolerance and delta_decoder < self.tolerance:
                if verbose:
                    print(f"âœ… Converged after {iteration+1} iterations")
                break
        
        final_mi_xz = mi_xz
        final_mi_zy = mi_zy
        final_objective = final_mi_xz - self.beta * final_mi_zy
        
        print(f"âœ… Information Bottleneck training completed!")
        print(f"   â€¢ Final I(X;Z) = {final_mi_xz:.4f} bits (compression cost)")
        print(f"   â€¢ Final I(Z;Y) = {final_mi_zy:.4f} bits (prediction benefit)")
        print(f"   â€¢ Final objective = {final_objective:.4f}")
        
        return {
            'final_objective': final_objective,
            'mutual_info_xz': final_mi_xz,
            'mutual_info_zy': final_mi_zy,
            'compression_ratio': final_mi_xz / (np.log2(n_x) + 1e-12),
            'prediction_ratio': final_mi_zy / (np.log2(n_y) + 1e-12),
            'training_history': self.training_history,
            'converged': iteration < self.max_iter - 1,
            'n_iterations': iteration + 1
        }
    
    def _compute_mi_xz(self, X_encoded: np.ndarray, n_x: int, n_samples: int) -> float:
        """Compute I(X;Z) from current distributions"""
        joint_xz = np.zeros((n_x, self.n_clusters))
        
        for x in range(n_x):
            count_x = np.sum(X_encoded == x)
            p_x = count_x / n_samples
            joint_xz[x] = p_x * self.p_z_given_x[x]
        
        return self._estimate_mutual_info_discrete(joint_xz)
    
    def _compute_mi_zy(self, Y_encoded: np.ndarray, n_y: int, n_samples: int) -> float:
        """Compute I(Z;Y) from current distributions"""
        joint_zy = np.zeros((self.n_clusters, n_y))
        
        for z in range(self.n_clusters):
            joint_zy[z] = self.p_z[z] * self.p_y_given_z[z]
        
        return self._estimate_mutual_info_discrete(joint_zy)
    
    def transform(self, X: np.ndarray) -> np.ndarray:
        """Transform data to information bottleneck representation"""
        if self.p_z_given_x is None:
            raise ValueError("Model not fitted. Call fit() first.")
        
        # Encode X if necessary
        if not isinstance(X[0], (int, float, np.integer, np.floating)):
            le_x = LabelEncoder()
            X_encoded = le_x.fit_transform([str(x) for x in X])
        else:
            X_encoded = np.array(X)
        
        # Get cluster assignments (hard assignment)
        Z = np.argmax(self.p_z_given_x[X_encoded], axis=1)
        return Z
    
    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """Predict class probabilities using information bottleneck"""
        if self.p_z_given_x is None or self.p_y_given_z is None:
            raise ValueError("Model not fitted. Call fit() first.")
        
        # Transform to representation
        Z = self.transform(X)
        
        # Get predictions from P(y|z)
        predictions = self.p_y_given_z[Z]
        return predictions
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Make hard predictions using information bottleneck"""
        proba = self.predict_proba(X)
        return np.argmax(proba, axis=1)
    
    def get_information_curve(self, beta_range: Optional[List[float]] = None) -> Dict[str, List[float]]:
        """
        Generate information curve by fitting IB at different Î² values
        
        This creates the classic I(X;Z) vs I(Z;Y) curve showing the
        compression-prediction trade-off.
        """
        
        if beta_range is None:
            beta_range = np.logspace(-2, 2, 20)  # Î² from 0.01 to 100
        
        original_beta = self.beta
        curve_data = {'beta': [], 'I_XZ': [], 'I_ZY': [], 'objective': []}
        
        print(f"ğŸ“Š Generating information curve with {len(beta_range)} Î² values...")
        
        for beta in beta_range:
            self.beta = beta
            
            # Re-fit with new beta (using stored data would be better)
            # This is a simplified version - in practice you'd want to store X,Y
            if hasattr(self, '_last_X') and hasattr(self, '_last_Y'):
                result = self.fit(self._last_X, self._last_Y, verbose=False)
                
                curve_data['beta'].append(beta)
                curve_data['I_XZ'].append(result['mutual_info_xz'])
                curve_data['I_ZY'].append(result['mutual_info_zy'])
                curve_data['objective'].append(result['final_objective'])
        
        # Restore original beta
        self.beta = original_beta
        
        return curve_data
    
    def get_cluster_assignments(self, X: np.ndarray) -> Dict[str, np.ndarray]:
        """Get detailed cluster assignment information"""
        if self.p_z_given_x is None:
            raise ValueError("Model not fitted. Call fit() first.")
        
        Z_soft = self.p_z_given_x[X]  # Soft assignments
        Z_hard = np.argmax(Z_soft, axis=1)  # Hard assignments
        Z_entropy = -np.sum(Z_soft * np.log(Z_soft + 1e-12), axis=1)  # Assignment uncertainty
        
        return {
            'soft_assignments': Z_soft,
            'hard_assignments': Z_hard,
            'assignment_entropy': Z_entropy,
            'cluster_utilization': np.bincount(Z_hard, minlength=self.n_clusters) / len(Z_hard)
        }