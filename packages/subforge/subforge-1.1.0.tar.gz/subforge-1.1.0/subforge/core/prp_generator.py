#!/usr/bin/env python3
"""
PRP Generator - Product Requirements Prompt System
Creates comprehensive, structured prompts that combine Context Engineering with Factory Pattern execution
"""

import json
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List

from .context_engineer import ContextPackage
from .project_analyzer import ProjectProfile


class PRPType(Enum):
    """Different types of Product Requirements Prompts"""

    FACTORY_ANALYSIS = "factory_analysis"
    FACTORY_GENERATION = "factory_generation"
    AGENT_SPECIALIZATION = "agent_specialization"
    WORKFLOW_OPTIMIZATION = "workflow_optimization"
    VALIDATION_COMPREHENSIVE = "validation_comprehensive"


@dataclass
class PRP:
    """Product Requirements Prompt - Comprehensive context for AI execution"""

    id: str
    type: PRPType
    title: str
    context_package: ContextPackage
    execution_prompt: str
    validation_checklist: List[str]
    success_metrics: List[str]
    output_specification: Dict[str, Any]
    created_at: datetime

    def to_markdown(self) -> str:
        """Convert PRP to structured markdown format"""
        return f"""# PRP: {self.title}

**ID**: `{self.id}`  
**Type**: {self.type.value}  
**Created**: {self.created_at.strftime('%Y-%m-%d %H:%M:%S')}

## Context Package
{self.context_package.to_markdown()}

## Execution Prompt

{self.execution_prompt}

## Validation Checklist

{self._format_checklist(self.validation_checklist)}

## Success Metrics

{self._format_metrics(self.success_metrics)}

## Output Specification

{self._format_output_spec(self.output_specification)}

---
*Generated by SubForge PRP Generator*
"""

    def _format_checklist(self, items: List[str]) -> str:
        """Format validation checklist as markdown"""
        return "\n".join(f"- [ ] {item}" for item in items)

    def _format_metrics(self, metrics: List[str]) -> str:
        """Format success metrics as markdown"""
        return "\n".join(f"- {metric}" for metric in metrics)

    def _format_output_spec(self, spec: Dict[str, Any]) -> str:
        """Format output specification as markdown"""
        lines = []
        for key, value in spec.items():
            if isinstance(value, dict):
                lines.append(f"### {key.replace('_', ' ').title()}")
                for subkey, subvalue in value.items():
                    lines.append(f"- **{subkey}**: {subvalue}")
            else:
                lines.append(f"- **{key.replace('_', ' ').title()}**: {value}")
        return "\n".join(lines)


class PRPGenerator:
    """
    Advanced PRP Generator that creates comprehensive Product Requirements Prompts

    This class implements the Context Engineering methodology by creating structured,
    comprehensive prompts that ensure high-quality AI execution with minimal iterations.
    """

    def __init__(self, workspace_dir: Path):
        self.workspace_dir = workspace_dir
        self.prps_dir = workspace_dir / "PRPs"
        self.templates_dir = self.prps_dir / "templates"
        self.generated_dir = self.prps_dir / "generated"

        # Ensure directories exist
        for directory in [self.prps_dir, self.templates_dir, self.generated_dir]:
            directory.mkdir(parents=True, exist_ok=True)

        # Initialize PRP templates
        self._create_prp_templates()

    def generate_factory_analysis_prp(
        self,
        project_profile: ProjectProfile,
        context_package: ContextPackage,
        user_request: str,
    ) -> PRP:
        """Generate PRP for factory analysis phase"""

        prp_id = f"analysis_{int(datetime.now().timestamp())}"

        execution_prompt = f"""# Factory Analysis Task

You are the SubForge Project Analyzer, a specialized agent responsible for deep project analysis and requirement gathering.

## Primary Objective
Perform comprehensive analysis of the project to enable optimal factory configuration generation.

## User Request Context
**Original Request**: {user_request}

## Analysis Framework

### 1. **Project Structure Analysis**
- Examine the complete project directory structure
- Identify entry points, configuration files, and key modules
- Map dependencies and relationships between components
- Document any unusual or project-specific patterns

### 2. **Technology Stack Deep Dive**
- Validate detected technologies: {', '.join(project_profile.technology_stack.languages)}
- Identify specific versions and configurations
- Analyze framework usage patterns: {', '.join(project_profile.technology_stack.frameworks)}
- Document build tools, package managers, and deployment tools

### 3. **Architecture Pattern Verification**
- Confirm architecture pattern: {project_profile.architecture_pattern.value}
- Identify architectural boundaries and interfaces
- Map data flow and communication patterns
- Document scalability and performance considerations

### 4. **Team and Workflow Analysis**
- Assess project complexity: {project_profile.complexity.value}
- Recommend team size: Currently estimated at {project_profile.team_size_estimate}
- Identify collaboration patterns and tools
- Analyze development workflow requirements

### 5. **Integration Requirements**
- CI/CD integration needs: {"Required" if project_profile.has_ci_cd else "Not detected"}
- Testing strategy requirements: {"Comprehensive" if project_profile.has_tests else "Basic"}
- Deployment and monitoring needs
- Security and compliance considerations

## Required Analysis Outputs

### Project Analysis Document
Create comprehensive `project_analysis.md` with:
- **Executive Summary**: Key findings and recommendations
- **Technical Architecture**: Detailed architecture documentation  
- **Technology Stack**: Complete stack with versions and usage patterns
- **Development Workflow**: Recommended processes and tools
- **Team Recommendations**: Optimal team composition and size
- **Integration Plan**: CI/CD, monitoring, and deployment strategy
- **Quality Standards**: Testing, security, and performance requirements

### Requirements Refinement
Based on analysis, refine the original user request with:
- Specific technical requirements discovered
- Architecture-specific considerations
- Team collaboration needs
- Quality and compliance requirements
- Timeline and complexity estimates

## Context Integration
Leverage the provided context package to:
- Use relevant examples from similar projects
- Apply proven patterns for the detected architecture
- Reference best practices for the technology stack
- Validate recommendations against success criteria

## Quality Gates
Before completing analysis, ensure:
- All major project components are documented
- Technology stack is comprehensively analyzed
- Architecture pattern is validated with evidence
- Team and workflow recommendations are specific
- Integration requirements are clearly defined

This analysis will serve as the foundation for all subsequent factory phases.
"""

        validation_checklist = [
            "Project structure is completely mapped and documented",
            "All technologies are identified with specific versions",
            "Architecture pattern is validated with concrete evidence",
            "Team size and workflow recommendations are specific",
            "Integration requirements are clearly documented",
            "Quality standards are defined and measurable",
            "Analysis provides clear guidance for template selection",
            "All findings are backed by project evidence",
        ]

        success_metrics = [
            "Analysis completion time < 3 minutes",
            "All major project components identified",
            "Technology stack accuracy > 95%",
            "Architecture pattern correctly classified",
            "Actionable team recommendations provided",
            "Clear template selection criteria established",
        ]

        output_specification = {
            "required_files": {
                "project_analysis.md": "Comprehensive project analysis document",
                "requirements_refined.md": "Enhanced requirements based on analysis",
                "template_criteria.json": "Criteria for template selection",
            },
            "analysis_depth": "comprehensive",
            "documentation_level": "detailed",
            "evidence_required": True,
            "recommendations_specificity": "high",
        }

        prp = PRP(
            id=prp_id,
            type=PRPType.FACTORY_ANALYSIS,
            title=f"Factory Analysis for {project_profile.name}",
            context_package=context_package,
            execution_prompt=execution_prompt,
            validation_checklist=validation_checklist,
            success_metrics=success_metrics,
            output_specification=output_specification,
            created_at=datetime.now(),
        )

        self._save_prp(prp)
        return prp

    def generate_factory_generation_prp(
        self,
        project_profile: ProjectProfile,
        context_package: ContextPackage,
        analysis_outputs: Dict[str, Any],
        subagent_type: str,
    ) -> PRP:
        """Generate PRP for factory generation phase"""

        prp_id = f"generation_{subagent_type}_{int(datetime.now().timestamp())}"

        # Get subagent-specific prompt
        execution_prompt = self._get_subagent_execution_prompt(
            subagent_type, project_profile, context_package, analysis_outputs
        )

        validation_checklist = self._get_subagent_validation_checklist(subagent_type)
        success_metrics = self._get_subagent_success_metrics(subagent_type)
        output_specification = self._get_subagent_output_specification(subagent_type)

        prp = PRP(
            id=prp_id,
            type=PRPType.FACTORY_GENERATION,
            title=f"{subagent_type.replace('-', ' ').title()} Generation for {project_profile.name}",
            context_package=context_package,
            execution_prompt=execution_prompt,
            validation_checklist=validation_checklist,
            success_metrics=success_metrics,
            output_specification=output_specification,
            created_at=datetime.now(),
        )

        self._save_prp(prp)
        return prp

    def _get_subagent_execution_prompt(
        self,
        subagent_type: str,
        project_profile: ProjectProfile,
        context_package: ContextPackage,
        analysis_outputs: Dict[str, Any],
    ) -> str:
        """Get execution prompt for specific subagent type"""

        if subagent_type == "claude-md-generator":
            return self._get_claude_md_generator_prompt(
                project_profile, context_package, analysis_outputs
            )
        elif subagent_type == "agent-generator":
            return self._get_agent_generator_prompt(
                project_profile, context_package, analysis_outputs
            )
        elif subagent_type == "workflow-generator":
            return self._get_workflow_generator_prompt(
                project_profile, context_package, analysis_outputs
            )
        else:
            return self._get_generic_subagent_prompt(
                subagent_type, project_profile, context_package, analysis_outputs
            )

    def _get_claude_md_generator_prompt(
        self,
        project_profile: ProjectProfile,
        context_package: ContextPackage,
        analysis_outputs: Dict[str, Any],
    ) -> str:
        """Get Claude.md generator specific prompt"""
        return f"""# CLAUDE.md Generation Task

You are the SubForge CLAUDE.md Generator, specialized in creating comprehensive CLAUDE.md files that serve as the central configuration for Claude Code projects.

## Primary Objective
Generate a complete, project-specific CLAUDE.md file that optimizes Claude Code for this project's unique characteristics and requirements.

## Project Context
- **Name**: {project_profile.name}
- **Architecture**: {project_profile.architecture_pattern.value}  
- **Complexity**: {project_profile.complexity.value}
- **Languages**: {', '.join(project_profile.technology_stack.languages)}
- **Frameworks**: {', '.join(project_profile.technology_stack.frameworks)}
- **Team Size**: {project_profile.team_size_estimate}

## Analysis Insights
{self._format_analysis_insights(analysis_outputs)}

## Generation Requirements

### 1. **Project Overview Section**
- Clear, concise project description
- Key objectives and goals
- Target users or use cases
- Technology stack summary

### 2. **Build Commands Section**
- Project-specific build commands
- Environment setup instructions
- Testing commands tailored to the project
- Deployment commands if applicable

### 3. **Code Style Section**
- Language-specific style guidelines
- Framework conventions for: {', '.join(project_profile.technology_stack.frameworks)}
- Formatting and linting rules
- Documentation standards

### 4. **Architecture Section**
- {project_profile.architecture_pattern.value} architecture guidelines
- Key architectural decisions
- Component interactions
- Scalability considerations

### 5. **Workflow Section**
- Development process definition
- Git workflow recommendations
- Code review process
- Release management

### 6. **Agent Team Configuration**
- List of recommended agents based on analysis
- Agent roles and responsibilities
- Coordination protocols
- Auto-activation rules

## Context Integration
Use provided examples and patterns to:
- Adapt templates to project specifics
- Include relevant code examples
- Reference best practices
- Ensure consistency with project patterns

## Quality Standards
The generated CLAUDE.md must:
- Be immediately usable without modifications
- Include accurate build commands that work
- Provide clear guidance for all team members
- Integrate seamlessly with existing project structure
- Follow Claude Code best practices
"""

    def _get_agent_generator_prompt(
        self,
        project_profile: ProjectProfile,
        context_package: ContextPackage,
        analysis_outputs: Dict[str, Any],
    ) -> str:
        """Get agent generator specific prompt"""
        return f"""# Agent Generation Task

You are the SubForge Agent Generator, specialized in creating optimal teams of Claude Code subagents tailored to specific project needs.

## Primary Objective
Generate a complete set of specialized subagents that will work together effectively to support development of this {project_profile.architecture_pattern.value} project.

## Project Analysis Summary
{self._format_analysis_insights(analysis_outputs)}

## Agent Generation Strategy

### 1. **Core Agent Team**
Based on project analysis, generate these essential agents:
- **Backend Developer**: For {', '.join(project_profile.technology_stack.languages)} development
- **Code Reviewer**: For quality assurance and standards compliance
- **Test Engineer**: For {"comprehensive" if project_profile.has_tests else "basic"} testing strategy

### 2. **Specialized Agents**
Based on project characteristics, include:
{"- **API Developer**: For REST/GraphQL API development" if any("api" in fw.lower() for fw in project_profile.technology_stack.frameworks) else ""}
{"- **DevOps Engineer**: For CI/CD and deployment" if project_profile.has_ci_cd else ""}
{"- **Database Specialist**: For data modeling and optimization" if project_profile.technology_stack.databases else ""}
{"- **Performance Optimizer**: For complex system optimization" if project_profile.complexity.value == "complex" else ""}

### 3. **Agent Configuration Requirements**

For each generated agent:

#### YAML Frontmatter
```yaml
---
name: agent-name
description: Specific role and expertise
model: opus|sonnet|haiku  # Based on complexity
tools: [appropriate tools list]
---
```

#### System Prompt Structure
- **Role Definition**: Clear specialization and expertise
- **Project Context**: Technology stack and architecture awareness  
- **Responsibilities**: Specific tasks and domains
- **Coordination**: How agent works with others
- **Quality Standards**: Project-specific standards and practices

#### Tool Assignment Strategy
- **Minimal Necessary**: Only tools required for role
- **Security Conscious**: Appropriate permissions
- **Project Specific**: Tools relevant to tech stack

## Context Integration
Leverage provided context to:
- Customize agent prompts for project tech stack
- Include relevant code examples and patterns
- Reference project-specific standards
- Ensure agents coordinate effectively

## Quality Requirements
Each generated agent must:
- Have a clear, non-overlapping specialization
- Include project-specific knowledge
- Coordinate effectively with other agents
- Follow security best practices
- Be immediately usable in the project context
"""

    def _get_workflow_generator_prompt(
        self,
        project_profile: ProjectProfile,
        context_package: ContextPackage,
        analysis_outputs: Dict[str, Any],
    ) -> str:
        """Get workflow generator specific prompt"""
        return f"""# Workflow Generation Task

You are the SubForge Workflow Generator, specialized in creating custom development workflows and automation commands tailored to project architecture and team needs.

## Primary Objective
Generate comprehensive development workflows, quality gates, and automation commands that optimize productivity for this {project_profile.architecture_pattern.value} project.

## Project Workflow Context
- **Architecture**: {project_profile.architecture_pattern.value} (requires specific workflow patterns)
- **Team Size**: {project_profile.team_size_estimate} (affects coordination complexity)
- **Tech Stack**: {', '.join(project_profile.technology_stack.languages)} with {', '.join(project_profile.technology_stack.frameworks)}
- **CI/CD**: {"Integrated" if project_profile.has_ci_cd else "Manual"}
- **Testing**: {"Comprehensive" if project_profile.has_tests else "Basic"}

## Workflow Generation Requirements

### 1. **Development Workflows**
Create workflows for:
- **Feature Development**: End-to-end feature implementation process
- **Bug Fix Workflow**: Rapid response and resolution process  
- **Code Review Process**: Quality assurance and knowledge sharing
- **Testing Strategy**: {project_profile.architecture_pattern.value}-appropriate testing
- **Release Management**: {"Automated" if project_profile.has_ci_cd else "Manual"} release process

### 2. **Architecture-Specific Patterns**
{self._get_architecture_workflow_requirements(project_profile.architecture_pattern)}

### 3. **Quality Gates**
Define measurable quality checkpoints:
- **Code Commit Gates**: Syntax, formatting, basic tests
- **Pull Request Gates**: Comprehensive testing, code review, security
- **Pre-Deployment Gates**: Integration tests, performance validation
- **Post-Deployment Gates**: Monitoring, rollback readiness

### 4. **Automation Commands**
Generate project-specific commands:
- **Development Setup**: `subforge-dev-setup`
- **Quality Checks**: `subforge-quality-check`  
- **Testing Suite**: `subforge-test-all`
- **Deployment**: `subforge-deploy-{{'staging' if project_profile.complexity.value != 'simple' else 'production'}}`

### 5. **Agent Coordination Workflows**
Design how agents work together:
- **Handoff Protocols**: Clear responsibility transitions
- **Escalation Paths**: When and how to escalate between agents
- **Quality Validation**: Agent-specific quality checks
- **Documentation Flow**: Knowledge capture and sharing

## Context Integration
Use provided patterns and examples to:
- Adapt workflow templates to project specifics
- Include relevant automation examples
- Reference architecture-specific best practices
- Ensure workflows integrate with existing tools

## Output Requirements
Generate comprehensive workflow documentation including:
- Step-by-step process definitions
- Executable commands and scripts
- Quality gate specifications  
- Agent coordination protocols
- Emergency procedures and rollback plans
"""

    def _get_generic_subagent_prompt(
        self,
        subagent_type: str,
        project_profile: ProjectProfile,
        context_package: ContextPackage,
        analysis_outputs: Dict[str, Any],
    ) -> str:
        """Get generic subagent prompt as fallback"""
        return f"""# {subagent_type.replace('-', ' ').title()} Generation Task

You are a SubForge factory subagent specialized in {subagent_type.replace('-', ' ')} for project configuration generation.

## Project Context
{self._format_project_context(project_profile)}

## Analysis Context  
{self._format_analysis_insights(analysis_outputs)}

## Generation Objectives
Generate high-quality, project-specific configurations that:
- Align with {project_profile.architecture_pattern.value} architecture
- Support {', '.join(project_profile.technology_stack.languages)} development
- Scale for {project_profile.team_size_estimate} team members
- Meet {project_profile.complexity.value} complexity requirements

## Context Integration
Leverage provided context including:
- Relevant examples and patterns
- Best practices for technology stack
- Architecture-specific considerations
- Team collaboration requirements

## Quality Standards
Ensure all outputs:
- Are immediately usable without modification
- Follow project-specific conventions
- Integrate seamlessly with other components
- Include comprehensive documentation
- Meet established quality criteria
"""

    def _format_analysis_insights(self, analysis_outputs: Dict[str, Any]) -> str:
        """Format analysis outputs for prompt context"""
        if not analysis_outputs:
            return "Analysis in progress - using project profile data"

        insights = []
        for key, value in analysis_outputs.items():
            if isinstance(value, dict):
                insights.append(
                    f"**{key.replace('_', ' ').title()}**: {len(value)} items identified"
                )
            elif isinstance(value, list):
                insights.append(
                    f"**{key.replace('_', ' ').title()}**: {', '.join(map(str, value[:3]))}"
                )
            else:
                insights.append(f"**{key.replace('_', ' ').title()}**: {value}")

        return (
            "\n".join(insights)
            if insights
            else "Standard analysis approach will be used"
        )

    def _format_project_context(self, project_profile: ProjectProfile) -> str:
        """Format project profile for prompt context"""
        return f"""- **Name**: {project_profile.name}
- **Architecture**: {project_profile.architecture_pattern.value}
- **Complexity**: {project_profile.complexity.value}  
- **Languages**: {', '.join(project_profile.technology_stack.languages)}
- **Frameworks**: {', '.join(project_profile.technology_stack.frameworks)}
- **Team Size**: {project_profile.team_size_estimate}
- **Testing**: {"Comprehensive" if project_profile.has_tests else "Basic"}
- **CI/CD**: {"Integrated" if project_profile.has_ci_cd else "Manual"}"""

    def _get_architecture_workflow_requirements(self, architecture) -> str:
        """Get architecture-specific workflow requirements"""
        if architecture.value == "microservices":
            return """For microservices architecture:
- **Service Development**: Independent service development and testing
- **API Contract Management**: OpenAPI specification and validation
- **Service Integration**: Inter-service communication testing
- **Deployment Coordination**: Independent deployments with dependency management
- **Monitoring & Observability**: Distributed tracing and service health monitoring"""

        elif architecture.value == "monolithic":
            return """For monolithic architecture:
- **Module Development**: Feature development within monolithic boundaries
- **Integration Testing**: Comprehensive system-wide testing
- **Database Migrations**: Coordinated schema changes
- **Deployment Strategy**: Blue-green or rolling deployments
- **Performance Monitoring**: System-wide performance and resource monitoring"""

        else:
            return """For standard architecture:
- **Component Development**: Modular development practices
- **Integration Points**: Clear interface definitions and testing
- **Deployment Pipeline**: Straightforward deployment automation
- **Quality Assurance**: Comprehensive testing strategy
- **Monitoring**: Application and system monitoring"""

    def _get_subagent_validation_checklist(self, subagent_type: str) -> List[str]:
        """Get validation checklist for specific subagent type"""
        common_checks = [
            "Output files are generated in correct locations",
            "All generated content is syntactically valid",
            "Configuration integrates with existing project structure",
            "Documentation is comprehensive and accurate",
        ]

        if subagent_type == "claude-md-generator":
            return common_checks + [
                "CLAUDE.md follows proper structure and format",
                "Build commands are executable and accurate",
                "Agent team configuration is appropriate",
                "All project-specific sections are included",
            ]
        elif subagent_type == "agent-generator":
            return common_checks + [
                "All agents have valid YAML frontmatter",
                "Agent roles are clearly defined and non-overlapping",
                "Tool assignments are appropriate and secure",
                "System prompts are project-specific",
            ]
        elif subagent_type == "workflow-generator":
            return common_checks + [
                "Workflows are appropriate for project architecture",
                "Quality gates are measurable and enforceable",
                "Commands are executable and tested",
                "Agent coordination is clearly defined",
            ]

        return common_checks

    def _get_subagent_success_metrics(self, subagent_type: str) -> List[str]:
        """Get success metrics for specific subagent type"""
        if subagent_type == "claude-md-generator":
            return [
                "CLAUDE.md generation time < 30 seconds",
                "Build commands execute successfully",
                "Configuration accuracy > 95%",
                "No manual corrections required",
            ]
        elif subagent_type == "agent-generator":
            return [
                "All agents generated within 60 seconds",
                "Agent specialization clarity score > 90%",
                "Tool assignment accuracy > 95%",
                "No configuration conflicts detected",
            ]
        elif subagent_type == "workflow-generator":
            return [
                "Workflow generation time < 45 seconds",
                "All commands are executable",
                "Quality gates are comprehensive",
                "Agent coordination is well-defined",
            ]

        return [
            "Generation completed within expected timeframe",
            "Output quality meets standards",
        ]

    def _get_subagent_output_specification(self, subagent_type: str) -> Dict[str, Any]:
        """Get output specification for specific subagent type"""
        if subagent_type == "claude-md-generator":
            return {
                "primary_output": "CLAUDE.md",
                "location": "project_root",
                "format": "markdown",
                "sections_required": [
                    "project_overview",
                    "build_commands",
                    "code_style",
                    "architecture",
                    "workflow",
                    "agent_team",
                ],
                "customization_level": "high",
            }
        elif subagent_type == "agent-generator":
            return {
                "primary_output": "agent_configurations",
                "location": ".claude/agents/",
                "format": "yaml_frontmatter_markdown",
                "agents_count": "variable_based_on_analysis",
                "customization_level": "high",
            }
        elif subagent_type == "workflow-generator":
            return {
                "primary_output": "workflow_documentation",
                "location": "workflows/",
                "format": "markdown",
                "includes": ["processes", "commands", "quality_gates", "coordination"],
                "customization_level": "architecture_specific",
            }

        return {
            "primary_output": f"{subagent_type}_configuration",
            "format": "markdown",
        }

    def _create_prp_templates(self):
        """Create base PRP templates"""
        # This would create template files for different PRP types
        # Implementation would create actual template files

    def _save_prp(self, prp: PRP):
        """Save PRP to file system"""
        prp_file = self.generated_dir / f"{prp.id}.md"

        with open(prp_file, "w", encoding="utf-8") as f:
            f.write(prp.to_markdown())

        # Also save metadata as JSON
        meta_file = self.generated_dir / f"{prp.id}_meta.json"
        with open(meta_file, "w", encoding="utf-8") as f:
            json.dump(
                {
                    "id": prp.id,
                    "type": prp.type.value,
                    "title": prp.title,
                    "created_at": prp.created_at.isoformat(),
                    "validation_checklist": prp.validation_checklist,
                    "success_metrics": prp.success_metrics,
                    "output_specification": prp.output_specification,
                },
                f,
                indent=2,
            )


def create_prp_generator(workspace_dir: Path) -> PRPGenerator:
    """Factory function to create PRPGenerator instance"""
    return PRPGenerator(workspace_dir)