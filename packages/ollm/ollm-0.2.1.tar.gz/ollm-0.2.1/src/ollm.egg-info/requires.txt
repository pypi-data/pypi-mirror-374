numpy
torch
transformers<4.56.0,>=4.55.0
accelerate
flash-attn
