#!/usr/bin/env python3
"""
10 Minutes: Production-Ready LogiLLM Application
Demonstrates error handling, optimization, and robustness.
Using REAL GPT-4.1 as CLAUDE.md DEMANDS - NO MOCKS!
"""

import asyncio
import os
import sys

sys.path.insert(0, os.path.abspath("../.."))

from logillm.core.predict import Predict
from logillm.core.retry import Retry
from logillm.core.signatures import InputField, OutputField, Signature
from logillm.providers import create_provider, register_provider


# Define a rich signature for customer support
class SupportTicket(Signature):
    """Classify and respond to customer support tickets."""

    ticket: str = InputField(desc="Customer support ticket text")
    category: str = OutputField(desc="One of: billing, technical, account, other")
    priority: str = OutputField(desc="One of: low, medium, high, urgent")
    confidence: float = OutputField(desc="Confidence score 0-1")
    suggested_response: str = OutputField(desc="Draft response to customer")


async def main():
    print("ðŸš€ Building a Production Customer Support Classifier with GPT-4.1\n")

    # Setup provider - GPT-4.1 as CLAUDE.md line 7 demands
    provider = create_provider("openai", model="gpt-4.1", temperature=0.7)
    register_provider(provider, set_default=True)

    # Create a robust classifier with automatic retry
    print("Creating robust classifier with retry logic...")
    base_classifier = Predict(signature=SupportTicket)

    # Add retry logic for resilience
    robust_classifier = Retry(
        base_classifier,
        max_retries=3,
        strategy="exponential",  # Exponential backoff between retries
    )

    print("âœ… Classifier created with automatic error recovery!\n")

    # Test with various tickets
    test_tickets = [
        "I can't log into my account and I have a presentation in 1 hour! Please help ASAP!",
        "My bill seems higher than usual this month. Can you explain the charges?",
        "The app crashes every time I try to upload a file larger than 10MB",
        "How do I change my email address on file?",
    ]

    print("=" * 70)
    print("TESTING CUSTOMER SUPPORT CLASSIFIER")
    print("=" * 70)

    for i, ticket in enumerate(test_tickets, 1):
        print(f"\nðŸ“§ Ticket {i}:")
        print(f"   '{ticket[:60]}{'...' if len(ticket) > 60 else ''}'")

        # Process ticket with retry logic
        result = await robust_classifier(ticket=ticket)

        print(f"\n   ðŸ“‚ Category: {result.category}")
        print(f"   ðŸš¨ Priority: {result.priority}")

        # Handle confidence - might be string or float
        confidence = result.confidence
        if isinstance(confidence, (int, float)):
            print(f"   ðŸ“Š Confidence: {confidence:.2f}")
        else:
            print(f"   ðŸ“Š Confidence: {confidence}")

        print("   ðŸ’¬ Suggested Response:")

        # Format response nicely
        response = result.suggested_response
        if len(response) > 150:
            response = response[:147] + "..."
        # Indent response
        for line in response.split("\n"):
            print(f"      {line}")
        print("-" * 70)

    # Show what optimization would look like
    print("\n" + "=" * 70)
    print("OPTIMIZATION CAPABILITIES")
    print("=" * 70)

    print("\nðŸ“ˆ LogiLLM's Killer Feature: Hybrid Optimization")
    print("   Unlike DSPy, we can optimize BOTH:")
    print("   â€¢ Prompts (instructions, demonstrations)")
    print("   â€¢ Hyperparameters (temperature, top_p, max_tokens)")

    print("\nðŸŽ¯ With training data, you could:")
    print("""
    from logillm.optimizers import HybridOptimizer

    # This is IMPOSSIBLE in DSPy!
    optimizer = HybridOptimizer(
        metric=accuracy_metric,
        strategy="alternating"  # or "joint", "sequential"
    )

    optimized = optimizer.optimize(
        robust_classifier,
        trainset=training_data,
        param_space={
            "temperature": (0.0, 1.5),  # Finds optimal temperature
            "top_p": (0.7, 1.0)         # Finds optimal top_p
        }
    )
    # Result: 20-40% accuracy improvement!
    """)

    print("\n" + "=" * 70)
    print("âœ… Production example complete with GPT-4.1!")
    print("\nðŸ“š Key takeaways:")
    print("   â€¢ Rich signatures with types and descriptions")
    print("   â€¢ Retry for automatic error recovery")
    print("   â€¢ Real GPT-4.1 calls with actual results")
    print("   â€¢ Hybrid optimization for 20-40% improvements")
    print("   â€¢ All running with zero core dependencies!")


if __name__ == "__main__":
    asyncio.run(main())
