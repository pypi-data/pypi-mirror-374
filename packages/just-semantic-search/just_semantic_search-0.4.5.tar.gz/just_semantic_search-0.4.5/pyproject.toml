# IMPORTANT: to make proper cpu/gpu resolution you must apply poetry config installer.re-resolve false
[tool.poetry]
name = "just-semantic-search"
version = "0.4.5"
description = "Core interfaces for hybrid search implementations (CPU version)"
authors = ["Alex Karmazin <karmazinalex@gmail.com>", "Anton Kulaga <antonkulaga@gmail.com>", "Newton Winter <isoutthere@gmail.com>"]
license = "Apache-2.0"
readme = "README.md"
packages = [{include = "just_semantic_search"}]
keywords = ["python", "llm", "cpu", "science", "review", "hybrid search", "semantic search", "core"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Programming Language :: Python :: 3.14",
    "Operating System :: Unix",
    "Operating System :: POSIX :: Linux",
    "Operating System :: MacOS :: MacOS X",
    "Operating System :: Microsoft :: Windows",
]

[[tool.poetry.source]]
name = "torch-cpu"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[[tool.poetry.source]]
name = "torch-gpu"
url = "https://download.pytorch.org/whl/cu124"
priority = "explicit"

[tool.poetry.dependencies]
python = ">=3.10,<3.15"
transformers = ">=4.52.4"
sentence-transformers = ">=4.1.0"
typer = "*"
pydantic = ">=2.11.5"
scikit-learn = ">=1.6.1"
einops = ">=0.8.1"
eliot = ">=1.17.5"
eliot-tree = ">=24.0.0"

# CUDA version - explicitly from GPU source
torch = { version = "2.6.0", source = "torch-cpu" }

# CUDA dependencies
triton = { version = ">=3.2.0", optional = true }

[tool.poetry.extras]
cuda = ["triton"]

[build-system]
requires = ["poetry-core>=1.0.0", "poetry-dynamic-versioning>=1.4.1"]
build-backend = "poetry.core.masonry.api"

[tool.poetry-dynamic-versioning]
enable = false
vcs = "git"
style = "semver"
pattern = "v?(?P<base>\\d+\\.\\d+\\.\\d+)"
format-jinja = "{{base}}"