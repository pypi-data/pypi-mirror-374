#!/usr/bin/env python3
"""
CodeClinic CLI tool - Python project dependency and stub analysis

This is the main entry point for the CodeClinic CLI tool.
It imports and uses the core library from src/codeclinic.
"""

import sys
import argparse
import os
import json
from pathlib import Path
from collections import defaultdict
from typing import Dict, Tuple

# æ–°ç‰ˆå¯¼å…¥
from codeclinic.data_collector import collect_project_data
from codeclinic.config_loader import load_config, ExtendedConfig
from codeclinic.violations_analysis import analyze_violations, save_violations_report
from codeclinic.stub_analysis import analyze_stub_completeness, save_stub_report
from codeclinic.graphviz_render import render_graph

# ä¿æŒå‘åå…¼å®¹çš„å¯¼å…¥
from codeclinic.ast_scanner import scan_project_ast as scan_project
from codeclinic.config import Config
from codeclinic.types import ModuleStats, Modules, GraphEdges
from codeclinic.json_output import save_json_output
from codeclinic.stub_report import save_stub_report as save_legacy_stub_report


def main() -> None:
    parser = argparse.ArgumentParser(
        prog="codeclinic",
        description="Diagnose your Python project: import graph + stub metrics + import rules compliance",
    )
    
    # é…ç½®ç®¡ç†å‘½ä»¤
    parser.add_argument("--init", action="store_true", help="Generate default configuration file (codeclinic.yaml)")
    parser.add_argument("--show-config", action="store_true", help="Show current effective configuration")
    
    # åˆ†æå‚æ•°
    parser.add_argument("--path", help="Root path to scan (package folder or src root)")
    parser.add_argument("--out", default=None, help="Output directory for results (default: ./codeclinic_results)")
    parser.add_argument("--format", default=None, choices=["svg", "png", "pdf", "dot", "json"], help="Output format (svg/png/pdf/dot for visualization, json for data)")
    parser.add_argument("--aggregate", default=None, choices=["module", "package"], help="Aggregate nodes by module or package")
    parser.add_argument("--count-private", action="store_true", help="Count private (_prefixed) functions in metrics")
    parser.add_argument("--legacy", action="store_true", help="Use legacy analysis mode (backward compatibility)")

    args = parser.parse_args()

    # å¤„ç†é…ç½®ç®¡ç†å‘½ä»¤
    if args.init:
        from codeclinic.config_init import init_config
        init_config()
        return
    
    if args.show_config:
        from codeclinic.config_init import show_config
        show_config()
        return
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®š --pathï¼Œè¦æ±‚ç”¨æˆ·æä¾›
    if not args.path:
        print("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®š --path å‚æ•°")
        print("ğŸ’¡ æç¤º:")
        print("  â€¢ åˆ†æé¡¹ç›®: codeclinic --path /path/to/project")
        print("  â€¢ ç”Ÿæˆé…ç½®: codeclinic --init")
        print("  â€¢ æŸ¥çœ‹é…ç½®: codeclinic --show-config")
        sys.exit(1)

    # å¦‚æœä½¿ç”¨legacyæ¨¡å¼ï¼Œè°ƒç”¨æ—§ç‰ˆæœ¬å‡½æ•°
    if args.legacy:
        _run_legacy_analysis(args)
        return
    
    # === æ–°ç‰ˆåˆ†ææµç¨‹ ===
    
    # 1. åŠ è½½é…ç½®
    try:
        config = load_config()
        white_list_count = len(config.import_rules.white_list) if config.import_rules.white_list else 0
        print(f"å·²åŠ è½½é…ç½®: {white_list_count} ä¸ªç™½åå•é¡¹")
    except Exception as e:
        print(f"è­¦å‘Š: é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        config = ExtendedConfig()
    
    # 2. åˆå¹¶å‘½ä»¤è¡Œå‚æ•°
    if args.path:
        config.paths = [args.path]
    if args.out:
        config.output = args.out
    if args.format:
        config.format = args.format
    if args.aggregate:
        config.aggregate = args.aggregate
    if args.count_private:
        config.count_private = True
    
    print(f"\nğŸ” å¼€å§‹åˆ†æé¡¹ç›®: {config.paths}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {config.output}")
    
    # 3. æ”¶é›†é¡¹ç›®æ•°æ®
    project_data = collect_project_data(
        paths=config.paths,
        include=config.include,
        exclude=config.exclude,
        count_private=config.count_private,
        config={
            'import_rules': config.import_rules,
            'aggregate': config.aggregate,
            'format': config.format
        }
    )
    
    # å¤„ç†èšåˆæ¨¡å¼
    if config.aggregate == "package":
        project_data.nodes, project_data.import_edges = _aggregate_to_packages_new(
            project_data.nodes, project_data.import_edges
        )
    
    # 4. æ‰“å°æ‘˜è¦
    _print_project_summary(project_data, root=args.path)
    
    # 5. åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(config.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ“‚ è¾“å‡ºç›®å½•: {output_dir.absolute()}")
    
    # 6. ä¿å­˜å®Œæ•´é¡¹ç›®æ•°æ®
    data_json_path = output_dir / "data.json"
    _save_project_data(project_data, data_json_path)
    print(f"âœ“ é¡¹ç›®æ•°æ®ä¿å­˜åˆ°: {data_json_path}")
    
    # 7. å¹¶è¡Œè¿›è¡Œä¸“é¡¹åˆ†æ
    print(f"\nğŸ”¬ å¼€å§‹ä¸“é¡¹åˆ†æ...")
    
    # 7.1 å¯¼å…¥è¿è§„åˆ†æ
    violations_data = analyze_violations(project_data)
    violations_json = save_violations_report(violations_data, project_data, output_dir)
    
    # 7.2 Stubå®Œæ•´åº¦åˆ†æ
    stub_data = analyze_stub_completeness(project_data)
    stub_json = save_stub_report(stub_data, project_data, output_dir)
    
    # 8. æ€»ç»“æŠ¥å‘Š
    _print_final_summary(violations_data, stub_data, output_dir)


def _save_project_data(project_data, json_path: Path) -> None:
    """ä¿å­˜å®Œæ•´çš„é¡¹ç›®æ•°æ®ä¸ºJSONæ–‡ä»¶"""
    from .node_types import NodeType, FunctionInfo
    
    # å‡†å¤‡å¯åºåˆ—åŒ–çš„æ•°æ®
    config_data = {}
    for key, value in project_data.config.items():
        if hasattr(value, '__dict__'):
            # å¦‚æœæ˜¯å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
            config_data[key] = value.__dict__
        else:
            config_data[key] = value
    
    json_data = {
        "version": project_data.version,
        "timestamp": project_data.timestamp,
        "project_root": project_data.project_root,
        "config": config_data,
        "summary": {
            "total_nodes": len(project_data.nodes),
            "total_modules": len(project_data.modules),
            "total_packages": len(project_data.packages),
            "total_import_edges": len(project_data.import_edges),
            "total_child_edges": len(project_data.child_edges),
            "total_functions": sum(node.functions_total for node in project_data.nodes.values()),
            "total_stubs": sum(node.stubs for node in project_data.nodes.values())
        },
        "nodes": {},
        "import_edges": list(project_data.import_edges),
        "child_edges": list(project_data.child_edges)
    }
    
    # åºåˆ—åŒ–èŠ‚ç‚¹æ•°æ®
    for name, node in project_data.nodes.items():
        # åºåˆ—åŒ–å‡½æ•°ä¿¡æ¯
        functions_data = []
        for func in node.functions:
            functions_data.append({
                "name": func.name,
                "full_name": func.full_name,
                "is_stub": func.is_stub,
                "is_public": func.is_public,
                "docstring": func.docstring,
                "line_number": func.line_number,
                "is_method": func.is_method,
                "class_name": func.class_name
            })
        
        # åºåˆ—åŒ–ç±»æ–¹æ³•ä¿¡æ¯
        classes_data = {}
        for class_name, methods in node.classes.items():
            classes_data[class_name] = []
            for method in methods:
                classes_data[class_name].append({
                    "name": method.name,
                    "full_name": method.full_name,
                    "is_stub": method.is_stub,
                    "is_public": method.is_public,
                    "docstring": method.docstring,
                    "line_number": method.line_number,
                    "is_method": method.is_method,
                    "class_name": method.class_name
                })
        
        json_data["nodes"][name] = {
            "name": node.name,
            "node_type": node.node_type.value,
            "file_path": node.file_path,
            "functions": functions_data,
            "classes": classes_data,
            "imports": list(node.imports),
            "functions_total": node.functions_total,
            "functions_public": node.functions_public,
            "stubs": node.stubs,
            "stub_ratio": node.stub_ratio,
            "parent": node.parent,
            "children": list(node.children),
            "package_depth": node.package_depth,
            "graph_depth": node.graph_depth
        }
    
    # å†™å…¥JSONæ–‡ä»¶
    with json_path.open('w', encoding='utf-8') as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)


def _aggregate_to_packages_new(nodes, edges):
    """æ–°ç‰ˆçš„åŒ…èšåˆå‡½æ•°"""
    from .node_types import NodeInfo, NodeType
    
    # æŒ‰åŒ…åèšåˆ
    def pkg_of(mod: str) -> str:
        return mod if "." not in mod else mod.rsplit(".", 1)[0]

    pkg_nodes = {}
    for node_name, node in nodes.items():
        pkg_name = pkg_of(node_name)
        if pkg_name not in pkg_nodes:
            # åˆ›å»ºåŒ…èŠ‚ç‚¹
            pkg_nodes[pkg_name] = NodeInfo(
                name=pkg_name,
                node_type=NodeType.PACKAGE,
                file_path=node.file_path  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾„
            )
        
        # èšåˆç»Ÿè®¡æ•°æ®
        pkg_node = pkg_nodes[pkg_name]
        pkg_node.functions.extend(node.functions)
        for class_name, methods in node.classes.items():
            if class_name not in pkg_node.classes:
                pkg_node.classes[class_name] = []
            pkg_node.classes[class_name].extend(methods)
        pkg_node.imports.update(node.imports)
        
        # é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        pkg_node.__post_init__()

    # èšåˆè¾¹
    pkg_edges = set()
    for src, dst in edges:
        src_pkg, dst_pkg = pkg_of(src), pkg_of(dst)
        if src_pkg != dst_pkg:
            pkg_edges.add((src_pkg, dst_pkg))
    
    return pkg_nodes, pkg_edges


def _print_project_summary(project_data, root: str) -> None:
    """æ‰“å°é¡¹ç›®æ‘˜è¦ä¿¡æ¯"""
    total_funcs = sum(node.functions_total for node in project_data.nodes.values())
    total_public = sum(node.functions_public for node in project_data.nodes.values())
    total_stubs = sum(node.stubs for node in project_data.nodes.values())
    ratio = (total_stubs / total_public) if total_public else 0.0

    print("\n== CodeClinic v0.1.3a1 é¡¹ç›®åˆ†ææ‘˜è¦ ==")
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {root}")
    print(f"ğŸ“Š èŠ‚ç‚¹ç»Ÿè®¡: {len(project_data.nodes)} ä¸ª "
          f"({len(project_data.modules)} modules + {len(project_data.packages)} packages)")
    print(f"ğŸ”— å…³ç³»ç»Ÿè®¡: {len(project_data.import_edges)} ä¸ªå¯¼å…¥å…³ç³», "
          f"{len(project_data.child_edges)} ä¸ªåŒ…å«å…³ç³»")
    print(f"âš™ï¸  å‡½æ•°ç»Ÿè®¡: {total_public}/{total_funcs} (å…¬å…±/æ€»è®¡)")
    print(f"ğŸš§ Stubç»Ÿè®¡: {total_stubs} ä¸ªstub ({ratio:.1%})")

    # æ˜¾ç¤ºå¯¼å…¥å…³ç³»ï¼ˆç®€åŒ–ï¼‰
    if len(project_data.import_edges) <= 20:  # åªåœ¨è¾¹æ•°è¾ƒå°‘æ—¶æ˜¾ç¤º
        adj = defaultdict(set)
        for s, d in project_data.import_edges:
            adj[s].add(d)
        print(f"\nğŸ“ˆ å¯¼å…¥å…³ç³»å›¾:")
        for src in sorted(list(adj.keys())[:10]):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            src_display = _get_display_name(src)
            target_names = [_get_display_name(t) for t in sorted(list(adj[src])[:3])]
            targets = ", ".join(target_names)  # æ¯ä¸ªæœ€å¤šæ˜¾ç¤º3ä¸ªç›®æ ‡
            if len(adj[src]) > 3:
                targets += f" (+{len(adj[src])-3} more)"
            print(f"  {src_display} -> {targets}")
        if len(adj) > 10:
            print(f"  ... (+{len(adj)-10} more nodes)")


def _get_display_name(full_name: str) -> str:
    """è·å–ç”¨äºæ˜¾ç¤ºçš„ç®€åŒ–åç§°ï¼ˆåªæ˜¾ç¤ºæœ€åä¸€çº§ï¼‰"""
    if not full_name:
        return "root"
    return full_name.split('.')[-1]


def _print_final_summary(violations_data, stub_data, output_dir: Path) -> None:
    """æ‰“å°æœ€ç»ˆåˆ†ææ‘˜è¦"""
    print(f"\nğŸ“‹ === åˆ†æå®Œæˆ ===")
    
    # è¿è§„æ‘˜è¦ - ä»violationsè®¡ç®—
    total_violations = len(violations_data["violations"])
    
    # æŒ‰ç±»å‹ç»Ÿè®¡è¿è§„
    violations_by_type = {}
    for v in violations_data["violations"]:
        vtype = v.violation_type  # ImportViolationå¯¹è±¡çš„å±æ€§
        violations_by_type[vtype] = violations_by_type.get(vtype, 0) + 1
    
    # è®¡ç®—åˆè§„ç‡éœ€è¦è·å–æ€»è¾¹æ•°ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
    print(f"ğŸš¨ å¯¼å…¥åˆè§„æ€§: {total_violations} ä¸ªè¿è§„")
    
    if total_violations > 0:
        for vtype, count in violations_by_type.items():
            print(f"   - {vtype}: {count} ä¸ª")
    
    # Stubæ‘˜è¦ - ä»stub_functionsè®¡ç®—
    total_stubs = len(stub_data["stub_functions"])
    # ä»stub_functionsç»Ÿè®¡æ€»å‡½æ•°æ•°ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
    print(f"ğŸš§ å®ç°å®Œæ•´åº¦: {total_stubs} ä¸ªstubå‡½æ•°")
    
    # è¾“å‡ºæ–‡ä»¶æ‘˜è¦
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   ğŸ“„ data.json - å®Œæ•´é¡¹ç›®æ•°æ®")
    print(f"   ğŸ“‚ import_violations/ - å¯¼å…¥è¿è§„åˆ†æ")
    print(f"   ğŸ“‚ stub_completeness/ - å®ç°å®Œæ•´åº¦åˆ†æ")
    
    print(f"\nğŸ‰ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {output_dir.absolute()}")


def _run_legacy_analysis(args):
    """è¿è¡Œæ—§ç‰ˆåˆ†ææµç¨‹ï¼Œä¿æŒå‘åå…¼å®¹"""
    print("ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿåˆ†ææ¨¡å¼...")
    
    # åŠ è½½æ—§ç‰ˆé…ç½®
    cfg = Config.from_files(os.getcwd())
    cfg.paths = [args.path] if args.path else cfg.paths
    if args.out:
        cfg.output = args.out
    if args.format:
        cfg.format = args.format
    if args.aggregate:
        cfg.aggregate = args.aggregate
    if args.count_private:
        cfg.count_private = True

    modules, edges, child_edges, stub_functions = scan_project(cfg.paths, cfg.include, cfg.exclude, cfg.count_private)

    if cfg.aggregate == "package":
        modules, edges = _aggregate_to_packages(modules, edges)

    _print_summary(modules, edges, child_edges, root=args.path)

    # Create output directory
    output_dir = Path(cfg.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nOutput directory: {output_dir.absolute()}")

    # Always generate JSON output
    json_path = save_json_output(modules, edges, child_edges, args.path, output_dir / "analysis.json")
    print(f"âœ“ JSON analysis saved to: {json_path}")
    
    # Generate stub function report
    if stub_functions:
        stub_report_path = save_legacy_stub_report(stub_functions, edges, args.path, output_dir / "stub_report.json")
        print(f"âœ“ Stub function report saved to: {stub_report_path}")
    else:
        print("âœ“ No stub functions found in project")

    # Always generate visualization
    graph_base = output_dir / "dependency_graph"
    dot_path, viz_path = render_graph(modules, edges, child_edges, str(graph_base), cfg.format)
    print(f"âœ“ DOT file saved to: {dot_path}")
    if viz_path:
        print(f"âœ“ Visualization saved to: {viz_path}")
    else:
        print("âš  Graphviz 'dot' executable not found. Install Graphviz to render visualizations (DOT file still created).")
    
    print(f"\nğŸ“ All results saved in: {output_dir.absolute()}")


def _aggregate_to_packages(modules, edges):
    # map module -> package (drop last segment)
    def pkg_of(mod: str) -> str:
        return mod if "." not in mod else mod.rsplit(".", 1)[0]

    pkg_stats: Modules = {}
    for m, st in modules.items():
        p = pkg_of(m)
        acc = pkg_stats.get(p)
        if not acc:
            acc = ModuleStats(name=p, file=st.file, functions_total=0, functions_public=0, stubs=0)
            pkg_stats[p] = acc
        acc.functions_total += st.functions_total
        acc.functions_public += st.functions_public
        acc.stubs += st.stubs

    pkg_edges: GraphEdges = set()
    for src, dst in edges:
        s, d = pkg_of(src), pkg_of(dst)
        if s != d:
            pkg_edges.add((s, d))
    return pkg_stats, pkg_edges


def _print_summary(modules, edges, child_edges, root: str) -> None:
    total_funcs = sum(m.functions_total for m in modules.values())
    total_public = sum(m.functions_public for m in modules.values())
    total_stubs = sum(m.stubs for m in modules.values())
    ratio = (total_stubs / total_public) if total_public else 0.0

    print("\n== CodeXray summary ==")
    print(f"root: {root}")
    print(f"nodes: {len(modules)}  edges: {len(edges)}  child edges: {len(child_edges)}")
    print(f"functions(public/total): {total_public}/{total_funcs}")
    print(f"stubs: {total_stubs}  ratio: {ratio:.1%}")

    # Adjacency list (brief)
    adj = defaultdict(set)
    for s, d in edges:
        adj[s].add(d)
    print("\nImport graph (adjacency):")
    for src in sorted(adj.keys()):
        targets = ", ".join(sorted(adj[src]))
        print(f" - {src} -> {targets}")
    
    # Child relationships
    if child_edges:
        child_adj = defaultdict(set)
        for parent, child in child_edges:
            child_adj[parent].add(child)
        print("\nParent-child relationships:")
        for parent in sorted(child_adj.keys()):
            children = ", ".join(sorted(child_adj[parent]))
            print(f" - {parent} contains {children}")


def cli_main():
    """Entry point for CLI tool when installed via pip."""
    main()


if __name__ == "__main__":
    main()