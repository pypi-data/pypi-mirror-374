"""empty message

Revision ID: 172715eae700
Revises: 8d99f2f348fc
Create Date: 2025-08-20 18:20:04.711323

"""

from __future__ import annotations

import traceback
from typing import Text
import sqlalchemy as sa
from alembic import context, op
from edgy import monkay, run_sync
from sqlalchemy.dialects import postgresql
from sqlalchemy.dialects import sqlite

# revision identifiers, used by Alembic.
revision = "172715eae700"
down_revision = "8d99f2f348fc"
branch_labels = None
depends_on = None


def hash_to_identifier(key: str | bytes) -> str:
    from base64 import b32encode
    from hashlib import blake2b

    if isinstance(key, str):
        key = key.encode()
    return f"_{b32encode(blake2b(key, digest_size=16).digest()).decode().rstrip('=')}"


force_fields_nullable: list[tuple[str, str]] = []


def upgrade(engine_name: str = "") -> None:
    # hash_to_identifier adds already an "_"
    fn = globals().get(f"upgrade{hash_to_identifier(engine_name)}")
    if fn is not None:
        fn()


def downgrade(engine_name: str = "") -> None:
    # hash_to_identifier adds already an "_"
    fn = globals().get(f"downgrade{hash_to_identifier(engine_name)}")
    if fn is not None:
        fn()


def upgrade_ZLTGSQOZ566UATSNRB2Y5JTWOA():
    # Migration of:
    # main database
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("auths", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column(
                "my_file", sa.String(length=255), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "my_file_storage",
                sa.String(length=20),
                server_default=sa.text("('')"),
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "my_image", sa.String(length=255), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "my_image_storage",
                sa.String(length=20),
                server_default=sa.text("('')"),
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "my_image_size", sa.BigInteger(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "my_image_ok",
                sa.Boolean(),
                server_default=sa.text("(false)"),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "my_image_mname",
                sa.JSON()
                .with_variant(postgresql.JSONB(astext_type=Text()), "postgres")
                .with_variant(postgresql.JSONB(astext_type=Text()), "postgresql"),
                server_default=sa.text("'{}'"),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "my_file_size", sa.BigInteger(), autoincrement=False, nullable=False
            )
        )
        batch_op.add_column(
            sa.Column(
                "my_file_mname",
                sa.JSON()
                .with_variant(postgresql.JSONB(astext_type=Text()), "postgres")
                .with_variant(postgresql.JSONB(astext_type=Text()), "postgresql"),
                server_default=sa.text("'{}'"),
                autoincrement=False,
                nullable=False,
            )
        )
        batch_op.drop_column("file")
        batch_op.drop_column("file_storage")
        batch_op.drop_column("image_mname")
        batch_op.drop_column("image")
        batch_op.drop_column("image_size")
        batch_op.drop_column("file_mname")
        batch_op.drop_column("image_storage")
        batch_op.drop_column("image_ok")
        batch_op.drop_column("file_size")

    with op.batch_alter_table("users", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column("parent", sa.Uuid(), autoincrement=False, nullable=False)
        )
        batch_op.create_foreign_key(
            "fk_users_users_parent",
            "users",
            ["parent"],
            ["id"],
            onupdate="CASCADE",
            ondelete="RESTRICT",
        )

    # ### end Alembic commands ###
    if not context.is_offline_mode():
        try:
            with monkay.instance.registry.with_async_env():
                run_sync(
                    monkay.instance.registry.apply_default_force_nullable_fields(
                        force_fields_nullable=force_fields_nullable,
                        filter_db_name="",
                        model_defaults={},
                    )
                )
        except Exception as exc:
            print("failure migrating defaults", exc)
            traceback.print_exception(exc)


def downgrade_ZLTGSQOZ566UATSNRB2Y5JTWOA():
    # Migration of:
    # main database
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("users", schema=None) as batch_op:
        batch_op.drop_constraint("fk_users_users_parent", type_="foreignkey")
        batch_op.drop_column("parent")

    with op.batch_alter_table("auths", schema=None) as batch_op:
        batch_op.add_column(sa.Column("file_size", sa.BIGINT(), nullable=False))
        batch_op.add_column(
            sa.Column(
                "image_ok",
                sa.BOOLEAN(),
                server_default=sa.text("(false)"),
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "image_storage",
                sa.VARCHAR(length=20),
                server_default=sa.text("('')"),
                nullable=True,
            )
        )
        batch_op.add_column(
            sa.Column(
                "file_mname",
                sqlite.JSON(),
                server_default=sa.text("'{}'"),
                nullable=False,
            )
        )
        batch_op.add_column(sa.Column("image_size", sa.BIGINT(), nullable=False))
        batch_op.add_column(sa.Column("image", sa.VARCHAR(length=255), nullable=False))
        batch_op.add_column(
            sa.Column(
                "image_mname",
                sqlite.JSON(),
                server_default=sa.text("'{}'"),
                nullable=False,
            )
        )
        batch_op.add_column(
            sa.Column(
                "file_storage",
                sa.VARCHAR(length=20),
                server_default=sa.text("('')"),
                nullable=True,
            )
        )
        batch_op.add_column(sa.Column("file", sa.VARCHAR(length=255), nullable=False))
        batch_op.drop_column("my_file_mname")
        batch_op.drop_column("my_file_size")
        batch_op.drop_column("my_image_mname")
        batch_op.drop_column("my_image_ok")
        batch_op.drop_column("my_image_size")
        batch_op.drop_column("my_image_storage")
        batch_op.drop_column("my_image")
        batch_op.drop_column("my_file_storage")
        batch_op.drop_column("my_file")

    # ### end Alembic commands ###
