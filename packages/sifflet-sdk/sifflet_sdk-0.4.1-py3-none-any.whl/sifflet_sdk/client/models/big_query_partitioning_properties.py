# coding: utf-8

"""
    Sifflet Backend API

    Requirements: <br>    - [Create your access token through the UI](https://docs.siffletdata.com/docs/generate-an-api-token#create-an-api-token) <br>    - Get your tenant name: if you access to Sifflet with `https://abcdef.siffletdata.com`, then your tenant would be `abcdef`

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations

import json
import pprint
import re  # noqa: F401
from importlib import import_module
from typing import TYPE_CHECKING, Any, ClassVar, Dict, List, Optional, Set, Union

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing_extensions import Self

if TYPE_CHECKING:
    from sifflet_sdk.client.models.big_query_ingestion_time_partitioning_properties import (
        BigQueryIngestionTimePartitioningProperties,
    )
    from sifflet_sdk.client.models.big_query_integer_range_partitioning_properties import (
        BigQueryIntegerRangePartitioningProperties,
    )
    from sifflet_sdk.client.models.big_query_time_unit_column_partitioning_properties import (
        BigQueryTimeUnitColumnPartitioningProperties,
    )
    from sifflet_sdk.client.models.default_partitioning import DefaultPartitioning


class BigQueryPartitioningProperties(BaseModel):
    """
    BigQueryPartitioningProperties
    """  # noqa: E501

    partitioning_type: StrictStr = Field(alias="partitioningType")
    __properties: ClassVar[List[str]] = ["partitioningType"]

    @field_validator("partitioning_type")
    def partitioning_type_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(["INTEGER_RANGE", "TIME_UNIT_COLUMN", "INGESTION_TIME", "NO_PARTITIONING"]):
            raise ValueError(
                "must be one of enum values ('INTEGER_RANGE', 'TIME_UNIT_COLUMN', 'INGESTION_TIME', 'NO_PARTITIONING')"
            )
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    # JSON field name that stores the object type
    __discriminator_property_name: ClassVar[str] = "partitioningType"

    # discriminator mappings
    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
        "INGESTION_TIME": "BigQueryIngestionTimePartitioningProperties",
        "INTEGER_RANGE": "BigQueryIntegerRangePartitioningProperties",
        "NO_PARTITIONING": "DefaultPartitioning",
        "TIME_UNIT_COLUMN": "BigQueryTimeUnitColumnPartitioningProperties",
    }

    @classmethod
    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
        """Returns the discriminator value (object type) of the data"""
        discriminator_value = obj[cls.__discriminator_property_name]
        if discriminator_value:
            return cls.__discriminator_value_class_map.get(discriminator_value)
        else:
            return None

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[
        Union[
            BigQueryIngestionTimePartitioningProperties,
            BigQueryIntegerRangePartitioningProperties,
            DefaultPartitioning,
            BigQueryTimeUnitColumnPartitioningProperties,
        ]
    ]:
        """Create an instance of BigQueryPartitioningProperties from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict[str, Any]) -> Optional[
        Union[
            BigQueryIngestionTimePartitioningProperties,
            BigQueryIntegerRangePartitioningProperties,
            DefaultPartitioning,
            BigQueryTimeUnitColumnPartitioningProperties,
        ]
    ]:
        """Create an instance of BigQueryPartitioningProperties from a dict"""
        # look up the object type based on discriminator mapping
        object_type = cls.get_discriminator_value(obj)
        if object_type == "BigQueryIngestionTimePartitioningProperties":
            return import_module(
                "sifflet_sdk.client.models.big_query_ingestion_time_partitioning_properties"
            ).BigQueryIngestionTimePartitioningProperties.from_dict(obj)
        if object_type == "BigQueryIntegerRangePartitioningProperties":
            return import_module(
                "sifflet_sdk.client.models.big_query_integer_range_partitioning_properties"
            ).BigQueryIntegerRangePartitioningProperties.from_dict(obj)
        if object_type == "DefaultPartitioning":
            return import_module("sifflet_sdk.client.models.default_partitioning").DefaultPartitioning.from_dict(obj)
        if object_type == "BigQueryTimeUnitColumnPartitioningProperties":
            return import_module(
                "sifflet_sdk.client.models.big_query_time_unit_column_partitioning_properties"
            ).BigQueryTimeUnitColumnPartitioningProperties.from_dict(obj)

        raise ValueError(
            "BigQueryPartitioningProperties failed to lookup discriminator value from "
            + json.dumps(obj)
            + ". Discriminator property name: "
            + cls.__discriminator_property_name
            + ", mapping: "
            + json.dumps(cls.__discriminator_value_class_map)
        )
