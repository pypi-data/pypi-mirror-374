# coding: utf-8

"""
    Sifflet Backend API

    Requirements: <br>    - [Create your access token through the UI](https://docs.siffletdata.com/docs/generate-an-api-token#create-an-api-token) <br>    - Get your tenant name: if you access to Sifflet with `https://abcdef.siffletdata.com`, then your tenant would be `abcdef`

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations

import json
import pprint
import re  # noqa: F401
from typing import Any, ClassVar, Dict, List, Optional, Set

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from sifflet_sdk.client.models.description_dto import DescriptionDto
from typing_extensions import Self


class FieldLevelSearchFieldDto(BaseModel):
    """
    FieldLevelSearchFieldDto
    """  # noqa: E501

    description: Optional[StrictStr] = None
    entity_type: StrictStr = Field(alias="entityType")
    external_descriptions: Optional[List[DescriptionDto]] = Field(default=None, alias="externalDescriptions")
    name: StrictStr
    __properties: ClassVar[List[str]] = ["description", "entityType", "externalDescriptions", "name"]

    @field_validator("entity_type")
    def entity_type_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(
            [
                "INTEGRATION",
                "DATASOURCE",
                "DATASOURCE_USAGE",
                "DATASOURCE_INGESTION_RUN",
                "DATASET",
                "DASHBOARD",
                "CHART",
                "COLLECTION",
                "DATASET_FIELD",
                "DAG",
                "DAG_RUN",
                "TRANSFORMATION",
                "TRANSFORMATION_RUN",
                "RULE_RUN",
                "RULE_EXECUTION_SUMMARY",
                "INCIDENT",
                "USER",
                "ACCESS_TOKEN",
                "SIFFLET_RULE",
                "CONFIG",
                "TAG",
                "DOMAIN",
                "ALERTING_HOOK",
                "RULE_MONITORING_RECOMMENDATION",
                "DATAPOINT_QUALIFICATION",
                "DECLARED_ASSET",
                "DECLARED_ASSET_PROPERTIES",
                "WEBHOOK",
                "SIFFLET_AGENT",
                "SIFFLET_AGENT_JOB",
                "SIFFLET_AGENT_DATASOURCE_JOB",
                "SIFFLET_AGENT_DEBUG_JOB",
                "AI_METADATA_PREDICTION",
                "CUSTOM_METADATA",
                "CUSTOM_METADATA_ENTRY",
                "DATA_PRODUCT",
                "METRIC",
                "ASSET_UPDATE_HISTORY_ENTITY",
                "ASSET_USAGE",
                "ASSET_USAGE_HISTORY_RECORD",
                "SAML_REQUEST",
                "SINGLE_USE_TOKEN",
                "FORMATTED_DESCRIPTION",
                "RULE_ROOT_CAUSE_ANALYSIS_RUN",
                "AS_CODE_WORKSPACE",
                "ALERT",
                "SIFFLET_RULE_MODEL_PARAMETERS",
                "CALENDAR",
                "CONNECTION",
                "METADATA_JOB",
                "DATASET_MODEL_PARAMETERS",
                "COLLABORATION_TOOL_ITEM",
                "DBT_IMPACT_ANALYSIS_RUN",
                "INGESTION_STATEMENT_CACHE",
                "LINEAGE",
                "MUTATION_LINK",
                "UPSTREAM_STATE",
            ]
        ):
            raise ValueError(
                "must be one of enum values ('INTEGRATION', 'DATASOURCE', 'DATASOURCE_USAGE', 'DATASOURCE_INGESTION_RUN', 'DATASET', 'DASHBOARD', 'CHART', 'COLLECTION', 'DATASET_FIELD', 'DAG', 'DAG_RUN', 'TRANSFORMATION', 'TRANSFORMATION_RUN', 'RULE_RUN', 'RULE_EXECUTION_SUMMARY', 'INCIDENT', 'USER', 'ACCESS_TOKEN', 'SIFFLET_RULE', 'CONFIG', 'TAG', 'DOMAIN', 'ALERTING_HOOK', 'RULE_MONITORING_RECOMMENDATION', 'DATAPOINT_QUALIFICATION', 'DECLARED_ASSET', 'DECLARED_ASSET_PROPERTIES', 'WEBHOOK', 'SIFFLET_AGENT', 'SIFFLET_AGENT_JOB', 'SIFFLET_AGENT_DATASOURCE_JOB', 'SIFFLET_AGENT_DEBUG_JOB', 'AI_METADATA_PREDICTION', 'CUSTOM_METADATA', 'CUSTOM_METADATA_ENTRY', 'DATA_PRODUCT', 'METRIC', 'ASSET_UPDATE_HISTORY_ENTITY', 'ASSET_USAGE', 'ASSET_USAGE_HISTORY_RECORD', 'SAML_REQUEST', 'SINGLE_USE_TOKEN', 'FORMATTED_DESCRIPTION', 'RULE_ROOT_CAUSE_ANALYSIS_RUN', 'AS_CODE_WORKSPACE', 'ALERT', 'SIFFLET_RULE_MODEL_PARAMETERS', 'CALENDAR', 'CONNECTION', 'METADATA_JOB', 'DATASET_MODEL_PARAMETERS', 'COLLABORATION_TOOL_ITEM', 'DBT_IMPACT_ANALYSIS_RUN', 'INGESTION_STATEMENT_CACHE', 'LINEAGE', 'MUTATION_LINK', 'UPSTREAM_STATE')"
            )
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of FieldLevelSearchFieldDto from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in external_descriptions (list)
        _items = []
        if self.external_descriptions:
            for _item_external_descriptions in self.external_descriptions:
                if _item_external_descriptions:
                    _items.append(_item_external_descriptions.to_dict())
            _dict["externalDescriptions"] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of FieldLevelSearchFieldDto from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "description": obj.get("description"),
                "entityType": obj.get("entityType"),
                "externalDescriptions": (
                    [DescriptionDto.from_dict(_item) for _item in obj["externalDescriptions"]]
                    if obj.get("externalDescriptions") is not None
                    else None
                ),
                "name": obj.get("name"),
            }
        )
        return _obj
