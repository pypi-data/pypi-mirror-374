"""
=========================================================

Author: Benedict Chen (benedict@benedictchen.com)
Based on: Comprehensive fake code audit - implementing ALL identified solutions

üöÄ RESEARCH FOUNDATION:
======================
This implements ALL configuration options for the missing DeepESN and OnlineESN
implementations that were identified as fake code with only `pass` statements.

üìö **Research Basis**:
- Jaeger (2001) "The 'Echo State' approach to analyzing RNNs"
- Gallicchio & Micheli (2017) "Deep Echo State Networks"  
- Jaeger & Haas (2004) "Harnessing nonlinearity: Predicting chaotic systems"
- Luko≈°eviƒçius (2012) "A practical guide to applying echo state networks"
- Jaeger (2007) "Echo state network"

```
Solution A: Deep Echo State Network
‚îú‚îÄ‚îÄ Multiple reservoir layers  
‚îú‚îÄ‚îÄ Hierarchical information processing
‚îú‚îÄ‚îÄ Inter-layer connectivity options
‚îî‚îÄ‚îÄ Layer-specific spectral radius control

Solution B: Online Echo State Network  
‚îú‚îÄ‚îÄ Recursive Least Squares (RLS) training
‚îú‚îÄ‚îÄ Real-time adaptation capabilities
‚îú‚îÄ‚îÄ Forgetting factor for non-stationary data
‚îî‚îÄ‚îÄ Incremental learning with memory management

Solution C: Advanced ESN Variants
‚îú‚îÄ‚îÄ Leaky integrator neurons  
‚îú‚îÄ‚îÄ Bidirectional reservoirs
‚îú‚îÄ‚îÄ Ring topology reservoirs
‚îî‚îÄ‚îÄ Multi-scale temporal processing

Solution D: Hyperparameter Optimization
‚îú‚îÄ‚îÄ Bayesian optimization of spectral radius
‚îú‚îÄ‚îÄ Grid search for reservoir size
‚îú‚îÄ‚îÄ Cross-validation based selection
‚îî‚îÄ‚îÄ Performance-guided parameter tuning

Solution E: Task-Specific ESN Factory
‚îú‚îÄ‚îÄ Time series prediction optimized ESN
‚îú‚îÄ‚îÄ Classification optimized ESN  
‚îú‚îÄ‚îÄ Control task optimized ESN
‚îî‚îÄ‚îÄ Chaotic system prediction ESN
```

üíé **USER CHOICE**: Complete configuration system allowing selection of:
- ESN architecture (standard, deep, online, bidirectional)
- Training method (ridge regression, RLS, pseudo-inverse) 
- Reservoir topology (random, small-world, scale-free)
- Neuron dynamics (standard, leaky integrator, spiking)
- Optimization strategy (manual, grid search, Bayesian)

üéØ **BACKWARD COMPATIBILITY**: All original ESN functionality preserved
"""

from enum import Enum
from typing import Dict, List, Optional, Union, Tuple, Any, Callable
from dataclasses import dataclass, field
import numpy as np


class ESNArchitecture(Enum):
    """ESN architecture variants - ALL identified solutions"""
    STANDARD = "standard"                    # Basic ESN (Jaeger 2001)
    DEEP = "deep"                           # Deep ESN with multiple layers
    ONLINE = "online"                       # Online RLS-trained ESN
    BIDIRECTIONAL = "bidirectional"         # Forward + backward reservoirs
    HIERARCHICAL = "hierarchical"           # Multi-timescale processing
    ENSEMBLE = "ensemble"                   # Multiple ESN combination


class TrainingMethod(Enum):
    """Training method options"""
    RIDGE_REGRESSION = "ridge_regression"   # L2 regularized least squares
    PSEUDO_INVERSE = "pseudo_inverse"       # Moore-Penrose inverse
    RLS_ONLINE = "rls_online"              # Recursive Least Squares
    LASSO = "lasso"                        # L1 regularized
    ELASTIC_NET = "elastic_net"            # L1 + L2 regularized
    BAYESIAN_RIDGE = "bayesian_ridge"      # Bayesian approach


class ReservoirTopology(Enum):
    """Reservoir connection topology"""
    RANDOM = "random"                       # Random sparse connections
    SMALL_WORLD = "small_world"            # Watts-Strogatz small-world
    SCALE_FREE = "scale_free"              # Barab√°si-Albert scale-free
    RING = "ring"                          # Ring topology
    LATTICE = "lattice"                    # 2D lattice structure
    ERDOS_RENYI = "erdos_renyi"           # Erd≈ës-R√©nyi random graph


class NeuronDynamics(Enum):
    """Neuron activation dynamics"""
    STANDARD = "standard"                   # tanh activation
    LEAKY_INTEGRATOR = "leaky_integrator"  # Leaky integrator neurons
    SPIKING = "spiking"                    # Spiking neuron model
    RELU = "relu"                          # ReLU activation
    SIGMOID = "sigmoid"                    # Sigmoid activation
    LINEAR = "linear"                      # Linear activation


class OptimizationStrategy(Enum):
    """Hyperparameter optimization strategy"""
    MANUAL = "manual"                       # User-specified parameters
    GRID_SEARCH = "grid_search"            # Exhaustive grid search
    RANDOM_SEARCH = "random_search"        # Random parameter sampling
    BAYESIAN = "bayesian"                  # Bayesian optimization
    EVOLUTIONARY = "evolutionary"          # Genetic algorithm
    AUTO = "auto"                          # Automatic strategy selection


@dataclass
class DeepESNConfig:
    """Configuration for Deep Echo State Networks"""
    num_layers: int = 3                     # Number of reservoir layers
    layer_sizes: Optional[List[int]] = None # Size of each layer
    spectral_radii: Optional[List[float]] = None  # Spectral radius per layer
    inter_layer_scaling: float = 0.1       # Scaling for inter-layer connections
    skip_connections: bool = True           # Direct input-to-layer connections
    layer_activation: List[str] = field(default_factory=lambda: ["tanh"])
    hierarchical_timescales: bool = True    # Different timescales per layer


@dataclass  
class OnlineESNConfig:
    """Configuration for Online Echo State Networks"""
    rls_forgetting_factor: float = 0.999    # RLS forgetting factor (0 < Œª ‚â§ 1)
    initial_covariance: float = 1000.0      # Initial P matrix scaling
    adaptation_rate: str = "constant"       # 'constant', 'decreasing', 'adaptive'
    memory_management: bool = True          # Automatic memory cleanup
    batch_size: int = 1                     # Online batch size
    warmup_samples: int = 100               # Samples before adaptation starts
    stability_monitoring: bool = True       # Monitor numerical stability


@dataclass
class ESNOptimizationConfig:
    """Configuration for ESN hyperparameter optimization"""
    optimize_spectral_radius: bool = True
    optimize_input_scaling: bool = True  
    optimize_bias_scaling: bool = True
    optimize_reservoir_size: bool = False   # Expensive - disable by default
    
    # Search ranges
    spectral_radius_range: Tuple[float, float] = (0.1, 1.2)
    input_scaling_range: Tuple[float, float] = (0.01, 2.0)
    bias_scaling_range: Tuple[float, float] = (0.0, 1.0)
    reservoir_size_range: Tuple[int, int] = (50, 500)
    
    # Optimization parameters
    n_trials: int = 50                      # Number of optimization trials
    cv_folds: int = 5                       # Cross-validation folds
    scoring_metric: str = "mse"             # 'mse', 'mae', 'r2', 'accuracy'
    early_stopping: bool = True             # Stop if no improvement
    patience: int = 10                      # Early stopping patience


@dataclass
class ESNConfig:
    """
    Complete ESN Configuration System
    
    üî¨ Provides ALL configuration options for implementing the missing
    DeepEchoStateNetwork and OnlineEchoStateNetwork classes that were
    identified as fake code with only `pass` statements.
    
    üíé USER CHOICE: Allows selection between ALL identified solutions
    """
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CORE ESN PARAMETERS (Standard ESN - preserved for compatibility)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    reservoir_size: int = 100               # Number of reservoir neurons
    spectral_radius: float = 0.95           # Largest eigenvalue magnitude
    input_scaling: float = 1.0              # Input weight scaling
    bias_scaling: float = 0.0               # Bias weight scaling  
    sparsity: float = 0.9                   # Fraction of zero connections
    random_state: Optional[int] = None      # Random seed for reproducibility
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ARCHITECTURE SELECTION (Solution A: Deep ESN, Solution B: Online ESN)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    architecture: ESNArchitecture = ESNArchitecture.STANDARD
    
    # Deep ESN configuration (Solution A)
    deep_config: Optional[DeepESNConfig] = None
    
    # Online ESN configuration (Solution B) 
    online_config: Optional[OnlineESNConfig] = None
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ADVANCED ESN VARIANTS (Solution C)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    topology: ReservoirTopology = ReservoirTopology.RANDOM
    neuron_dynamics: NeuronDynamics = NeuronDynamics.STANDARD
    leaky_rate: Optional[float] = None      # For leaky integrator neurons
    bidirectional_mode: bool = False        # Enable bidirectional processing
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # TRAINING CONFIGURATION
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    training_method: TrainingMethod = TrainingMethod.RIDGE_REGRESSION
    regularization_strength: float = 1e-6   # L2 regularization parameter
    washout_length: int = 100               # Washout period length
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # HYPERPARAMETER OPTIMIZATION (Solution D)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    optimization_strategy: OptimizationStrategy = OptimizationStrategy.MANUAL
    optimization_config: Optional[ESNOptimizationConfig] = None
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # TASK-SPECIFIC CONFIGURATION (Solution E)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    task_type: str = "regression"           # 'regression', 'classification', 'control'
    target_dimension: int = 1               # Output dimension
    input_dimension: Optional[int] = None   # Auto-detected if None
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ADVANCED FEATURES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    enable_feedback: bool = False           # Output feedback to reservoir
    feedback_scaling: float = 0.1           # Feedback connection scaling
    noise_level: float = 0.0                # Reservoir noise level
    
    # Performance and numerical stability
    enable_gpu: bool = False                # GPU acceleration if available
    numerical_precision: str = "float64"    # 'float32' or 'float64'
    stability_check: bool = True            # Check Echo State Property
    
    # Legacy compatibility
    legacy_compatibility: bool = True       # Maintain backward compatibility
    legacy_warnings: bool = True            # Warn about deprecated usage

    def __post_init__(self):
        """Post-initialization validation and setup"""
        # Initialize default deep config if deep architecture selected
        if self.architecture == ESNArchitecture.DEEP and self.deep_config is None:
            self.deep_config = DeepESNConfig()
            
        # Initialize default online config if online architecture selected  
        if self.architecture == ESNArchitecture.ONLINE and self.online_config is None:
            self.online_config = OnlineESNConfig()
            
        # Initialize default optimization config if optimization enabled
        if (self.optimization_strategy != OptimizationStrategy.MANUAL and 
            self.optimization_config is None):
            self.optimization_config = ESNOptimizationConfig()
            
        # Validate configuration consistency
        validation = self.validate_config()
        if not validation['valid']:
            raise ValueError(f"Invalid ESN configuration: {validation['issues']}")

    def validate_config(self) -> Dict[str, Any]:
        """
        Validate configuration for consistency and correctness
        
        Returns:
            Dict with validation results and warnings
        """
        issues = []
        warnings = []
        
        # Core parameter validation
        if self.reservoir_size <= 0:
            issues.append("Reservoir size must be positive")
            
        if not 0 < self.spectral_radius <= 1.5:
            warnings.append("Spectral radius outside typical range [0.1, 1.2]")
            
        if self.sparsity < 0 or self.sparsity >= 1:
            issues.append("Sparsity must be in [0, 1)")
            
        # Architecture-specific validation
        if self.architecture == ESNArchitecture.DEEP:
            if self.deep_config is None:
                issues.append("Deep config required for deep architecture")
            elif self.deep_config.num_layers < 2:
                issues.append("Deep ESN requires at least 2 layers")
                
        if self.architecture == ESNArchitecture.ONLINE:
            if self.online_config is None:
                issues.append("Online config required for online architecture")
            elif not 0 < self.online_config.rls_forgetting_factor <= 1:
                issues.append("RLS forgetting factor must be in (0, 1]")
        
        # Training method compatibility
        if (self.architecture == ESNArchitecture.ONLINE and 
            self.training_method != TrainingMethod.RLS_ONLINE):
            warnings.append("Online ESN typically uses RLS training")
            
        # Optimization validation
        if (self.optimization_strategy != OptimizationStrategy.MANUAL and 
            self.optimization_config is None):
            issues.append("Optimization config required for non-manual optimization")
            
        return {
            'valid': len(issues) == 0,
            'issues': issues,
            'warnings': warnings
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# FACTORY FUNCTIONS FOR COMMON CONFIGURATIONS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def create_standard_esn_config(**kwargs) -> ESNConfig:
    """Create standard ESN configuration (Jaeger 2001)"""
    defaults = {
        'architecture': ESNArchitecture.STANDARD,
        'reservoir_size': 100,
        'spectral_radius': 0.95,
        'input_scaling': 1.0,
        'training_method': TrainingMethod.RIDGE_REGRESSION
    }
    defaults.update(kwargs)
    return ESNConfig(**defaults)


def create_deep_esn_config(num_layers: int = 3, **kwargs) -> ESNConfig:
    """Create Deep ESN configuration (Solution A)"""
    deep_config = DeepESNConfig(
        num_layers=num_layers,
        layer_sizes=kwargs.pop('layer_sizes', None),
        spectral_radii=kwargs.pop('spectral_radii', None)
    )
    
    defaults = {
        'architecture': ESNArchitecture.DEEP,
        'deep_config': deep_config,
        'reservoir_size': 100,  # Size of each layer if layer_sizes not specified
        'spectral_radius': 0.95
    }
    defaults.update(kwargs)
    return ESNConfig(**defaults)


def create_online_esn_config(forgetting_factor: float = 0.999, **kwargs) -> ESNConfig:
    """Create Online ESN configuration (Solution B)"""
    online_config = OnlineESNConfig(
        rls_forgetting_factor=forgetting_factor,
        initial_covariance=kwargs.pop('initial_covariance', 1000.0),
        adaptation_rate=kwargs.pop('adaptation_rate', 'constant')
    )
    
    defaults = {
        'architecture': ESNArchitecture.ONLINE, 
        'online_config': online_config,
        'training_method': TrainingMethod.RLS_ONLINE,
        'reservoir_size': 100,
        'spectral_radius': 0.95
    }
    defaults.update(kwargs)
    return ESNConfig(**defaults)


def create_optimized_esn_config(strategy: str = 'bayesian', **kwargs) -> ESNConfig:
    """Create ESN with hyperparameter optimization (Solution D)"""
    opt_strategy = OptimizationStrategy(strategy)
    opt_config = ESNOptimizationConfig(
        n_trials=kwargs.pop('n_trials', 50),
        cv_folds=kwargs.pop('cv_folds', 5),
        scoring_metric=kwargs.pop('scoring_metric', 'mse')
    )
    
    defaults = {
        'optimization_strategy': opt_strategy,
        'optimization_config': opt_config,
        'reservoir_size': 100,
        'spectral_radius': 0.95
    }
    defaults.update(kwargs)
    return ESNConfig(**defaults)


def create_task_specific_esn_config(task: str = 'regression', **kwargs) -> ESNConfig:
    """Create task-optimized ESN configuration (Solution E)"""
    if task == 'time_series':
        defaults = {
            'reservoir_size': 200,
            'spectral_radius': 0.99,
            'input_scaling': 0.5,
            'leaky_rate': 0.1,
            'neuron_dynamics': NeuronDynamics.LEAKY_INTEGRATOR
        }
    elif task == 'classification':
        defaults = {
            'reservoir_size': 500,
            'spectral_radius': 0.9, 
            'input_scaling': 1.0,
            'training_method': TrainingMethod.RIDGE_REGRESSION,
            'regularization_strength': 1e-3
        }
    elif task == 'control':
        defaults = {
            'reservoir_size': 100,
            'spectral_radius': 0.8,
            'enable_feedback': True,
            'feedback_scaling': 0.1,
            'training_method': TrainingMethod.RLS_ONLINE
        }
    elif task == 'chaotic':
        defaults = {
            'reservoir_size': 1000,
            'spectral_radius': 1.2,  # Edge of chaos
            'topology': ReservoirTopology.SMALL_WORLD,
            'noise_level': 0.001
        }
    else:  # Default regression
        defaults = {
            'reservoir_size': 100,
            'spectral_radius': 0.95,
            'input_scaling': 1.0
        }
    
    defaults.update({'task_type': task})
    defaults.update(kwargs)
    return ESNConfig(**defaults)


def create_gpu_accelerated_esn_config(**kwargs) -> ESNConfig:
    """Create GPU-accelerated ESN configuration"""
    defaults = {
        'enable_gpu': True,
        'reservoir_size': 1000,  # Larger reservoir for GPU efficiency
        'numerical_precision': 'float32',  # GPU optimization
        'architecture': ESNArchitecture.DEEP,
        'deep_config': DeepESNConfig(num_layers=4)
    }
    defaults.update(kwargs)
    return ESNConfig(**defaults)