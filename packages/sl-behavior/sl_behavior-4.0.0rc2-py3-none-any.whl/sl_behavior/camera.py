"""This module provides the functions used to extract the frame acquisition timestamps from the .npz log archives
generated by behavior video cameras used in the Sun lab."""

from pathlib import Path
from multiprocessing import cpu_count
from concurrent.futures import ProcessPoolExecutor, as_completed

from tqdm import tqdm
from numba import njit, prange  # type: ignore
import numpy as np
import polars as pl
from numpy.typing import NDArray
from sl_shared_assets import (
    SessionData,
    SessionLock,
    SessionTypes,
    TrackerFileNames,
    ProcessingTracker,
    AcquisitionSystems,
    generate_project_manifest,
)
from ataraxis_base_utilities import LogLevel, console, chunk_iterable

# Defines session types and acquisition systems that support extracting video camera frames.
_supported_systems = {AcquisitionSystems.MESOSCOPE_VR}
_supported_sessions = {SessionTypes.LICK_TRAINING, SessionTypes.RUN_TRAINING, SessionTypes.MESOSCOPE_EXPERIMENT}


def _process_frame_message_batch(log_path: Path, file_names: list[str], onset_us: np.uint64) -> list[np.uint64]:
    """Processes the target batch of VideoSystem-generated messages stored in the .npz log file.

    This worker function is used by the _extract_camera_timestamps() function to process multiple message batches in
    parallel to speed up the overall camera timestamp data processing.

    Args:
        log_path: The path to the processed .npz log file.
        file_names: The names of the individual message .npy files stored in the target archive.
        onset_us: The onset of the frame data acquisition, in microseconds elapsed since UTC epoch onset.

    Returns:
        The list of frame acquisition timestamps for all frames whose messages have been processed as part of the
        batch, stored as microseconds since UTC epoch onset.
    """

    # Opens the processed log archive using memory mapping. If frame processing is performed in parallel, all processes
    # interact with the archive concurrently.
    with np.load(log_path, allow_pickle=False, fix_imports=False, mmap_mode="r") as archive:
        frame_timestamps = []

        # Loops over the batch of frame messages and extracts frame acquisition timestamps.
        for item in file_names:
            message = archive[item]

            # Frame timestamp messages do not have a payload, they only contain the source ID and the acquisition
            # timestamp. This gives them the length of 9 bytes.
            if len(message) == 9:
                # Extracts the number of microseconds elapsed since acquisition onset and uses it to calculate the
                # global timestamp for the message, in microseconds since UTC epoch onset.
                elapsed_microseconds = message[1:9].view(np.uint64).item()
                frame_timestamps.append(onset_us + elapsed_microseconds)

    return frame_timestamps


def _extract_camera_timestamps(
    log_path: Path,
    n_workers: int = -1,
) -> tuple[np.uint64, ...]:
    """Extracts the video camera frame acquisition timestamps from the target .npz log file generated by a VideoSystem
    instance during sl-experiment runtime.

    This worker function was copied from the ataraxis-video-system library and optimized to use multiprocessing to
    achieve a measurable speedup while processing large log files.

    Notes:
        If the target .npz archive contains fewer than 2000 messages, the processing is carried out sequentially
        regardless of the specified worker-count.

    Args:
        log_path: The path to the .npz log file that stores the logged data generated by the VideoSystem
            instance during runtime.
        n_workers: The number of parallel worker processes (CPU cores) to use for processing. Setting this to a value
            below 1 uses all available CPU cores. Setting this to a value of 1 conducts the processing sequentially.

    Returns:
        A tuple that stores the frame acquisition timestamps. Each timestamp is stored as the number of microseconds
        since the UTC epoch onset.

    Raises:
        ValueError: If the target .npz archive does not exist.
    """
    # Ensures that the target .npz log archive exists.
    if not log_path.exists() or log_path.suffix != ".npz" or not log_path.is_file():
        error_message = (
            f"Unable to extract camera frame timestamp data from the log file {log_path}, as it does not exist or does "
            f"not point to a valid .npz archive."
        )
        console.error(message=error_message, error=ValueError)

    # Memory-maps the processed archive to conserve RAM. The first processing pass is designed to find the onset
    # timestamp value.
    with np.load(log_path, allow_pickle=False, fix_imports=False, mmap_mode="r") as archive:
        # Locates the logging onset timestamp. The onset is used to convert the relative timestamps for logged frame
        # data into absolute UTC timestamps. Originally, all timestamps other than onset are stored as elapsed time in
        # microseconds relative to the onset timestamp.
        onset_us = np.uint64(0)
        timestamp_offset = 0
        message_list = list(archive.files)
        for number, item in enumerate(message_list):
            message: NDArray[np.uint8] = archive[item]  # Extracts message payload from the compressed .npy file

            # Recovers the uint64 timestamp value from each message. The timestamp occupies 8 bytes of each logged
            # message starting at index 1. If the timestamp value is 0, the message contains the onset timestamp value
            # stored as an 8-byte payload. Index 0 stores the source ID (uint8 value).
            timestamp_value = message[1:9].view(np.uint64).item()
            if timestamp_value == 0:
                # Extracts the byte-serialized UTC timestamp stored as microseconds since epoch onset.
                onset_us = np.uint64(message[9:].view(np.int64).item())

                # Breaks the loop once the onset is found. Generally, the onset is expected to be found very early into
                # the loop.
                timestamp_offset = number  # Records the item number at which the onset value was found.
                break

    # Builds the list of files to process after discovering the timestamp (the list of remaining messages)
    messages_to_process = message_list[timestamp_offset + 1 :]

    # If there are no leftover messages to process, return an empty tuple
    if not messages_to_process:
        return tuple()

    # Small archives are processed sequentially to avoid the unnecessary overhead of setting up the multiprocessing
    # runtime. This is also done for large files if the user explicitly requests to use a single worker process.
    if n_workers == 1 or len(messages_to_process) < 2000:
        return tuple(_process_frame_message_batch(log_path, messages_to_process, onset_us))

    # If the user enabled using all available cores, configures the runtime to use all available CPUs
    if n_workers < 0:
        n_workers = cpu_count()

    # Creates batches of messages to process during runtime. Uses a fairly high batch multiplier to create many smaller
    # batches, which leads to a measurable increase in the processing speed, especially for large archives. The optimal
    # multiplier value (4) was determined experimentally.
    batches = []
    batch_indices = []  # Keeps track of batch order
    for i, batch in enumerate(chunk_iterable(messages_to_process, n_workers * 4)):
        if batch:
            batches.append((log_path, list(batch), onset_us))
            batch_indices.append(i)

    # Processes batches using ProcessPoolExecutor
    with ProcessPoolExecutor(max_workers=n_workers) as executor:
        # Submits all tasks
        future_to_index = {
            executor.submit(_process_frame_message_batch, *batch_args): idx
            for idx, batch_args in zip(batch_indices, batches)
        }

        # Collects results while maintaining frame order. This also propagates processing errors to the caller process.
        results: list[list[np.uint64] | None] = [None] * len(batches)

        # Creates a progress bar for batch processing
        with tqdm(total=len(batches), desc="Extracting camera frame timestamps", unit="batch") as pbar:
            for future in as_completed(future_to_index):
                results[future_to_index[future]] = future.result()
                pbar.update(1)  # Updates the progress bar after each batch completes

    # Combines processing results in order
    all_timestamps: list[np.uint64] = []
    for batch_timestamps in results:
        # noinspection PyUnreachableCode
        if batch_timestamps is not None:  # Skips None results
            all_timestamps.extend(batch_timestamps)

    return tuple(all_timestamps)


def process_camera_timestamps(
    session_path: Path,
    log_id: int,
    manager_id: int,
    job_count: int,
    reset_tracker: bool = False,
    processed_data_root: Path | None = None,
    workers: int = -1,
) -> None:
    """Reads the specified camera log .npz file and extracts the frame acquisition timestamps as an uncompressed
    .feather file.

    This function is used to process the log archives generated by any video camera used in the Sun lab. It assumes that
    the data was logged using the assets from the ataraxis-video-system library.

    Args:
        session_path: The path to the session directory for which to process the camera log file.
        log_id: The name (ID) of the log archive to process, e.g. '51'.
        manager_id: The unique identifier of the manager process that manages the log processing runtime.
        job_count: The total number of jobs executed as part of the behavior processing pipeline that calls this
            function.
        reset_tracker: Determines whether to reset the tracker file before executing the runtime. This allows
            recovering from deadlocked runtimes, but otherwise should not be used to ensure runtime safety.
        processed_data_root: The absolute path to the directory where processed data from all projects is stored, if
            different from the root directory provided as part of the 'session_path' argument.
        workers: The number of worker processes to use for extracting the camera frame timestamps in parallel. Setting
            this argument to a value less than 1 uses all available CPU cores. Setting this to a value of 1 conducts
            the processing sequentially.
    """

    # Loads the target session's data hierarchy into memory
    session = SessionData.load(session_path=session_path, processed_data_root=processed_data_root)

    # Resolves the path to the processed log file
    log_path = session.source_data.behavior_data_path.joinpath(f"{log_id}_log.npz")

    # Ensures that runtime's manager process has exclusive access to the processed session's data
    lock = SessionLock(file_path=session.tracking_data.session_lock_path)
    lock.check_owner(manager_id=manager_id)

    # Initializes the processing tracker for this pipeline.
    tracker = ProcessingTracker(file_path=session.tracking_data.tracking_data_path.joinpath(TrackerFileNames.BEHAVIOR))

    # If requested, resets the processing tracker to the default state before running the processing
    if reset_tracker:
        tracker.abort()

    # Extracts the video camera frame timestamps from the target log file
    tracker.start(manager_id=manager_id, job_count=job_count)
    try:
        # Mesoscope-VR system
        output_path = Path()
        if session.acquisition_system == AcquisitionSystems.MESOSCOPE_VR:
            # Ensures that the processed session supports this type of processing.
            if session.session_type not in _supported_sessions:
                message = (
                    f"Unable to extract the video camera frame timestamps from the '{log_id}' log file of the session "
                    f"'{session.session_name}'. The processed session has an unsupported session type "
                    f"'{session.session_type}'. Currently, only the following Mesoscope-VR-acquired session types are "
                    f"supported: {', '.join(_supported_sessions)}."
                )
                console.error(message=message, error=NotImplementedError)

            # Statically maps processed log IDs to human-readable output file names and resolves the output .feather
            # file path
            if log_id == 51:
                output_path = session.processed_data.camera_data_path.joinpath("face_camera_timestamps.feather")
            elif log_id == 62:
                output_path = session.processed_data.camera_data_path.joinpath("left_camera_timestamps.feather")
            elif log_id == 73:
                output_path = session.processed_data.camera_data_path.joinpath("right_camera_timestamps.feather")
            else:
                message = (
                    f"Unable to extract the video camera frame timestamps from the '{log_id}' log file of the session "
                    f"'{session.session_name}'. Encountered an unknown video camera log ID. Currently, the "
                    f"Mesoscope-VR system is expected to use the following log IDs: 51 (face camera), "
                    f"62 (left camera), and 73 (right camera)."
                )
                console.error(message=message, error=ValueError)
        else:
            message = (
                f"Unable to extract the video camera frame timestamps from the '{log_id}' log file of the session "
                f"'{session.session_name}'. The processed session was acquired using an unsupported data acquisition "
                f"system '{session.acquisition_system}'. Currently, only the following acquisition systems are "
                f"supported: {', '.join(_supported_sessions)}."
            )
            console.error(message=message, error=NotImplementedError)

        console.echo(f"Extracting video camera frame timestamps from '{log_id}' log file...")

        # Extracts timestamp data from log archive
        timestamp_data = _extract_camera_timestamps(log_path=log_path, n_workers=workers)

        # Converts extracted data to Polars series.
        timestamps_series = pl.Series(name="frame_time_us", values=timestamp_data)

        # Saves extracted data using Feather format and no compression to support memory-mapping the file during
        # processing.
        timestamps_series.to_frame().write_ipc(file=output_path, compression="uncompressed")

        # Configures the tracker to indicate that the processing was completed successfully.
        tracker.stop(manager_id=manager_id)

        console.echo(f"Camera frame timestamp processing: Complete.", level=LogLevel.SUCCESS)

    # If the runtime encounters an error, configures the tracker to indicate that the processing was interrupted.
    except Exception:
        tracker.error(manager_id=manager_id)
        raise

    # Updates the project manifest file to reflect the processing outcome.
    finally:
        generate_project_manifest(
            raw_project_directory=session.raw_data.root_path.joinpath(session.project_name),
            processed_data_root=processed_data_root,
            manager_id=manager_id,
        )
