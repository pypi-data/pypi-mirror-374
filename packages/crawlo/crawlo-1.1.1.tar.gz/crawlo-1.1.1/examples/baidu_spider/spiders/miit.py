#!/usr/bin/python
# -*- coding:UTF-8 -*-
"""
# @Time    :    2025-08-22 14:00
# @Author  :   oscar
# @Desc    :   çˆ¬å–å·¥ä¿¡éƒ¨æ— çº¿ç”µè®¾å¤‡æ ¸å‡†ä¿¡æ¯ï¼ˆæ”¯æŒå…¨é‡34652é¡µï¼‰
"""

import json
import asyncio
import random

from crawlo import Request
from crawlo.spider import Spider
from crawlo.utils.log import get_logger
from crawlo.utils.date_tools import to_datetime

# å¼•å…¥å®šä¹‰å¥½çš„ Item
from examples.baidu_spider.items import MiitDeviceItem


logger = get_logger(__name__)


class MiitDeviceSpider(Spider):
    name = 'miit_device'
    allowed_domains = ['ythzxfw.miit.gov.cn']

    # å­—æ®µæ˜ å°„è¡¨
    FIELD_MAPPING = {
        "articleField01": ("æ ¸å‡†è¯ç¼–å·", "approval_certificate_no"),
        "articleField02": ("è®¾å¤‡åç§°", "device_name"),
        "articleField03": ("è®¾å¤‡å‹å·", "model_number"),
        "articleField04": ("ç”³è¯·å•ä½", "applicant"),
        "articleField05": ("å¤‡æ³¨", "remarks"),
        "articleField06": ("æœ‰æ•ˆæœŸ", "validity_period"),
        "articleField07": ("é¢‘ç‡å®¹é™", "frequency_tolerance"),
        "articleField08": ("é¢‘ç‡èŒƒå›´", "frequency_range"),
        "articleField09": ("å‘å°„åŠŸç‡", "transmission_power"),
        "articleField10": ("å ç”¨å¸¦å®½", "occupied_bandwidth"),
        "articleField11": ("æ‚æ•£å‘å°„é™åˆ¶", "spurious_emission_limit"),
        "articleField12": ("å‘è¯æ—¥æœŸ", "issue_date"),
        "articleField13": ("æ ¸å‡†ä»£ç ", "approval_code"),
        "articleField14": ("CMIIT ID", "cmiit_id"),
        "articleField15": ("è°ƒåˆ¶æ–¹å¼", "modulation_scheme"),
        "articleField16": ("æŠ€æœ¯ä½“åˆ¶/åŠŸèƒ½æ¨¡å—", "technology_module"),
        "createTime": ("createTime", "create_time"),
        "articleId": ("articleId", "article_id")
    }

    headers = {
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Authorization": "null",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "Content-Type": "application/json;charset=UTF-8",
        "Origin": "https://ythzxfw.miit.gov.cn",
        "Pragma": "no-cache",
        "Referer": "https://ythzxfw.miit.gov.cn/oldyth/resultQuery",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
        "sec-ch-ua": '"Not;A=Brand";v="99", "Google Chrome";v="139", "Chromium";v="139"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"macOS"'
    }

    cookies = {
        "wzws_sessionid": "gjdjYmMyNYFkZjRiZjCgaKkOx4AyNDBlOjQ3ZTozMmUwOmQ5MmI6ZjFjZTphNWJiOjk5ZmU6OTU4OQ==",
        "ariauseGraymode": "false",
        "Hm_lvt_a73626d298a849004aacc34159f68abd": "1755909833",
        "Hm_lpvt_a73626d298a849004aacc34159f68abd": "1755909833",
        "HMACCOUNT": "6C5E4C6C47DC62FF"
    }

    # åˆ†é¡µé…ç½®
    start_page = 1           # èµ·å§‹é¡µ
    end_page = 34652         # æ€»é¡µæ•°
    current_page = 1
    page_size = 5            # æ¯é¡µæ¡æ•°

    # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé˜²æ­¢è¢«å°
    min_delay = 1.5
    max_delay = 3.0

    def start_requests(self):
        # ä»èµ·å§‹é¡µå¼€å§‹
        yield self.make_request(self.start_page)

    def make_request(self, page):
        """å°è£…è¯·æ±‚åˆ›å»º"""
        data = {
            "categoryId": "352",
            "currentPage": page,
            "pageSize": self.page_size,
            "searchContent": ""
        }
        return Request(
            method='POST',
            url='https://ythzxfw.miit.gov.cn/oldyth/user-center/tbAppSearch/selectResult',
            headers=self.headers,
            cookies=self.cookies,
            body=json.dumps(data, separators=(',', ':'), ensure_ascii=False),
            callback=self.parse,
            dont_filter=True,
            meta={'page': page}  # è®°å½•å½“å‰é¡µç ï¼Œä¾¿äºæ—¥å¿—å’Œè°ƒè¯•
        )

    async def parse(self, response):
        page = response.meta.get('page', 'unknown')
        try:
            json_data = response.json()
            success = json_data.get("success")
            code = json_data.get("code")

            if not success or code != 200:
                logger.error(f"ç¬¬ {page} é¡µè¯·æ±‚å¤±è´¥: code={code}, msg={json_data.get('msg')}")
                return

            tb_app_article = json_data.get('params', {}).get('tbAppArticle', {})
            records = tb_app_article.get('list', [])
            total_count = tb_app_article.get('total', 0)  # æ€»æ•°æ®æ¡æ•°ï¼Œä¾‹å¦‚ 173256

            logger.info(f"âœ… ç¬¬ {page} é¡µè§£ææˆåŠŸï¼Œå…± {len(records)} æ¡æ•°æ®ã€‚æ€»è®¡: {total_count} æ¡")

            for raw_item in records:
                item = MiitDeviceItem()
                for field_key, (chinese_name, english_field) in self.FIELD_MAPPING.items():
                    value = raw_item.get(field_key)
                    if english_field == 'issue_date' and value:
                        value = to_datetime(value.split()[0])
                    item[english_field] = value
                yield item

            # âœ… æ ¸å¿ƒä¿®å¤ï¼šæ ¹æ® total_count å’Œ page_size è®¡ç®—çœŸå®æ€»é¡µæ•°
            # æ³¨æ„ï¼šéœ€è¦å‘ä¸Šå–æ•´ï¼Œä¾‹å¦‚ 173256 / 5 = 34651.2ï¼Œåº”è¯¥æœ‰ 34652 é¡µ
            import math
            calculated_total_pages = math.ceil(total_count / self.page_size)

            # ç°åœ¨ä½¿ç”¨ calculated_total_pages æ¥åˆ¤æ–­æ˜¯å¦ç»§ç»­ç¿»é¡µ
            next_page = page + 1
            if next_page <= calculated_total_pages:
                delay = random.uniform(self.min_delay, self.max_delay)
                logger.debug(f"ç­‰å¾… {delay:.2f}s åè¯·æ±‚ç¬¬ {next_page} é¡µ...")
                await asyncio.sleep(delay)
                yield self.make_request(next_page)
            else:
                logger.info(f"ğŸ‰ çˆ¬å–å®Œæˆï¼å·²åˆ°è¾¾æœ€åä¸€é¡µ {calculated_total_pages}")

        except Exception as e:
            logger.error(f"âŒ è§£æç¬¬ {page} é¡µå¤±è´¥: {e}, å“åº”: {response.text[:500]}...")

    async def spider_opened(self):
        logger.info(f"MiitDeviceSpider å¯åŠ¨ï¼Œå‡†å¤‡çˆ¬å– {self.start_page} è‡³ {self.end_page} é¡µ...")

    async def spider_closed(self):
        logger.info("MiitDeviceSpider ç»“æŸã€‚")