# Example LiteLLM configuration for AgentGraph
# This configuration includes latest OpenAI and Anthropic models

models:
  - model: "gpt-4o"
    api_key: "${OPENAI_API_KEY}"  # Use environment variable
    temperature: 0.7
    max_tokens: 4096
    timeout: 30
    max_retries: 3

  - model: "gpt-4"
    api_key: "${OPENAI_API_KEY}"  # Use environment variable
    temperature: 0.7
    max_tokens: 4096
    timeout: 30
    max_retries: 3

  - model: "claude-3-5-sonnet-20241022"
    api_key: "${ANTHROPIC_API_KEY}"  # Use environment variable
    temperature: 0.7
    max_tokens: 8192
    timeout: 45
    max_retries: 3
    custom_llm_provider: "anthropic"

  - model: "claude-3-sonnet-20240229"
    api_key: "${ANTHROPIC_API_KEY}"  # Use environment variable
    temperature: 0.7
    max_tokens: 4096
    timeout: 30
    max_retries: 3
    custom_llm_provider: "anthropic"

# Default model to use when not specified
default_model: "gpt-4o"

# Global settings
enable_caching: false
cache_ttl: 3600  # 1 hour
log_level: "INFO"

# Fallback configuration
enable_fallback: true
fallback_order:
  - "gpt-4o"
  - "claude-3-5-sonnet-20241022"
  - "gpt-4"
  - "claude-3-sonnet-20240229"
