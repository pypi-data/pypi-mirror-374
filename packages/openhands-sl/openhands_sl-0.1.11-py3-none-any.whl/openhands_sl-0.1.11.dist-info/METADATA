Metadata-Version: 2.1
Name: openhands-sl
Version: 0.1.11
Summary: üëêOpenHands : Making Sign Language Recognition Accessible
Home-page: https://openhands.ai4bharat.org
Download-URL: https://pypi.org/project/openhands_sl
Author: AI4BhƒÅrat
Project-URL: Source, https://github.com/AI4Bharat/OpenHands
Project-URL: Issues, https://github.com/AI4Bharat/OpenHands/issues
Project-URL: Documentation, https://openhands.readthedocs.io
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries
Description-Content-Type: text/markdown
License-File: LICENSE.txt
Requires-Dist: numpy>=1.21.6
Requires-Dist: albumentations<2.0.0,>=1.3.0
Requires-Dist: tqdm>=4.66.0
Requires-Dist: PyYAML>=6.0.0
Requires-Dist: omegaconf>=2.3.0
Requires-Dist: pytorch-lightning<2.0.0,>=1.5.0
Requires-Dist: pytorchvideo>=0.1.5
Requires-Dist: hydra-core>=1.2.0
Requires-Dist: torch<3.0.0,>=2.0.0
Requires-Dist: mediapipe<0.11.0,>=0.10.5
Requires-Dist: natsort>=8.4.0
Requires-Dist: h5py>=3.9.0
Requires-Dist: torchvision<0.16.0,>=0.15.0
Requires-Dist: opencv-python-headless>=4.8.0
Requires-Dist: torchmetrics<1.0.0,>=0.11.0
Requires-Dist: timm>=0.9.16
Requires-Dist: transformers>=4.35.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: Pillow>=10.0.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: beautifulsoup4>=4.12.0
Requires-Dist: lxml>=4.9.0
Requires-Dist: sphinx==7.2.6
Requires-Dist: myst-parser==2.0.0
Requires-Dist: sphinx-rtd-theme==2.0.0
Requires-Dist: sphinx-copybutton==0.5.2

# üëêOpenHands: Sign Language Recognition Library

> _Making Sign Language Recognition Accessible_

Check the documentation on how to use the library:  
**[ReadTheDocs: üëêOpenHands](https://openhands.readthedocs.io)**

## Installation

- For stable version: `pip install --upgrade openhands_sl`
- For latest development version: `pip install git+https://github.com/AI4Bharat/OpenHands`

## Basic Usage

```python
import openhands as oh

# List available models and datasets
print(oh.list_models())
print(oh.list_datasets())
```

## License

This project is released under the [Apache 2.0 license](LICENSE.txt).

## Datasets used

Please cite the respective datasets if you used them in your research. Also check the licensing terms for the dataset used.

| Dataset         | Link |
| --------------- | ----------- |
| AUTSL           | [Link](https://chalearnlap.cvc.uab.es/dataset/40/description/)       |
| CSL             | [Link](http://home.ustc.edu.cn/~pjh/openresources/cslr-dataset-2015/index.html)        |
| DEVISIGN         | [Link](http://vipl.ict.ac.cn/homepage/ksl/data.html)       |
| GSL             | [Link](https://vcl.iti.gr/dataset/gsl/)        |
| INCLUDE         | [Link](https://sign-language.ai4bharat.org/#/INCLUDE)       |
| LSA64           | [Link](http://facundoq.github.io/datasets/lsa64/)        |
| WLASL           | [Link](https://dxli94.github.io/WLASL/)        |

## Extraction of poses

For datasets without the pose data, poses can be extracted from the videos using [this script](scripts/mediapipe_extract.py). 
## Citation

If you find our work useful in your research, please consider citing us:

```BibTeX
@misc{2021_openhands_slr_preprint,
      title={OpenHands: Making Sign Language Recognition Accessible with Pose-based Pretrained Models across Languages}, 
      author={Prem Selvaraj and Gokul NC and Pratyush Kumar and Mitesh Khapra},
      year={2021},
      eprint={2110.05877},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
      nc2022addressing,
      title={Addressing Resource Scarcity across Sign Languages with Multilingual Pretraining and Unified-Vocabulary Datasets},
      author={Gokul NC and Manideep Ladi and Sumit Negi and Prem Selvaraj and Pratyush Kumar and Mitesh M Khapra},
      booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
      year={2022},
      url={https://openreview.net/forum?id=zBBmV-i84Go}
}
```

