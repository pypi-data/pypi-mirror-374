"""
æ™ºèƒ½ç¼“å­˜ç­–ç•¥ - é«˜çº§ç¼“å­˜å†³ç­–å’Œä¼˜åŒ–ç®—æ³•

å®ç°å¤šç§æ™ºèƒ½ç¼“å­˜ç­–ç•¥ï¼ŒåŒ…æ‹¬æˆæœ¬æ„ŸçŸ¥ç¼“å­˜ã€è´¨é‡é©±åŠ¨ç¼“å­˜ã€
æ—¶é—´æ„ŸçŸ¥ç¼“å­˜ç­‰ï¼Œä¸ºè¯­ä¹‰ç¼“å­˜ç³»ç»Ÿæä¾›å†³ç­–æ”¯æŒã€‚

Author: ADC Team
Date: 2024-12-19
Version: 1.0.0
"""

import asyncio
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Any
from enum import Enum
import logging
import numpy as np
from collections import defaultdict

from .semantic_cache import CacheEntry, CachePriority, UserRole

logger = logging.getLogger(__name__)

class CacheStrategy(Enum):
    """ç¼“å­˜ç­–ç•¥ç±»å‹"""
    COST_AWARE = "cost_aware"              # æˆæœ¬æ„ŸçŸ¥
    QUALITY_DRIVEN = "quality_driven"      # è´¨é‡é©±åŠ¨
    TEMPORAL_AWARE = "temporal_aware"      # æ—¶é—´æ„ŸçŸ¥
    FREQUENCY_BASED = "frequency_based"    # é¢‘ç‡åŸºç¡€
    USER_ADAPTIVE = "user_adaptive"        # ç”¨æˆ·è‡ªé€‚åº”
    HYBRID = "hybrid"                      # æ··åˆç­–ç•¥

class CacheDecisionFactor(Enum):
    """ç¼“å­˜å†³ç­–å› å­"""
    QUERY_COMPLEXITY = "query_complexity"
    RESPONSE_LENGTH = "response_length"
    GENERATION_COST = "generation_cost"
    USER_SATISFACTION = "user_satisfaction"
    QUERY_FREQUENCY = "query_frequency"
    TEMPORAL_RELEVANCE = "temporal_relevance"
    USER_ROLE_IMPORTANCE = "user_role_importance"

@dataclass
class CacheDecisionContext:
    """ç¼“å­˜å†³ç­–ä¸Šä¸‹æ–‡"""
    query: str
    response: str
    user_role: UserRole
    generation_cost: float
    quality_score: float
    response_time: float
    user_satisfaction: Optional[float] = None
    query_complexity: Optional[float] = None
    temporal_relevance: Optional[float] = None
    similar_queries_count: int = 0
    metadata: Dict[str, Any] = None

@dataclass
class CacheDecision:
    """ç¼“å­˜å†³ç­–ç»“æœ"""
    should_cache: bool
    priority: CachePriority
    ttl_seconds: int
    reasoning: List[str]
    confidence: float
    expected_value: float  # é¢„æœŸä»·å€¼

class IntelligentCacheStrategy:
    """æ™ºèƒ½ç¼“å­˜ç­–ç•¥"""
    
    def __init__(
        self,
        strategy_type: CacheStrategy = CacheStrategy.HYBRID,
        cost_threshold: float = 0.1,
        quality_threshold: float = 0.6,
        frequency_threshold: int = 3
    ):
        self.strategy_type = strategy_type
        self.cost_threshold = cost_threshold
        self.quality_threshold = quality_threshold
        self.frequency_threshold = frequency_threshold
        
        # å†³ç­–å› å­æƒé‡
        self.factor_weights = self._initialize_factor_weights()
        
        # æŸ¥è¯¢é¢‘ç‡ç»Ÿè®¡
        self.query_frequency_stats: Dict[str, int] = defaultdict(int)
        
        # ç”¨æˆ·è¡Œä¸ºæ¨¡å¼
        self.user_behavior_patterns: Dict[UserRole, Dict[str, float]] = defaultdict(lambda: defaultdict(float))
        
        logger.info(f"ğŸ§  æ™ºèƒ½ç¼“å­˜ç­–ç•¥åˆå§‹åŒ– - ç­–ç•¥: {strategy_type.value}")
    
    def _initialize_factor_weights(self) -> Dict[CacheDecisionFactor, float]:
        """åˆå§‹åŒ–å†³ç­–å› å­æƒé‡"""
        base_weights = {
            CacheDecisionFactor.QUERY_COMPLEXITY: 0.15,
            CacheDecisionFactor.RESPONSE_LENGTH: 0.10,
            CacheDecisionFactor.GENERATION_COST: 0.25,
            CacheDecisionFactor.USER_SATISFACTION: 0.20,
            CacheDecisionFactor.QUERY_FREQUENCY: 0.15,
            CacheDecisionFactor.TEMPORAL_RELEVANCE: 0.10,
            CacheDecisionFactor.USER_ROLE_IMPORTANCE: 0.05
        }
        
        # æ ¹æ®ç­–ç•¥ç±»å‹è°ƒæ•´æƒé‡
        if self.strategy_type == CacheStrategy.COST_AWARE:
            base_weights[CacheDecisionFactor.GENERATION_COST] = 0.40
            base_weights[CacheDecisionFactor.QUERY_FREQUENCY] = 0.25
        elif self.strategy_type == CacheStrategy.QUALITY_DRIVEN:
            base_weights[CacheDecisionFactor.USER_SATISFACTION] = 0.35
            base_weights[CacheDecisionFactor.QUERY_COMPLEXITY] = 0.25
        elif self.strategy_type == CacheStrategy.FREQUENCY_BASED:
            base_weights[CacheDecisionFactor.QUERY_FREQUENCY] = 0.40
            base_weights[CacheDecisionFactor.TEMPORAL_RELEVANCE] = 0.20
        
        return base_weights
    
    async def make_cache_decision(self, context: CacheDecisionContext) -> CacheDecision:
        """åšå‡ºç¼“å­˜å†³ç­–"""
        try:
            # æ›´æ–°æŸ¥è¯¢é¢‘ç‡ç»Ÿè®¡
            query_hash = self._hash_query(context.query)
            self.query_frequency_stats[query_hash] += 1
            
            # è®¡ç®—å„ä¸ªå†³ç­–å› å­çš„åˆ†æ•°
            factor_scores = await self._calculate_factor_scores(context)
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            total_score = self._calculate_weighted_score(factor_scores)
            
            # åŸºäºè¯„åˆ†åšå‡ºå†³ç­–
            decision = await self._make_decision_based_on_score(total_score, context)
            
            # æ›´æ–°ç”¨æˆ·è¡Œä¸ºæ¨¡å¼
            await self._update_user_behavior_pattern(context, decision)
            
            logger.debug(f"ğŸ§  ç¼“å­˜å†³ç­–: {context.query[:50]}... -> {decision.should_cache} (è¯„åˆ†: {total_score:.3f})")
            
            return decision
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜å†³ç­–å¤±è´¥: {e}")
            # è¿”å›ä¿å®ˆçš„å†³ç­–
            return CacheDecision(
                should_cache=context.generation_cost > self.cost_threshold,
                priority=CachePriority.LOW,
                ttl_seconds=3600 * 24,  # 1å¤©
                reasoning=[f"å†³ç­–å¤±è´¥ï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥: {str(e)}"],
                confidence=0.5,
                expected_value=context.generation_cost * 0.5
            )
    
    async def _calculate_factor_scores(self, context: CacheDecisionContext) -> Dict[CacheDecisionFactor, float]:
        """è®¡ç®—å„ä¸ªå†³ç­–å› å­çš„åˆ†æ•°"""
        scores = {}
        
        # æŸ¥è¯¢å¤æ‚åº¦åˆ†æ•°
        scores[CacheDecisionFactor.QUERY_COMPLEXITY] = await self._score_query_complexity(context)
        
        # å“åº”é•¿åº¦åˆ†æ•°
        scores[CacheDecisionFactor.RESPONSE_LENGTH] = self._score_response_length(context)
        
        # ç”Ÿæˆæˆæœ¬åˆ†æ•°
        scores[CacheDecisionFactor.GENERATION_COST] = self._score_generation_cost(context)
        
        # ç”¨æˆ·æ»¡æ„åº¦åˆ†æ•°
        scores[CacheDecisionFactor.USER_SATISFACTION] = self._score_user_satisfaction(context)
        
        # æŸ¥è¯¢é¢‘ç‡åˆ†æ•°
        scores[CacheDecisionFactor.QUERY_FREQUENCY] = self._score_query_frequency(context)
        
        # æ—¶é—´ç›¸å…³æ€§åˆ†æ•°
        scores[CacheDecisionFactor.TEMPORAL_RELEVANCE] = await self._score_temporal_relevance(context)
        
        # ç”¨æˆ·è§’è‰²é‡è¦æ€§åˆ†æ•°
        scores[CacheDecisionFactor.USER_ROLE_IMPORTANCE] = self._score_user_role_importance(context)
        
        return scores
    
    async def _score_query_complexity(self, context: CacheDecisionContext) -> float:
        """è¯„åˆ†æŸ¥è¯¢å¤æ‚åº¦"""
        if context.query_complexity is not None:
            return context.query_complexity
        
        # åŸºäºæŸ¥è¯¢é•¿åº¦å’Œç‰¹å¾ä¼°ç®—å¤æ‚åº¦
        query_length = len(context.query)
        
        # å¤æ‚æŸ¥è¯¢æŒ‡æ ‡
        complexity_indicators = [
            'å¦‚ä½•å®ç°', 'è®¾è®¡', 'ä¼˜åŒ–', 'è°ƒè¯•', 'åˆ†æ',
            'æ¯”è¾ƒ', 'è¯„ä¼°', 'é€‰æ‹©', 'é…ç½®', 'é›†æˆ'
        ]
        
        complexity_score = 0.0
        
        # é•¿åº¦å› å­
        if query_length > 100:
            complexity_score += 0.4
        elif query_length > 50:
            complexity_score += 0.2
        
        # å¤æ‚æ€§å…³é”®è¯
        for indicator in complexity_indicators:
            if indicator in context.query:
                complexity_score += 0.2
                break
        
        # æŠ€æœ¯æœ¯è¯­å¯†åº¦
        technical_terms = ['FPGA', 'Verilog', 'HDL', 'RTL', 'æ—¶åº', 'ç»¼åˆ', 'ä»¿çœŸ']
        term_count = sum(1 for term in technical_terms if term in context.query)
        complexity_score += min(term_count * 0.1, 0.3)
        
        return min(complexity_score, 1.0)
    
    def _score_response_length(self, context: CacheDecisionContext) -> float:
        """è¯„åˆ†å“åº”é•¿åº¦"""
        response_length = len(context.response)
        
        # é•¿å“åº”æ›´æœ‰ä»·å€¼ï¼Œæ›´åº”è¯¥ç¼“å­˜
        if response_length > 2000:
            return 0.9
        elif response_length > 1000:
            return 0.7
        elif response_length > 500:
            return 0.5
        elif response_length > 200:
            return 0.3
        else:
            return 0.1
    
    def _score_generation_cost(self, context: CacheDecisionContext) -> float:
        """è¯„åˆ†ç”Ÿæˆæˆæœ¬"""
        # æˆæœ¬è¶Šé«˜ï¼Œç¼“å­˜ä»·å€¼è¶Šå¤§
        cost = context.generation_cost
        
        if cost > 1.0:
            return 1.0
        elif cost > 0.5:
            return 0.8
        elif cost > 0.2:
            return 0.6
        elif cost > 0.1:
            return 0.4
        else:
            return 0.2
    
    def _score_user_satisfaction(self, context: CacheDecisionContext) -> float:
        """è¯„åˆ†ç”¨æˆ·æ»¡æ„åº¦"""
        if context.user_satisfaction is not None:
            return context.user_satisfaction
        
        # åŸºäºè´¨é‡åˆ†æ•°ä¼°ç®—æ»¡æ„åº¦
        if context.quality_score > 0.8:
            return 0.9
        elif context.quality_score > 0.6:
            return 0.7
        elif context.quality_score > 0.4:
            return 0.5
        else:
            return 0.3
    
    def _score_query_frequency(self, context: CacheDecisionContext) -> float:
        """è¯„åˆ†æŸ¥è¯¢é¢‘ç‡"""
        query_hash = self._hash_query(context.query)
        frequency = self.query_frequency_stats[query_hash]
        
        # é¢‘ç‡è¶Šé«˜ï¼Œç¼“å­˜ä»·å€¼è¶Šå¤§
        if frequency > 10:
            return 1.0
        elif frequency > 5:
            return 0.8
        elif frequency > 2:
            return 0.6
        elif frequency > 1:
            return 0.4
        else:
            return 0.2
    
    async def _score_temporal_relevance(self, context: CacheDecisionContext) -> float:
        """è¯„åˆ†æ—¶é—´ç›¸å…³æ€§"""
        if context.temporal_relevance is not None:
            return context.temporal_relevance
        
        # æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦åŒ…å«æ—¶é—´æ•æ„Ÿçš„å†…å®¹
        temporal_keywords = [
            'æœ€æ–°', 'å½“å‰', 'ç°åœ¨', 'ä»Šå¹´', 'æœ€è¿‘',
            'æ–°ç‰ˆæœ¬', 'æ›´æ–°', 'å‘å¸ƒ', 'è¶‹åŠ¿'
        ]
        
        has_temporal_content = any(keyword in context.query for keyword in temporal_keywords)
        
        if has_temporal_content:
            return 0.3  # æ—¶é—´æ•æ„Ÿå†…å®¹ç¼“å­˜ä»·å€¼è¾ƒä½
        else:
            return 0.8  # æ—¶é—´æ— å…³å†…å®¹é€‚åˆé•¿æœŸç¼“å­˜
    
    def _score_user_role_importance(self, context: CacheDecisionContext) -> float:
        """è¯„åˆ†ç”¨æˆ·è§’è‰²é‡è¦æ€§"""
        role_importance = {
            UserRole.EXPERT: 0.9,      # ä¸“å®¶çš„å“åº”æ›´æœ‰ä»·å€¼
            UserRole.RESEARCHER: 0.8,  # ç ”ç©¶è€…çš„å“åº”ä¹Ÿå¾ˆæœ‰ä»·å€¼
            UserRole.INTERMEDIATE: 0.6, # ä¸­çº§ç”¨æˆ·çš„å“åº”æœ‰ä¸€å®šä»·å€¼
            UserRole.BEGINNER: 0.4     # åˆå­¦è€…çš„å“åº”ä»·å€¼è¾ƒä½
        }
        
        return role_importance.get(context.user_role, 0.5)
    
    def _calculate_weighted_score(self, factor_scores: Dict[CacheDecisionFactor, float]) -> float:
        """è®¡ç®—åŠ æƒç»¼åˆè¯„åˆ†"""
        total_score = 0.0
        total_weight = 0.0
        
        for factor, score in factor_scores.items():
            weight = self.factor_weights.get(factor, 0.0)
            total_score += score * weight
            total_weight += weight
        
        return total_score / max(total_weight, 1.0)
    
    async def _make_decision_based_on_score(
        self, 
        total_score: float, 
        context: CacheDecisionContext
    ) -> CacheDecision:
        """åŸºäºè¯„åˆ†åšå‡ºå†³ç­–"""
        reasoning = []
        
        # å†³ç­–é˜ˆå€¼
        high_value_threshold = 0.75
        medium_value_threshold = 0.50
        low_value_threshold = 0.25
        
        if total_score >= high_value_threshold:
            should_cache = True
            priority = CachePriority.HIGH
            ttl_seconds = 3600 * 24 * 14  # 14å¤©
            reasoning.append(f"é«˜ä»·å€¼æŸ¥è¯¢ (è¯„åˆ†: {total_score:.3f})")
            expected_value = context.generation_cost * 0.8
            
        elif total_score >= medium_value_threshold:
            should_cache = True
            priority = CachePriority.MEDIUM
            ttl_seconds = 3600 * 24 * 7   # 7å¤©
            reasoning.append(f"ä¸­ç­‰ä»·å€¼æŸ¥è¯¢ (è¯„åˆ†: {total_score:.3f})")
            expected_value = context.generation_cost * 0.6
            
        elif total_score >= low_value_threshold:
            should_cache = True
            priority = CachePriority.LOW
            ttl_seconds = 3600 * 24 * 3   # 3å¤©
            reasoning.append(f"ä½ä»·å€¼æŸ¥è¯¢ (è¯„åˆ†: {total_score:.3f})")
            expected_value = context.generation_cost * 0.3
            
        else:
            should_cache = False
            priority = CachePriority.LOW
            ttl_seconds = 0
            reasoning.append(f"ä»·å€¼è¿‡ä½ï¼Œä¸ç¼“å­˜ (è¯„åˆ†: {total_score:.3f})")
            expected_value = 0.0
        
        # ç‰¹æ®Šè§„åˆ™è¦†ç›–
        if context.generation_cost > 1.0:
            should_cache = True
            priority = max(priority, CachePriority.HIGH)
            reasoning.append("é«˜æˆæœ¬æŸ¥è¯¢å¼ºåˆ¶ç¼“å­˜")
        
        if context.quality_score < 0.3:
            should_cache = False
            reasoning.append("è´¨é‡è¿‡ä½ï¼Œè·³è¿‡ç¼“å­˜")
        
        confidence = min(total_score * 1.2, 1.0)  # ç½®ä¿¡åº¦åŸºäºè¯„åˆ†
        
        return CacheDecision(
            should_cache=should_cache,
            priority=priority,
            ttl_seconds=ttl_seconds,
            reasoning=reasoning,
            confidence=confidence,
            expected_value=expected_value
        )
    
    async def _update_user_behavior_pattern(
        self, 
        context: CacheDecisionContext, 
        decision: CacheDecision
    ):
        """æ›´æ–°ç”¨æˆ·è¡Œä¸ºæ¨¡å¼"""
        user_pattern = self.user_behavior_patterns[context.user_role]
        
        # æ›´æ–°æˆæœ¬æ•æ„Ÿåº¦
        if context.generation_cost > 0.5 and decision.should_cache:
            user_pattern['cost_sensitivity'] = (user_pattern['cost_sensitivity'] * 0.9 + 0.8 * 0.1)
        
        # æ›´æ–°è´¨é‡åå¥½
        if context.quality_score > 0.8:
            user_pattern['quality_preference'] = (user_pattern['quality_preference'] * 0.9 + 0.9 * 0.1)
        
        # æ›´æ–°å¤æ‚åº¦åå¥½
        complexity_score = await self._score_query_complexity(context)
        if complexity_score > 0.7:
            user_pattern['complexity_preference'] = (user_pattern['complexity_preference'] * 0.9 + complexity_score * 0.1)
    
    def _hash_query(self, query: str) -> str:
        """ç”ŸæˆæŸ¥è¯¢å“ˆå¸Œ"""
        # ç®€å•çš„æŸ¥è¯¢è§„èŒƒåŒ–å’Œå“ˆå¸Œ
        normalized = query.lower().strip()
        return str(hash(normalized))
    
    async def optimize_strategy(self, cache_performance_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¼˜åŒ–ç¼“å­˜ç­–ç•¥"""
        optimization_result = {
            'weight_adjustments': {},
            'threshold_adjustments': {},
            'performance_improvement': 0.0,
            'recommendations': []
        }
        
        try:
            # åˆ†æç¼“å­˜æ€§èƒ½æ•°æ®
            hit_rate = cache_performance_data.get('hit_rate', 0.0)
            cost_efficiency = cache_performance_data.get('cost_efficiency', 0.0)
            average_quality = cache_performance_data.get('average_quality', 0.0)
            
            # åŸºäºæ€§èƒ½è°ƒæ•´æƒé‡
            if hit_rate < 0.3:
                # å‘½ä¸­ç‡ä½ï¼Œæé«˜é¢‘ç‡å› å­æƒé‡
                self.factor_weights[CacheDecisionFactor.QUERY_FREQUENCY] *= 1.2
                optimization_result['weight_adjustments']['query_frequency'] = '+20%'
                optimization_result['recommendations'].append('æé«˜æŸ¥è¯¢é¢‘ç‡æƒé‡ä»¥æ”¹å–„å‘½ä¸­ç‡')
            
            if cost_efficiency < 0.5:
                # æˆæœ¬æ•ˆç‡ä½ï¼Œæé«˜æˆæœ¬å› å­æƒé‡
                self.factor_weights[CacheDecisionFactor.GENERATION_COST] *= 1.1
                optimization_result['weight_adjustments']['generation_cost'] = '+10%'
                optimization_result['recommendations'].append('æé«˜æˆæœ¬å› å­æƒé‡ä»¥æ”¹å–„æˆæœ¬æ•ˆç‡')
            
            if average_quality < 0.6:
                # è´¨é‡åä½ï¼Œæé«˜è´¨é‡å› å­æƒé‡
                self.factor_weights[CacheDecisionFactor.USER_SATISFACTION] *= 1.15
                optimization_result['weight_adjustments']['user_satisfaction'] = '+15%'
                optimization_result['recommendations'].append('æé«˜ç”¨æˆ·æ»¡æ„åº¦æƒé‡ä»¥æ”¹å–„ç¼“å­˜è´¨é‡')
            
            # å½’ä¸€åŒ–æƒé‡
            total_weight = sum(self.factor_weights.values())
            for factor in self.factor_weights:
                self.factor_weights[factor] /= total_weight
            
            logger.info(f"ğŸ”§ ç¼“å­˜ç­–ç•¥ä¼˜åŒ–å®Œæˆ: {optimization_result}")
            return optimization_result
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            return optimization_result

class AdaptiveCacheStrategy(IntelligentCacheStrategy):
    """è‡ªé€‚åº”ç¼“å­˜ç­–ç•¥"""
    
    def __init__(self, **kwargs):
        super().__init__(strategy_type=CacheStrategy.USER_ADAPTIVE, **kwargs)
        
        # å­¦ä¹ å‚æ•°
        self.learning_rate = 0.1
        self.adaptation_window = 100  # æ¯100ä¸ªå†³ç­–åè¿›è¡Œä¸€æ¬¡é€‚åº”
        self.decision_history: List[Tuple[CacheDecisionContext, CacheDecision, float]] = []
    
    async def make_cache_decision(self, context: CacheDecisionContext) -> CacheDecision:
        """è‡ªé€‚åº”çš„ç¼“å­˜å†³ç­–"""
        decision = await super().make_cache_decision(context)
        
        # è®°å½•å†³ç­–å†å²
        self.decision_history.append((context, decision, 0.0))  # åˆå§‹åé¦ˆä¸º0
        
        # å®šæœŸè¿›è¡Œç­–ç•¥é€‚åº”
        if len(self.decision_history) % self.adaptation_window == 0:
            await self._adapt_strategy()
        
        return decision
    
    async def provide_feedback(self, decision_index: int, feedback_score: float):
        """æä¾›å†³ç­–åé¦ˆ"""
        if 0 <= decision_index < len(self.decision_history):
            context, decision, _ = self.decision_history[decision_index]
            self.decision_history[decision_index] = (context, decision, feedback_score)
    
    async def _adapt_strategy(self):
        """é€‚åº”ç­–ç•¥æƒé‡"""
        if not self.decision_history:
            return
        
        # åˆ†ææœ€è¿‘çš„å†³ç­–åé¦ˆ
        recent_decisions = self.decision_history[-self.adaptation_window:]
        positive_decisions = [d for d in recent_decisions if d[2] > 0.7]
        negative_decisions = [d for d in recent_decisions if d[2] < 0.3]
        
        # åŸºäºæ­£é¢åé¦ˆè°ƒæ•´æƒé‡
        for context, decision, feedback in positive_decisions:
            factor_scores = await self._calculate_factor_scores(context)
            for factor, score in factor_scores.items():
                if score > 0.7:  # é«˜åˆ†å› å­
                    self.factor_weights[factor] *= (1 + self.learning_rate * 0.1)
        
        # åŸºäºè´Ÿé¢åé¦ˆè°ƒæ•´æƒé‡
        for context, decision, feedback in negative_decisions:
            factor_scores = await self._calculate_factor_scores(context)
            for factor, score in factor_scores.items():
                if score > 0.7:  # å¯¼è‡´é”™è¯¯å†³ç­–çš„é«˜åˆ†å› å­
                    self.factor_weights[factor] *= (1 - self.learning_rate * 0.1)
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(self.factor_weights.values())
        for factor in self.factor_weights:
            self.factor_weights[factor] /= total_weight
        
        logger.info(f"ğŸ§  è‡ªé€‚åº”ç­–ç•¥è°ƒæ•´å®Œæˆï¼Œå¤„ç†äº† {len(recent_decisions)} ä¸ªå†³ç­–åé¦ˆ")

# å·¥å‚å‡½æ•°
def create_intelligent_cache_strategy(
    strategy_type: CacheStrategy = CacheStrategy.HYBRID,
    **kwargs
) -> IntelligentCacheStrategy:
    """åˆ›å»ºæ™ºèƒ½ç¼“å­˜ç­–ç•¥"""
    if strategy_type == CacheStrategy.USER_ADAPTIVE:
        return AdaptiveCacheStrategy(**kwargs)
    else:
        return IntelligentCacheStrategy(strategy_type=strategy_type, **kwargs) 