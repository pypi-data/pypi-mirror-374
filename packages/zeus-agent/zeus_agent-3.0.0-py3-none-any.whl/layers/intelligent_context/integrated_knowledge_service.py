"""
é›†æˆçŸ¥è¯†åº“æœåŠ¡
ç»“åˆå‘é‡æ•°æ®åº“å’ŒEmbeddingæœåŠ¡ï¼Œæä¾›å®Œæ•´çš„çŸ¥è¯†å­˜å‚¨å’Œæ£€ç´¢èƒ½åŠ›
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime

from .vector_database_service import VectorDatabaseService, VectorDocument, SearchResult
from .embedding_service import EmbeddingService, EmbeddingConfig

logger = logging.getLogger(__name__)


@dataclass
class KnowledgeItem:
    """çŸ¥è¯†é¡¹"""
    content: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    doc_id: Optional[str] = None
    embedding: Optional[List[float]] = None
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class KnowledgeSearchResult:
    """çŸ¥è¯†æœç´¢ç»“æœ"""
    content: str
    metadata: Dict[str, Any]
    score: float
    doc_id: str
    distance: float


class IntegratedKnowledgeService:
    """
    é›†æˆçŸ¥è¯†åº“æœåŠ¡
    
    ç»“åˆå‘é‡æ•°æ®åº“å’ŒEmbeddingæœåŠ¡ï¼Œæä¾›ï¼š
    - æ™ºèƒ½æ–‡æœ¬å‘é‡åŒ–
    - å‘é‡å­˜å‚¨å’Œæ£€ç´¢
    - è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
    - çŸ¥è¯†ç®¡ç†å’Œç»´æŠ¤
    """
    
    def __init__(self, 
                 vector_db_config: Dict[str, Any] = None,
                 embedding_config: EmbeddingConfig = None):
        """åˆå§‹åŒ–é›†æˆçŸ¥è¯†åº“æœåŠ¡"""
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        db_config = vector_db_config or {}
        self.vector_db = VectorDatabaseService(
            persist_directory=db_config.get("persist_directory", "./data/chroma_db"),
            collection_name=db_config.get("collection_name", "knowledge_base")
        )
        
        # åˆå§‹åŒ–EmbeddingæœåŠ¡
        self.embedding_service = EmbeddingService(embedding_config)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_documents": 0,
            "total_searches": 0,
            "average_search_time": 0.0,
            "cache_hit_rate": 0.0
        }
        
        logger.info("âœ… é›†æˆçŸ¥è¯†åº“æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    async def add_knowledge(self, 
                           content: str, 
                           metadata: Dict[str, Any] = None,
                           doc_id: str = None,
                           model_name: str = None) -> str:
        """
        æ·»åŠ çŸ¥è¯†åˆ°çŸ¥è¯†åº“
        
        Args:
            content: çŸ¥è¯†å†…å®¹
            metadata: å…ƒæ•°æ®
            doc_id: æ–‡æ¡£ID
            model_name: ä½¿ç”¨çš„embeddingæ¨¡å‹
            
        Returns:
            æ–‡æ¡£ID
        """
        try:
            # 1. ç”Ÿæˆembedding
            embedding_result = await self.embedding_service.embed_text(
                content, model_name=model_name
            )
            
            # 2. å‡†å¤‡å…ƒæ•°æ®
            metadata = metadata or {}
            metadata.update({
                "embedding_model": embedding_result.model_name,
                "embedding_dimensions": len(embedding_result.embedding),
                "content_length": len(content),
                "added_at": datetime.now().isoformat()
            })
            
            # 3. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            doc_id = await self.vector_db.add_document(
                content=content,
                metadata=metadata,
                doc_id=doc_id,
                embedding=embedding_result.embedding
            )
            
            # 4. æ›´æ–°ç»Ÿè®¡
            self.stats["total_documents"] += 1
            
            logger.debug(f"âœ… å·²æ·»åŠ çŸ¥è¯†: {doc_id[:16]}... (é•¿åº¦: {len(content)})")
            return doc_id
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ çŸ¥è¯†å¤±è´¥: {e}")
            raise
    
    async def add_knowledge_batch(self, 
                                 knowledge_items: List[KnowledgeItem],
                                 model_name: str = None) -> List[str]:
        """
        æ‰¹é‡æ·»åŠ çŸ¥è¯†
        
        Args:
            knowledge_items: çŸ¥è¯†é¡¹åˆ—è¡¨
            model_name: ä½¿ç”¨çš„embeddingæ¨¡å‹
            
        Returns:
            æ–‡æ¡£IDåˆ—è¡¨
        """
        if not knowledge_items:
            return []
        
        try:
            # 1. æ‰¹é‡ç”Ÿæˆembeddings
            texts = [item.content for item in knowledge_items]
            embedding_results = await self.embedding_service.embed_texts(
                texts, model_name=model_name
            )
            
            # 2. å‡†å¤‡å‘é‡æ–‡æ¡£
            vector_documents = []
            for item, embedding_result in zip(knowledge_items, embedding_results):
                # æ›´æ–°å…ƒæ•°æ®
                metadata = item.metadata.copy()
                metadata.update({
                    "embedding_model": embedding_result.model_name,
                    "embedding_dimensions": len(embedding_result.embedding),
                    "content_length": len(item.content),
                    "added_at": item.created_at.isoformat()
                })
                
                # åˆ›å»ºå‘é‡æ–‡æ¡£
                vector_doc = VectorDocument(
                    id=item.doc_id or "",
                    content=item.content,
                    metadata=metadata,
                    embedding=embedding_result.embedding,
                    created_at=item.created_at
                )
                vector_documents.append(vector_doc)
            
            # 3. æ‰¹é‡å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            doc_ids = await self.vector_db.add_documents(vector_documents)
            
            # 4. æ›´æ–°ç»Ÿè®¡
            self.stats["total_documents"] += len(doc_ids)
            
            logger.info(f"âœ… å·²æ‰¹é‡æ·»åŠ  {len(doc_ids)} ä¸ªçŸ¥è¯†é¡¹")
            return doc_ids
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ·»åŠ çŸ¥è¯†å¤±è´¥: {e}")
            raise
    
    async def search_knowledge(self, 
                              query: str, 
                              top_k: int = 10,
                              filters: Dict[str, Any] = None,
                              min_score: float = 0.0) -> List[KnowledgeSearchResult]:
        """
        æœç´¢çŸ¥è¯†
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶
            min_score: æœ€å°ç›¸å…³æ€§åˆ†æ•°
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            start_time = datetime.now()
            
            # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding_result = await self.embedding_service.embed_text(query)
            
            # 2. å‘é‡æœç´¢
            search_results = await self.vector_db.search(
                query, 
                top_k=top_k, 
                filters=filters,
                query_embedding=query_embedding_result.embedding
            )
            
            # 3. è¿‡æ»¤ä½åˆ†ç»“æœ
            filtered_results = [
                result for result in search_results 
                if result.score >= min_score
            ]
            
            # 4. è½¬æ¢ç»“æœæ ¼å¼
            knowledge_results = []
            for result in filtered_results:
                knowledge_results.append(KnowledgeSearchResult(
                    content=result.document.content,
                    metadata=result.document.metadata,
                    score=result.score,
                    doc_id=result.document.id,
                    distance=result.distance
                ))
            
            # 5. æ›´æ–°ç»Ÿè®¡
            search_time = (datetime.now() - start_time).total_seconds()
            self.stats["total_searches"] += 1
            
            # æ›´æ–°å¹³å‡æœç´¢æ—¶é—´
            total_time = (self.stats["average_search_time"] * (self.stats["total_searches"] - 1) + search_time)
            self.stats["average_search_time"] = total_time / self.stats["total_searches"]
            
            logger.debug(f"ğŸ” çŸ¥è¯†æœç´¢å®Œæˆ: {len(knowledge_results)} ä¸ªç»“æœ ({search_time:.3f}s)")
            return knowledge_results
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†æœç´¢å¤±è´¥: {e}")
            raise
    
    async def get_knowledge(self, doc_id: str) -> Optional[KnowledgeItem]:
        """
        è·å–æŒ‡å®šçŸ¥è¯†
        
        Args:
            doc_id: æ–‡æ¡£ID
            
        Returns:
            çŸ¥è¯†é¡¹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            doc = await self.vector_db.get_document(doc_id)
            if doc:
                return KnowledgeItem(
                    content=doc.content,
                    metadata=doc.metadata,
                    doc_id=doc.id,
                    created_at=doc.created_at
                )
            return None
            
        except Exception as e:
            logger.error(f"âŒ è·å–çŸ¥è¯†å¤±è´¥: {e}")
            return None
    
    async def update_knowledge(self, 
                              doc_id: str, 
                              content: str = None,
                              metadata: Dict[str, Any] = None,
                              model_name: str = None) -> bool:
        """
        æ›´æ–°çŸ¥è¯†
        
        Args:
            doc_id: æ–‡æ¡£ID
            content: æ–°å†…å®¹
            metadata: æ–°å…ƒæ•°æ®
            model_name: embeddingæ¨¡å‹
            
        Returns:
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            # å¦‚æœæ›´æ–°äº†å†…å®¹ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆembedding
            if content is not None:
                embedding_result = await self.embedding_service.embed_text(
                    content, model_name=model_name
                )
                
                # æ›´æ–°å…ƒæ•°æ®
                if metadata is None:
                    metadata = {}
                metadata.update({
                    "embedding_model": embedding_result.model_name,
                    "embedding_dimensions": len(embedding_result.embedding),
                    "content_length": len(content),
                    "updated_at": datetime.now().isoformat()
                })
                
                # ç”±äºChromaDBçš„é™åˆ¶ï¼Œæˆ‘ä»¬éœ€è¦åˆ é™¤æ—§æ–‡æ¡£å¹¶æ·»åŠ æ–°æ–‡æ¡£
                await self.vector_db.delete_document(doc_id)
                await self.vector_db.add_document(
                    content=content,
                    metadata=metadata,
                    doc_id=doc_id,
                    embedding=embedding_result.embedding
                )
            else:
                # åªæ›´æ–°å…ƒæ•°æ®
                success = await self.vector_db.update_document(doc_id, metadata=metadata)
                return success
            
            logger.debug(f"âœ… å·²æ›´æ–°çŸ¥è¯†: {doc_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°çŸ¥è¯†å¤±è´¥: {e}")
            return False
    
    async def delete_knowledge(self, doc_id: str) -> bool:
        """
        åˆ é™¤çŸ¥è¯†
        
        Args:
            doc_id: æ–‡æ¡£ID
            
        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            success = await self.vector_db.delete_document(doc_id)
            if success:
                self.stats["total_documents"] = max(0, self.stats["total_documents"] - 1)
            return success
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤çŸ¥è¯†å¤±è´¥: {e}")
            return False
    
    async def clear_knowledge_base(self) -> bool:
        """æ¸…ç©ºçŸ¥è¯†åº“"""
        try:
            success = await self.vector_db.clear_collection()
            if success:
                self.stats["total_documents"] = 0
            return success
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥: {e}")
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        # è·å–å„ç»„ä»¶çš„ç»Ÿè®¡ä¿¡æ¯
        vector_db_stats = self.vector_db.get_stats()
        embedding_stats = self.embedding_service.get_stats()
        
        return {
            **self.stats,
            "vector_db": vector_db_stats,
            "embedding_service": embedding_stats,
            "cache_hit_rate": embedding_stats.get("cache_hit_rate", 0.0)
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æ£€æŸ¥å„ç»„ä»¶å¥åº·çŠ¶æ€
            vector_db_health = await self.vector_db.health_check()
            embedding_health = await self.embedding_service.health_check()
            
            # æµ‹è¯•å®Œæ•´æµç¨‹
            test_content = "è¿™æ˜¯ä¸€ä¸ªå¥åº·æ£€æŸ¥æµ‹è¯•"
            test_doc_id = await self.add_knowledge(test_content, {"test": True})
            
            # æœç´¢æµ‹è¯•
            search_results = await self.search_knowledge("å¥åº·æ£€æŸ¥", top_k=1)
            
            # æ¸…ç†æµ‹è¯•æ•°æ®
            await self.delete_knowledge(test_doc_id)
            
            return {
                "status": "healthy",
                "integrated_workflow": len(search_results) > 0,
                "vector_db_health": vector_db_health,
                "embedding_health": embedding_health,
                "stats": self.get_stats()
            }
            
        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return {
                "status": "unhealthy",
                "error": str(e)
            }


# å•ä¾‹å®ä¾‹
_knowledge_service_instance = None

def get_knowledge_service(vector_db_config: Dict[str, Any] = None,
                         embedding_config: EmbeddingConfig = None) -> IntegratedKnowledgeService:
    """è·å–é›†æˆçŸ¥è¯†åº“æœåŠ¡å•ä¾‹å®ä¾‹"""
    global _knowledge_service_instance
    if _knowledge_service_instance is None:
        _knowledge_service_instance = IntegratedKnowledgeService(vector_db_config, embedding_config)
    return _knowledge_service_instance 