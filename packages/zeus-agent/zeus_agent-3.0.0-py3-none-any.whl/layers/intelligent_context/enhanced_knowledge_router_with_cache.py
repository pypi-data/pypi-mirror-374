"""
é›†æˆè¯­ä¹‰ç¼“å­˜çš„å¢å¼ºçŸ¥è¯†è·¯ç”±å™¨

å°†è¯­ä¹‰ç¼“å­˜ç³»ç»Ÿé›†æˆåˆ°å¢å¼ºçŸ¥è¯†è·¯ç”±å™¨ä¸­ï¼Œå®ç°æ™ºèƒ½ç¼“å­˜å’Œè·¯ç”±çš„ååŒå·¥ä½œã€‚
åœ¨è·¯ç”±å†³ç­–å‰å…ˆæ£€æŸ¥ç¼“å­˜ï¼Œåœ¨ç”Ÿæˆå“åº”åæ™ºèƒ½ç¼“å­˜ï¼Œå¤§å¹…æå‡æ€§èƒ½å’Œé™ä½æˆæœ¬ã€‚

Author: ADC Team
Date: 2024-12-19
Version: 2.1.0
"""

import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Any
import logging

from .enhanced_knowledge_router import (
    EnhancedKnowledgeRouter, UserProfile, ConversationContext,
    KnowledgeSourceDecision, QueryAnalysis
)
from .semantic_cache import SemanticCache, CacheHitResult, CachePriority
from .intelligent_cache_strategy import (
    IntelligentCacheStrategy, CacheDecisionContext, CacheStrategy
)

logger = logging.getLogger(__name__)

class CacheEnhancedKnowledgeRouter(EnhancedKnowledgeRouter):
    """é›†æˆè¯­ä¹‰ç¼“å­˜çš„å¢å¼ºçŸ¥è¯†è·¯ç”±å™¨"""
    
    def __init__(self, config: Optional[Dict] = None):
        super().__init__(config)
        
        # åˆå§‹åŒ–è¯­ä¹‰ç¼“å­˜ç³»ç»Ÿ
        self.semantic_cache = SemanticCache(
            similarity_threshold=config.get('cache_similarity_threshold', 0.85),
            max_cache_size=config.get('max_cache_size', 10000)
        )
        
        # åˆå§‹åŒ–æ™ºèƒ½ç¼“å­˜ç­–ç•¥
        cache_strategy_type = config.get('cache_strategy', 'hybrid')
        self.cache_strategy = IntelligentCacheStrategy(
            strategy_type=CacheStrategy(cache_strategy_type),
            cost_threshold=config.get('cache_cost_threshold', 0.1),
            quality_threshold=config.get('cache_quality_threshold', 0.6)
        )
        
        # ç¼“å­˜ç»Ÿè®¡
        self.cache_stats = {
            'total_queries': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'total_cost_saved': 0.0,
            'total_time_saved': 0.0
        }
        
        logger.info("ğŸ¯ ç¼“å­˜å¢å¼ºçŸ¥è¯†è·¯ç”±å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """åˆå§‹åŒ–è·¯ç”±å™¨"""
        await super().initialize()
        await self.semantic_cache.initialize()
        logger.info("âœ… ç¼“å­˜å¢å¼ºçŸ¥è¯†è·¯ç”±å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    async def route_query(
        self,
        query: str,
        user_profile: Optional[UserProfile] = None,
        context: Optional[ConversationContext] = None
    ) -> KnowledgeSourceDecision:
        """è·¯ç”±æŸ¥è¯¢ï¼ˆé›†æˆç¼“å­˜ï¼‰"""
        start_time = datetime.now()
        self.cache_stats['total_queries'] += 1
        
        try:
            # ğŸ¯ æ­¥éª¤1: æ£€æŸ¥è¯­ä¹‰ç¼“å­˜
            cache_result = await self._check_semantic_cache(query, user_profile)
            
            if cache_result.hit:
                # ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
                decision = await self._create_cached_decision(cache_result, query)
                
                # æ›´æ–°ç»Ÿè®¡
                self.cache_stats['cache_hits'] += 1
                self.cache_stats['total_cost_saved'] += cache_result.cost_saved
                
                execution_time = (datetime.now() - start_time).total_seconds() * 1000
                self.cache_stats['total_time_saved'] += max(0, 2000 - execution_time)  # å‡è®¾æ­£å¸¸è·¯ç”±éœ€è¦2ç§’
                
                logger.info(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {query[:50]}... (èŠ‚çœæˆæœ¬: ${cache_result.cost_saved:.3f})")
                return decision
            
            # ğŸ” æ­¥éª¤2: ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæ­£å¸¸è·¯ç”±
            self.cache_stats['cache_misses'] += 1
            decision = await super().route_query(query, user_profile, context)
            
            # ğŸ—ƒï¸ æ­¥éª¤3: æ™ºèƒ½ç¼“å­˜å†³ç­–
            await self._intelligent_cache_response(query, decision, user_profile, start_time)
            
            return decision
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜å¢å¼ºè·¯ç”±å¤±è´¥: {e}")
            # é™çº§åˆ°åŸºç¡€è·¯ç”±
            return await super().route_query(query, user_profile, context)
    
    async def _check_semantic_cache(
        self,
        query: str,
        user_profile: Optional[UserProfile] = None
    ) -> CacheHitResult:
        """æ£€æŸ¥è¯­ä¹‰ç¼“å­˜"""
        try:
            user_role = user_profile.role if user_profile else None
            if user_role is None:
                return CacheHitResult(hit=False, reason="ç”¨æˆ·è§’è‰²æœªçŸ¥")
            
            return await self.semantic_cache.get_cached_response(query, user_role)
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜æ£€æŸ¥å¤±è´¥: {e}")
            return CacheHitResult(hit=False, reason=f"ç¼“å­˜æ£€æŸ¥é”™è¯¯: {e}")
    
    async def _create_cached_decision(
        self,
        cache_result: CacheHitResult,
        query: str
    ) -> KnowledgeSourceDecision:
        """åŸºäºç¼“å­˜ç»“æœåˆ›å»ºå†³ç­–"""
        from .knowledge_router import KnowledgeSourceType
        
        return KnowledgeSourceDecision(
            primary_source=KnowledgeSourceType.CACHE,  # éœ€è¦æ·»åŠ ç¼“å­˜æºç±»å‹
            secondary_sources=[],
            reasoning=f"ç¼“å­˜å‘½ä¸­ (ç›¸ä¼¼åº¦: {cache_result.similarity_score:.3f}) - {cache_result.entry.original_query[:50]}...",
            confidence=min(0.95, cache_result.similarity_score + 0.1),
            estimated_cost=0.001,  # ç¼“å­˜æˆæœ¬æä½
            expected_latency=0.1,
            metadata={
                'cache_hit': True,
                'original_query': cache_result.entry.original_query,
                'cache_entry_id': cache_result.entry.entry_id,
                'similarity_score': cache_result.similarity_score,
                'cached_response': cache_result.entry.response,
                'cache_timestamp': cache_result.entry.timestamp.isoformat(),
                'access_count': cache_result.entry.access_count
            }
        )
    
    async def _intelligent_cache_response(
        self,
        query: str,
        decision: KnowledgeSourceDecision,
        user_profile: Optional[UserProfile],
        start_time: datetime
    ):
        """æ™ºèƒ½ç¼“å­˜å“åº”"""
        try:
            if not user_profile:
                logger.debug("ğŸš« ç”¨æˆ·ç”»åƒç¼ºå¤±ï¼Œè·³è¿‡ç¼“å­˜")
                return
            
            # æ¨¡æ‹Ÿè·å–å“åº”å†…å®¹ï¼ˆåœ¨å®é™…å®ç°ä¸­ï¼Œè¿™åº”è¯¥ä»å†³ç­–æ‰§è¡Œç»“æœè·å–ï¼‰
            response_content = decision.metadata.get('generated_response', '')
            if not response_content:
                logger.debug("ğŸš« å“åº”å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ç¼“å­˜")
                return
            
            # è®¡ç®—å“åº”æ—¶é—´å’Œè´¨é‡åˆ†æ•°
            response_time = (datetime.now() - start_time).total_seconds()
            quality_score = min(decision.confidence * 1.1, 1.0)  # åŸºäºç½®ä¿¡åº¦ä¼°ç®—è´¨é‡
            
            # åˆ›å»ºç¼“å­˜å†³ç­–ä¸Šä¸‹æ–‡
            cache_context = CacheDecisionContext(
                query=query,
                response=response_content,
                user_role=user_profile.role,
                generation_cost=decision.estimated_cost,
                quality_score=quality_score,
                response_time=response_time,
                user_satisfaction=None,  # æš‚æ—¶æœªçŸ¥
                metadata={
                    'decision_confidence': decision.confidence,
                    'primary_source': decision.primary_source.value,
                    'reasoning': decision.reasoning
                }
            )
            
            # ä½¿ç”¨æ™ºèƒ½ç­–ç•¥å†³å®šæ˜¯å¦ç¼“å­˜
            cache_decision = await self.cache_strategy.make_cache_decision(cache_context)
            
            if cache_decision.should_cache:
                # æ‰§è¡Œç¼“å­˜
                success = await self.semantic_cache.cache_response(
                    query=query,
                    response=response_content,
                    user_role=user_profile.role,
                    cost_saved=cache_decision.expected_value,
                    quality_score=quality_score,
                    priority=cache_decision.priority,
                    ttl_seconds=cache_decision.ttl_seconds,
                    metadata={
                        'decision_reasoning': cache_decision.reasoning,
                        'decision_confidence': cache_decision.confidence,
                        'original_decision': decision.__dict__
                    }
                )
                
                if success:
                    logger.info(f"âœ… æ™ºèƒ½ç¼“å­˜æˆåŠŸ: {query[:50]}... (ä¼˜å…ˆçº§: {cache_decision.priority.value})")
                else:
                    logger.warning(f"âš ï¸ ç¼“å­˜å¤±è´¥: {query[:50]}...")
            else:
                logger.debug(f"ğŸš« è·³è¿‡ç¼“å­˜: {query[:50]}... - {cache_decision.reasoning}")
                
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½ç¼“å­˜å¤„ç†å¤±è´¥: {e}")
    
    async def provide_cache_feedback(
        self,
        query: str,
        user_satisfaction: float,
        user_profile: Optional[UserProfile] = None
    ):
        """æä¾›ç¼“å­˜åé¦ˆ"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°ç¼“å­˜è´¨é‡çš„åé¦ˆå­¦ä¹ 
            # æ ¹æ®ç”¨æˆ·æ»¡æ„åº¦è°ƒæ•´ç¼“å­˜ç­–ç•¥
            
            if user_satisfaction < 0.3:
                # ç”¨æˆ·ä¸æ»¡æ„ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç¼“å­˜ç­–ç•¥
                logger.info(f"ğŸ“‰ æ”¶åˆ°è´Ÿé¢åé¦ˆï¼Œç”¨æˆ·æ»¡æ„åº¦: {user_satisfaction}")
                
                # å¦‚æœæ˜¯ç¼“å­˜å“åº”å¯¼è‡´çš„ä¸æ»¡æ„ï¼Œå¯ä»¥è€ƒè™‘æ— æ•ˆåŒ–ç›¸å…³ç¼“å­˜
                if user_profile:
                    await self.semantic_cache.invalidate_cache(
                        query_pattern=query[:20],  # éƒ¨åˆ†æŸ¥è¯¢æ¨¡å¼
                        user_role=user_profile.role
                    )
            
            elif user_satisfaction > 0.8:
                # ç”¨æˆ·æ»¡æ„ï¼Œå¯ä»¥æé«˜ç›¸ä¼¼æŸ¥è¯¢çš„ç¼“å­˜ä¼˜å…ˆçº§
                logger.info(f"ğŸ“ˆ æ”¶åˆ°æ­£é¢åé¦ˆï¼Œç”¨æˆ·æ»¡æ„åº¦: {user_satisfaction}")
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜åé¦ˆå¤„ç†å¤±è´¥: {e}")
    
    async def get_cache_performance_report(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜æ€§èƒ½æŠ¥å‘Š"""
        try:
            # è·å–ç¼“å­˜ç»Ÿè®¡
            cache_stats = await self.semantic_cache.get_cache_stats()
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            hit_rate = self.cache_stats['cache_hits'] / max(self.cache_stats['total_queries'], 1)
            cost_efficiency = self.cache_stats['total_cost_saved'] / max(self.cache_stats['total_queries'], 1)
            time_efficiency = self.cache_stats['total_time_saved'] / max(self.cache_stats['total_queries'], 1)
            
            return {
                'cache_performance': {
                    'hit_rate': hit_rate,
                    'total_queries': self.cache_stats['total_queries'],
                    'cache_hits': self.cache_stats['cache_hits'],
                    'cache_misses': self.cache_stats['cache_misses'],
                    'cost_efficiency': cost_efficiency,
                    'time_efficiency': time_efficiency,
                    'total_cost_saved': self.cache_stats['total_cost_saved'],
                    'total_time_saved_seconds': self.cache_stats['total_time_saved'] / 1000
                },
                'cache_storage': {
                    'total_entries': cache_stats.total_entries,
                    'active_entries': cache_stats.active_entries,
                    'expired_entries': cache_stats.expired_entries,
                    'cache_size_mb': cache_stats.cache_size_mb,
                    'average_similarity': cache_stats.average_similarity
                },
                'cost_analysis': {
                    'cost_per_query_without_cache': 0.85,  # å‡è®¾å€¼
                    'cost_per_query_with_cache': cost_efficiency,
                    'cost_reduction_percentage': (1 - cost_efficiency / 0.85) * 100,
                    'monthly_cost_savings': self.cache_stats['total_cost_saved'] * 30  # å‡è®¾æœˆåº¦
                },
                'recommendations': await self._generate_cache_recommendations(hit_rate, cost_efficiency)
            }
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç¼“å­˜æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")
            return {'error': str(e)}
    
    async def _generate_cache_recommendations(
        self,
        hit_rate: float,
        cost_efficiency: float
    ) -> List[str]:
        """ç”Ÿæˆç¼“å­˜ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if hit_rate < 0.3:
            recommendations.append("å‘½ä¸­ç‡è¾ƒä½ï¼Œå»ºè®®é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ä»0.85åˆ°0.80")
            recommendations.append("è€ƒè™‘å¢åŠ ç¼“å­˜æ—¶é—´ï¼Œæé«˜ç¼“å­˜åˆ©ç”¨ç‡")
        
        if cost_efficiency < 0.1:
            recommendations.append("æˆæœ¬æ•ˆç‡è¾ƒä½ï¼Œå»ºè®®æé«˜é«˜æˆæœ¬æŸ¥è¯¢çš„ç¼“å­˜ä¼˜å…ˆçº§")
            recommendations.append("è€ƒè™‘å®æ–½æ›´æ¿€è¿›çš„ç¼“å­˜ç­–ç•¥")
        
        if hit_rate > 0.7:
            recommendations.append("ç¼“å­˜æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘æ‰©å¤§ç¼“å­˜å®¹é‡")
        
        if cost_efficiency > 0.5:
            recommendations.append("æˆæœ¬èŠ‚çœæ˜¾è‘—ï¼Œå»ºè®®ç»´æŒå½“å‰ç¼“å­˜ç­–ç•¥")
        
        return recommendations
    
    async def optimize_cache_strategy(self) -> Dict[str, Any]:
        """ä¼˜åŒ–ç¼“å­˜ç­–ç•¥"""
        try:
            # è·å–æ€§èƒ½æ•°æ®
            performance_report = await self.get_cache_performance_report()
            cache_performance = performance_report.get('cache_performance', {})
            
            # ä½¿ç”¨æ™ºèƒ½ç­–ç•¥è¿›è¡Œä¼˜åŒ–
            optimization_result = await self.cache_strategy.optimize_strategy(cache_performance)
            
            # ä¼˜åŒ–è¯­ä¹‰ç¼“å­˜
            cache_optimization = await self.semantic_cache.optimize_cache()
            
            return {
                'strategy_optimization': optimization_result,
                'cache_optimization': cache_optimization,
                'timestamp': datetime.now().isoformat(),
                'next_optimization': (datetime.now().timestamp() + 3600 * 24)  # 24å°æ—¶å
            }
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def get_router_info(self) -> Dict[str, Any]:
        """è·å–è·¯ç”±å™¨ä¿¡æ¯ï¼ˆæ‰©å±•ç‰ˆï¼‰"""
        base_info = super().get_router_info()
        
        # æ·»åŠ ç¼“å­˜ç›¸å…³ä¿¡æ¯
        cache_info = {
            'cache_enabled': True,
            'cache_similarity_threshold': self.semantic_cache.similarity_threshold,
            'cache_max_size': self.semantic_cache.max_cache_size,
            'cache_strategy': self.cache_strategy.strategy_type.value,
            'cache_stats': self.cache_stats
        }
        
        base_info.update(cache_info)
        base_info['version'] = '2.1.0'  # æ›´æ–°ç‰ˆæœ¬å·
        base_info['features'].append('semantic_cache')
        base_info['features'].append('intelligent_cache_strategy')
        
        return base_info

# å·¥å‚å‡½æ•°
def create_cache_enhanced_router(config: Optional[Dict] = None) -> CacheEnhancedKnowledgeRouter:
    """åˆ›å»ºç¼“å­˜å¢å¼ºçŸ¥è¯†è·¯ç”±å™¨"""
    default_config = {
        'cache_similarity_threshold': 0.85,
        'max_cache_size': 10000,
        'cache_strategy': 'hybrid',
        'cache_cost_threshold': 0.1,
        'cache_quality_threshold': 0.6
    }
    
    if config:
        default_config.update(config)
    
    return CacheEnhancedKnowledgeRouter(default_config) 