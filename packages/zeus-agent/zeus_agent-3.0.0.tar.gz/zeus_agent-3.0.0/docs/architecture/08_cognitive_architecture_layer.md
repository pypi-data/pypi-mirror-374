# 06. è®¤çŸ¥æž¶æž„å±‚ (Cognitive Architecture Layer)

> **Agentæ™ºèƒ½çš„æ ¸å¿ƒ - æ„ŸçŸ¥ã€æŽ¨ç†ã€è®°å¿†ã€å­¦ä¹ ã€é€šä¿¡çš„å®Œæ•´è®¤çŸ¥æ¨¡åž‹**

## ðŸŽ¯ å±‚çº§æ¦‚è¿°

è®¤çŸ¥æž¶æž„å±‚æ˜¯Agent Development Centerçš„**æ™ºèƒ½æ ¸å¿ƒ**ï¼ŒåŸºäºŽè®¤çŸ¥ç§‘å­¦ç†è®ºæž„å»ºå®Œæ•´çš„Agentè®¤çŸ¥æ¨¡åž‹ã€‚å®ƒä¸ä»…ä»…æ˜¯ç®€å•çš„LLMè°ƒç”¨å°è£…ï¼Œè€Œæ˜¯ä¸€ä¸ªå…·æœ‰**æ„ŸçŸ¥-æŽ¨ç†-è¡ŒåŠ¨**å®Œæ•´å¾ªçŽ¯çš„æ™ºèƒ½ç³»ç»Ÿã€‚

### æ ¸å¿ƒèŒè´£
1. **ðŸ‘ï¸ æ„ŸçŸ¥ (Perception)**: å¤šæ¨¡æ€ä¿¡æ¯å¤„ç†å’Œç†è§£
2. **ðŸ§  æŽ¨ç† (Reasoning)**: é€»è¾‘æŽ¨ç†ã€å†³ç­–åˆ¶å®šã€è®¡åˆ’ç”Ÿæˆ
3. **ðŸ’¾ è®°å¿† (Memory)**: å¤šå±‚æ¬¡è®°å¿†ç®¡ç†å’ŒçŸ¥è¯†å­˜å‚¨
4. **ðŸ“š å­¦ä¹  (Learning)**: è‡ªé€‚åº”å­¦ä¹ å’ŒæŠ€èƒ½èŽ·å–
5. **ðŸ’¬ é€šä¿¡ (Communication)**: Agenté—´åä½œå’Œä¿¡æ¯äº¤æ¢

### è®¾è®¡ç†å¿µ
- **è®¤çŸ¥ç§‘å­¦æŒ‡å¯¼**: åŸºäºŽäººç±»è®¤çŸ¥ç†è®ºçš„æž¶æž„è®¾è®¡
- **æ¨¡å—åŒ–ç»„è£…**: å¯æ’æ‹”çš„è®¤çŸ¥æ¨¡å—ï¼Œæ”¯æŒçµæ´»ç»„åˆ
- **è‡ªä¸»è¿›åŒ–**: å…·å¤‡è‡ªä¸»å­¦ä¹ å’Œé€‚åº”èƒ½åŠ›
- **å¯è§‚æµ‹æ€§**: è®¤çŸ¥è¿‡ç¨‹é€æ˜Žå¯è§ï¼Œæ”¯æŒè°ƒè¯•åˆ†æž

---

## ðŸ‘ï¸ æ„ŸçŸ¥å¼•æ“Ž (Perception Engine)

> **Agentçš„"æ„Ÿå®˜ç³»ç»Ÿ" - å°†å¤šæ¨¡æ€ä¿¡æ¯è½¬åŒ–ä¸ºå¯ç†è§£çš„å†…éƒ¨è¡¨å¾**

### æ¦‚å¿µå’Œä½œç”¨

æ„ŸçŸ¥å¼•æ“Žè´Ÿè´£å¤„ç†å’Œç†è§£æ¥è‡ªå¤–éƒ¨ä¸–ç•Œçš„å„ç§ä¿¡æ¯ï¼Œå°†åŽŸå§‹è¾“å…¥è½¬åŒ–ä¸ºAgentå¯ä»¥å¤„ç†çš„å†…éƒ¨è¡¨å¾ã€‚å®ƒæ˜¯Agentä¸Žå¤–ç•Œäº¤äº’çš„ç¬¬ä¸€é“å…³å£ã€‚

**æ ¸å¿ƒä½œç”¨**:
- **å¤šæ¨¡æ€å¤„ç†**: ç»Ÿä¸€å¤„ç†æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰ä¸åŒç±»åž‹çš„è¾“å…¥
- **è¯­ä¹‰ç†è§£**: æå–è¾“å…¥å†…å®¹çš„æ·±å±‚è¯­ä¹‰å’Œæ„å›¾
- **ä¸Šä¸‹æ–‡åˆ†æž**: ç»“åˆåŽ†å²ä¿¡æ¯å’Œå½“å‰çŽ¯å¢ƒè¿›è¡Œç»¼åˆåˆ†æž
- **æ„å›¾è¯†åˆ«**: å‡†ç¡®è¯†åˆ«ç”¨æˆ·æ„å›¾å’Œä»»åŠ¡è¦æ±‚

### æ ¸å¿ƒç»„ä»¶

#### ðŸ“ æ–‡æœ¬å¤„ç†å™¨ (Text Processor)

**æ¦‚å¿µ**: å¤„ç†å’Œç†è§£æ–‡æœ¬ç±»åž‹çš„è¾“å…¥ä¿¡æ¯

**ä½œç”¨**:
- æ–‡æœ¬é¢„å¤„ç†å’Œæ¸…ç†
- è¯­è¨€æ£€æµ‹å’Œç¼–ç å¤„ç†
- è¯­æ³•åˆ†æžå’Œå¥æ³•è§£æž
- æƒ…æ„Ÿå’Œè¯­è°ƒåˆ†æž

**å®žçŽ°ç¤ºä¾‹**:
```python
class TextProcessor:
    """æ–‡æœ¬æ„ŸçŸ¥å¤„ç†å™¨"""
    
    def __init__(self):
        self.language_detector = LanguageDetector()
        self.syntax_parser = SyntaxParser()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.intent_classifier = IntentClassifier()
        
    async def process(self, text: str, context: ProcessingContext) -> TextPerceptionResult:
        """å¤„ç†æ–‡æœ¬è¾“å…¥"""
        
        # é¢„å¤„ç†
        cleaned_text = await self.preprocess_text(text)
        
        # è¯­è¨€æ£€æµ‹
        language_info = await self.language_detector.detect(cleaned_text)
        
        # è¯­æ³•åˆ†æž
        syntax_tree = await self.syntax_parser.parse(
            text=cleaned_text,
            language=language_info.language
        )
        
        # è¯­ä¹‰åˆ†æž
        semantic_info = await self.extract_semantic_info(cleaned_text, syntax_tree)
        
        # æƒ…æ„Ÿåˆ†æž
        sentiment = await self.sentiment_analyzer.analyze(cleaned_text)
        
        # æ„å›¾åˆ†ç±»
        intent = await self.intent_classifier.classify(
            text=cleaned_text,
            context=context,
            semantic_info=semantic_info
        )
        
        return TextPerceptionResult(
            original_text=text,
            cleaned_text=cleaned_text,
            language_info=language_info,
            syntax_tree=syntax_tree,
            semantic_info=semantic_info,
            sentiment=sentiment,
            intent=intent,
            confidence=self.calculate_confidence([
                language_info.confidence,
                semantic_info.confidence,
                intent.confidence
            ])
        )
    
    async def extract_semantic_info(self, text: str, syntax_tree: SyntaxTree) -> SemanticInfo:
        """æå–è¯­ä¹‰ä¿¡æ¯"""
        return SemanticInfo(
            entities=await self.extract_entities(text),
            relations=await self.extract_relations(text, syntax_tree),
            concepts=await self.extract_concepts(text),
            topics=await self.extract_topics(text),
            key_phrases=await self.extract_key_phrases(text),
            semantic_embedding=await self.generate_embedding(text)
        )
```

#### ðŸ‘ï¸ è§†è§‰å¤„ç†å™¨ (Vision Processor)

**æ¦‚å¿µ**: å¤„ç†å’Œç†è§£å›¾åƒã€è§†é¢‘ç­‰è§†è§‰ä¿¡æ¯

**ä½œç”¨**:
- å›¾åƒå†…å®¹è¯†åˆ«å’Œåˆ†æž
- åœºæ™¯ç†è§£å’Œå¯¹è±¡æ£€æµ‹
- æ–‡å­—è¯†åˆ«(OCR)å’Œä¿¡æ¯æå–
- è§†è§‰-è¯­è¨€è”åˆç†è§£

**å®žçŽ°ç¤ºä¾‹**:
```python
class VisionProcessor:
    """è§†è§‰æ„ŸçŸ¥å¤„ç†å™¨"""
    
    def __init__(self):
        self.object_detector = ObjectDetector()
        self.scene_analyzer = SceneAnalyzer()
        self.ocr_engine = OCREngine()
        self.vision_language_model = VisionLanguageModel()
        
    async def process(self, image_data: bytes, context: ProcessingContext) -> VisionPerceptionResult:
        """å¤„ç†è§†è§‰è¾“å…¥"""
        
        # å›¾åƒé¢„å¤„ç†
        processed_image = await self.preprocess_image(image_data)
        
        # å¯¹è±¡æ£€æµ‹
        objects = await self.object_detector.detect(processed_image)
        
        # åœºæ™¯åˆ†æž
        scene_info = await self.scene_analyzer.analyze(processed_image)
        
        # OCRæ–‡å­—è¯†åˆ«
        text_regions = await self.ocr_engine.extract_text(processed_image)
        
        # è§†è§‰-è¯­è¨€ç†è§£
        vl_description = await self.vision_language_model.describe(
            image=processed_image,
            context=context.text_context
        )
        
        # ç»¼åˆåˆ†æž
        visual_analysis = await self.comprehensive_analysis(
            objects, scene_info, text_regions, vl_description
        )
        
        return VisionPerceptionResult(
            image_metadata=self.extract_metadata(image_data),
            detected_objects=objects,
            scene_analysis=scene_info,
            extracted_text=text_regions,
            description=vl_description,
            visual_analysis=visual_analysis,
            confidence=self.calculate_vision_confidence([
                objects.confidence,
                scene_info.confidence,
                vl_description.confidence
            ])
        )
```

#### ðŸŽµ éŸ³é¢‘å¤„ç†å™¨ (Audio Processor)

**æ¦‚å¿µ**: å¤„ç†å’Œç†è§£éŸ³é¢‘ä¿¡æ¯

**ä½œç”¨**:
- è¯­éŸ³è¯†åˆ«å’Œè½¬å½•
- éŸ³é¢‘å†…å®¹åˆ†æž
- è¯´è¯äººè¯†åˆ«
- æƒ…æ„Ÿå’Œè¯­è°ƒæ£€æµ‹

**å®žçŽ°ç¤ºä¾‹**:
```python
class AudioProcessor:
    """éŸ³é¢‘æ„ŸçŸ¥å¤„ç†å™¨"""
    
    def __init__(self):
        self.speech_recognizer = SpeechRecognizer()
        self.speaker_identifier = SpeakerIdentifier()
        self.audio_analyzer = AudioAnalyzer()
        self.emotion_detector = AudioEmotionDetector()
        
    async def process(self, audio_data: bytes, context: ProcessingContext) -> AudioPerceptionResult:
        """å¤„ç†éŸ³é¢‘è¾“å…¥"""
        
        # éŸ³é¢‘é¢„å¤„ç†
        processed_audio = await self.preprocess_audio(audio_data)
        
        # è¯­éŸ³è¯†åˆ«
        transcription = await self.speech_recognizer.transcribe(
            audio=processed_audio,
            language=context.expected_language
        )
        
        # è¯´è¯äººè¯†åˆ«
        speaker_info = await self.speaker_identifier.identify(processed_audio)
        
        # éŸ³é¢‘ç‰¹å¾åˆ†æž
        audio_features = await self.audio_analyzer.analyze_features(processed_audio)
        
        # æƒ…æ„Ÿæ£€æµ‹
        emotion = await self.emotion_detector.detect_emotion(
            audio=processed_audio,
            transcription=transcription.text
        )
        
        return AudioPerceptionResult(
            audio_metadata=self.extract_audio_metadata(audio_data),
            transcription=transcription,
            speaker_info=speaker_info,
            audio_features=audio_features,
            detected_emotion=emotion,
            confidence=self.calculate_audio_confidence([
                transcription.confidence,
                speaker_info.confidence,
                emotion.confidence
            ])
        )
```

#### ðŸ” ä¸Šä¸‹æ–‡åˆ†æžå™¨ (Context Analyzer)

**æ¦‚å¿µ**: åˆ†æžå’Œç†è§£å½“å‰çš„ä¸Šä¸‹æ–‡çŽ¯å¢ƒ

**ä½œç”¨**:
- åŽ†å²ä¿¡æ¯æ•´åˆ
- çŽ¯å¢ƒçŠ¶æ€åˆ†æž
- ä»»åŠ¡ä¸Šä¸‹æ–‡ç†è§£
- å¤šæ¨¡æ€ä¿¡æ¯èžåˆ

**å®žçŽ°ç¤ºä¾‹**:
```python
class ContextAnalyzer:
    """ä¸Šä¸‹æ–‡åˆ†æžå™¨"""
    
    def __init__(self):
        self.history_analyzer = HistoryAnalyzer()
        self.environment_monitor = EnvironmentMonitor()
        self.multimodal_fusion = MultimodalFusion()
        self.temporal_analyzer = TemporalAnalyzer()
        
    async def analyze_context(self, 
                            current_input: PerceptionInput,
                            history: List[ContextEntry],
                            environment: EnvironmentState) -> ContextAnalysisResult:
        """ç»¼åˆåˆ†æžå½“å‰ä¸Šä¸‹æ–‡"""
        
        # åŽ†å²ä¿¡æ¯åˆ†æž
        history_analysis = await self.history_analyzer.analyze(
            history=history,
            current_input=current_input
        )
        
        # çŽ¯å¢ƒçŠ¶æ€åˆ†æž
        env_analysis = await self.environment_monitor.analyze(environment)
        
        # å¤šæ¨¡æ€ä¿¡æ¯èžåˆ
        fused_info = await self.multimodal_fusion.fuse(
            text_info=current_input.text_perception,
            vision_info=current_input.vision_perception,
            audio_info=current_input.audio_perception
        )
        
        # æ—¶åºåˆ†æž
        temporal_patterns = await self.temporal_analyzer.analyze_patterns(
            history=history,
            current_time=datetime.now()
        )
        
        # ç»¼åˆä¸Šä¸‹æ–‡ç†è§£
        context_understanding = await self.synthesize_understanding(
            history_analysis, env_analysis, fused_info, temporal_patterns
        )
        
        return ContextAnalysisResult(
            history_analysis=history_analysis,
            environment_analysis=env_analysis,
            multimodal_fusion=fused_info,
            temporal_patterns=temporal_patterns,
            context_understanding=context_understanding,
            confidence=self.calculate_context_confidence([
                history_analysis.confidence,
                env_analysis.confidence,
                fused_info.confidence
            ])
        )
```

---

## ðŸ§  æŽ¨ç†å¼•æ“Ž (Reasoning Engine)

> **Agentçš„"å¤§è„‘" - é€»è¾‘æŽ¨ç†ã€å†³ç­–åˆ¶å®šã€è®¡åˆ’ç”Ÿæˆ**

### æ¦‚å¿µå’Œä½œç”¨

æŽ¨ç†å¼•æ“Žæ˜¯Agentè®¤çŸ¥æž¶æž„çš„æ ¸å¿ƒï¼Œè´Ÿè´£åŸºäºŽæ„ŸçŸ¥åˆ°çš„ä¿¡æ¯è¿›è¡Œé€»è¾‘æŽ¨ç†ã€å†³ç­–åˆ¶å®šå’Œè¡ŒåŠ¨è®¡åˆ’ã€‚å®ƒé›†æˆäº†å¤šç§æŽ¨ç†æ–¹æ³•ï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„æŽ¨ç†ä»»åŠ¡ã€‚

**æ ¸å¿ƒä½œç”¨**:
- **é€»è¾‘æŽ¨ç†**: åŸºäºŽå·²çŸ¥ä¿¡æ¯è¿›è¡Œé€»è¾‘æŽ¨å¯¼
- **å†³ç­–åˆ¶å®š**: åœ¨å¤šä¸ªé€‰é¡¹ä¸­åšå‡ºæœ€ä¼˜å†³ç­–
- **è®¡åˆ’ç”Ÿæˆ**: åˆ¶å®šè¾¾æˆç›®æ ‡çš„è¡ŒåŠ¨è®¡åˆ’
- **é—®é¢˜æ±‚è§£**: åˆ†è§£å¤æ‚é—®é¢˜å¹¶å¯»æ‰¾è§£å†³æ–¹æ¡ˆ

### æ ¸å¿ƒç»„ä»¶

#### ðŸ” é€»è¾‘æŽ¨ç†å™¨ (Logical Reasoner)

**æ¦‚å¿µ**: æ‰§è¡Œå„ç§å½¢å¼çš„é€»è¾‘æŽ¨ç†

**ä½œç”¨**:
- æ¼”ç»ŽæŽ¨ç†: ä»Žä¸€èˆ¬åˆ°ç‰¹æ®Š
- å½’çº³æŽ¨ç†: ä»Žç‰¹æ®Šåˆ°ä¸€èˆ¬
- æº¯å› æŽ¨ç†: å¯»æ‰¾æœ€ä½³è§£é‡Š
- ç±»æ¯”æŽ¨ç†: åŸºäºŽç›¸ä¼¼æ€§æŽ¨ç†

**å®žçŽ°ç¤ºä¾‹**:
```python
class LogicalReasoner:
    """é€»è¾‘æŽ¨ç†å™¨"""
    
    def __init__(self):
        self.deductive_engine = DeductiveEngine()
        self.inductive_engine = InductiveEngine()
        self.abductive_engine = AbductiveEngine()
        self.analogical_engine = AnalogicalEngine()
        self.knowledge_base = KnowledgeBase()
        
    async def reason(self, 
                   premises: List[Premise], 
                   reasoning_type: ReasoningType,
                   context: ReasoningContext) -> ReasoningResult:
        """æ‰§è¡Œé€»è¾‘æŽ¨ç†"""
        
        if reasoning_type == ReasoningType.DEDUCTIVE:
            return await self.deductive_reasoning(premises, context)
        elif reasoning_type == ReasoningType.INDUCTIVE:
            return await self.inductive_reasoning(premises, context)
        elif reasoning_type == ReasoningType.ABDUCTIVE:
            return await self.abductive_reasoning(premises, context)
        elif reasoning_type == ReasoningType.ANALOGICAL:
            return await self.analogical_reasoning(premises, context)
        else:
            return await self.hybrid_reasoning(premises, context)
    
    async def deductive_reasoning(self, premises: List[Premise], context: ReasoningContext) -> ReasoningResult:
        """æ¼”ç»ŽæŽ¨ç†: ä»Žä¸€èˆ¬è§„å¾‹æŽ¨å¯¼å…·ä½“ç»“è®º"""
        
        # æž„å»ºæŽ¨ç†é“¾
        reasoning_chain = []
        current_premises = premises.copy()
        
        while True:
            # æŸ¥æ‰¾é€‚ç”¨çš„æŽ¨ç†è§„åˆ™
            applicable_rules = await self.knowledge_base.find_applicable_rules(current_premises)
            
            if not applicable_rules:
                break
            
            # é€‰æ‹©æœ€ä½³è§„åˆ™
            best_rule = self.select_best_rule(applicable_rules, context)
            
            # åº”ç”¨æŽ¨ç†è§„åˆ™
            new_conclusion = await best_rule.apply(current_premises)
            
            reasoning_chain.append(ReasoningStep(
                rule=best_rule,
                premises=current_premises.copy(),
                conclusion=new_conclusion,
                confidence=new_conclusion.confidence
            ))
            
            # æ›´æ–°å‰æé›†åˆ
            current_premises.append(new_conclusion)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if self.is_goal_reached(new_conclusion, context.goal):
                break
        
        return ReasoningResult(
            reasoning_type=ReasoningType.DEDUCTIVE,
            reasoning_chain=reasoning_chain,
            final_conclusion=reasoning_chain[-1].conclusion if reasoning_chain else None,
            confidence=self.calculate_chain_confidence(reasoning_chain),
            metadata={
                "steps_count": len(reasoning_chain),
                "rules_applied": [step.rule.name for step in reasoning_chain]
            }
        )
```

#### ðŸŽ¯ å†³ç­–åˆ¶å®šå™¨ (Decision Maker)

**æ¦‚å¿µ**: åœ¨å¤šä¸ªé€‰é¡¹ä¸­åšå‡ºæœ€ä¼˜å†³ç­–

**ä½œç”¨**:
- é€‰é¡¹è¯„ä¼°å’Œæ¯”è¾ƒ
- å¤šå‡†åˆ™å†³ç­–åˆ†æž
- é£Žé™©è¯„ä¼°å’Œç®¡ç†
- å†³ç­–ä¼˜åŒ–å’Œé€‰æ‹©

**å®žçŽ°ç¤ºä¾‹**:
```python
class DecisionMaker:
    """å†³ç­–åˆ¶å®šå™¨"""
    
    def __init__(self):
        self.option_evaluator = OptionEvaluator()
        self.criteria_analyzer = CriteriaAnalyzer()
        self.risk_assessor = RiskAssessor()
        self.optimization_engine = OptimizationEngine()
        
    async def make_decision(self,
                          options: List[DecisionOption],
                          criteria: List[DecisionCriteria],
                          context: DecisionContext) -> DecisionResult:
        """åˆ¶å®šå†³ç­–"""
        
        # è¯„ä¼°æ¯ä¸ªé€‰é¡¹
        option_evaluations = []
        for option in options:
            evaluation = await self.evaluate_option(option, criteria, context)
            option_evaluations.append(evaluation)
        
        # å¤šå‡†åˆ™å†³ç­–åˆ†æž
        mcdm_result = await self.multi_criteria_analysis(
            option_evaluations, criteria, context
        )
        
        # é£Žé™©è¯„ä¼°
        risk_analysis = await self.assess_risks(option_evaluations, context)
        
        # å†³ç­–ä¼˜åŒ–
        optimal_choice = await self.optimization_engine.optimize(
            options=option_evaluations,
            criteria=criteria,
            risk_profile=risk_analysis,
            context=context
        )
        
        return DecisionResult(
            recommended_option=optimal_choice.option,
            confidence=optimal_choice.confidence,
            reasoning=optimal_choice.reasoning,
            option_evaluations=option_evaluations,
            risk_analysis=risk_analysis,
            decision_metadata={
                "criteria_weights": criteria.get_weights(),
                "decision_method": optimal_choice.method,
                "alternatives_considered": len(options)
            }
        )
    
    async def evaluate_option(self,
                            option: DecisionOption,
                            criteria: List[DecisionCriteria],
                            context: DecisionContext) -> OptionEvaluation:
        """è¯„ä¼°å•ä¸ªé€‰é¡¹"""
        
        criterion_scores = {}
        
        for criterion in criteria:
            # è®¡ç®—è¯¥å‡†åˆ™ä¸‹çš„å¾—åˆ†
            score = await self.calculate_criterion_score(option, criterion, context)
            criterion_scores[criterion.name] = score
        
        # è®¡ç®—åŠ æƒæ€»åˆ†
        weighted_score = sum(
            score * criterion.weight 
            for criterion, score in zip(criteria, criterion_scores.values())
        )
        
        # è¯„ä¼°ä¼˜åŠ¿å’ŒåŠ£åŠ¿
        strengths = self.identify_strengths(option, criterion_scores)
        weaknesses = self.identify_weaknesses(option, criterion_scores)
        
        return OptionEvaluation(
            option=option,
            criterion_scores=criterion_scores,
            weighted_score=weighted_score,
            strengths=strengths,
            weaknesses=weaknesses,
            overall_assessment=self.generate_assessment(option, criterion_scores)
        )
```

#### ðŸ“‹ è®¡åˆ’å¼•æ“Ž (Planning Engine)

**æ¦‚å¿µ**: åˆ¶å®šè¾¾æˆç›®æ ‡çš„è¡ŒåŠ¨è®¡åˆ’

**ä½œç”¨**:
- ç›®æ ‡åˆ†è§£å’Œä»»åŠ¡è§„åˆ’
- èµ„æºåˆ†é…å’Œè°ƒåº¦
- è®¡åˆ’ä¼˜åŒ–å’Œè°ƒæ•´
- æ‰§è¡Œç›‘æŽ§å’Œåé¦ˆ

**å®žçŽ°ç¤ºä¾‹**:
```python
class PlanningEngine:
    """è®¡åˆ’ç”Ÿæˆå¼•æ“Ž"""
    
    def __init__(self):
        self.goal_decomposer = GoalDecomposer()
        self.task_scheduler = TaskScheduler()
        self.resource_allocator = ResourceAllocator()
        self.plan_optimizer = PlanOptimizer()
        
    async def generate_plan(self,
                          goal: Goal,
                          constraints: List[Constraint],
                          resources: ResourcePool,
                          context: PlanningContext) -> ExecutionPlan:
        """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        
        # ç›®æ ‡åˆ†è§£
        subgoals = await self.goal_decomposer.decompose(goal, context)
        
        # ä»»åŠ¡è¯†åˆ«å’Œä¾èµ–åˆ†æž
        tasks = []
        for subgoal in subgoals:
            task_set = await self.identify_tasks_for_goal(subgoal, context)
            tasks.extend(task_set)
        
        # ä¾èµ–å…³ç³»åˆ†æž
        dependencies = await self.analyze_dependencies(tasks)
        
        # èµ„æºéœ€æ±‚åˆ†æž
        resource_requirements = await self.analyze_resource_requirements(tasks)
        
        # ä»»åŠ¡è°ƒåº¦
        schedule = await self.task_scheduler.schedule(
            tasks=tasks,
            dependencies=dependencies,
            constraints=constraints,
            resources=resources
        )
        
        # èµ„æºåˆ†é…
        resource_allocation = await self.resource_allocator.allocate(
            tasks=tasks,
            requirements=resource_requirements,
            available_resources=resources,
            schedule=schedule
        )
        
        # è®¡åˆ’ä¼˜åŒ–
        optimized_plan = await self.plan_optimizer.optimize(
            tasks=tasks,
            schedule=schedule,
            resource_allocation=resource_allocation,
            constraints=constraints,
            optimization_criteria=context.optimization_criteria
        )
        
        return ExecutionPlan(
            goal=goal,
            subgoals=subgoals,
            tasks=tasks,
            dependencies=dependencies,
            schedule=optimized_plan.schedule,
            resource_allocation=optimized_plan.resource_allocation,
            execution_order=optimized_plan.execution_order,
            contingency_plans=await self.generate_contingency_plans(optimized_plan),
            plan_metadata={
                "total_tasks": len(tasks),
                "estimated_duration": optimized_plan.estimated_duration,
                "resource_utilization": optimized_plan.resource_utilization,
                "risk_level": optimized_plan.risk_assessment.level
            }
        )
```

#### ðŸŒ³ æ€ç»´æ ‘æŽ¨ç†å™¨ (Tree of Thought Reasoner)

**æ¦‚å¿µ**: æŽ¢ç´¢å¤šç§æŽ¨ç†è·¯å¾„çš„é«˜çº§æŽ¨ç†æ–¹æ³•

**ä½œç”¨**:
- å¹¶è¡ŒæŽ¢ç´¢å¤šä¸ªæ€ç»´è·¯å¾„
- è¯„ä¼°å’Œé€‰æ‹©æœ€ä¼˜è·¯å¾„
- å¤„ç†å¤æ‚çš„æŽ¨ç†é—®é¢˜
- æé«˜æŽ¨ç†çš„å‡†ç¡®æ€§

**å®žçŽ°ç¤ºä¾‹**:
```python
class TreeOfThoughtReasoner:
    """æ€ç»´æ ‘æŽ¨ç†å™¨ - æŽ¢ç´¢å¤šç§æŽ¨ç†è·¯å¾„"""
    
    def __init__(self):
        self.thought_generator = ThoughtGenerator()
        self.thought_evaluator = ThoughtEvaluator()
        self.path_selector = PathSelector()
        self.tree_builder = ThoughtTreeBuilder()
        
    async def reason_with_tree_search(self, 
                                    problem: str, 
                                    depth: int = 3,
                                    breadth: int = 3) -> ReasoningResult:
        """ä½¿ç”¨æ€ç»´æ ‘è¿›è¡Œæ·±åº¦æŽ¨ç†"""
        
        # åˆ›å»ºæ ¹èŠ‚ç‚¹
        root = ThoughtNode(
            content=problem,
            depth=0,
            path_id="root",
            confidence=1.0
        )
        
        thought_tree = ThoughtTree(root)
        
        # å¹¿åº¦ä¼˜å…ˆæœç´¢ç”Ÿæˆæ€ç»´æ ‘
        for current_depth in range(depth):
            current_level_nodes = thought_tree.get_nodes_at_depth(current_depth)
            
            for node in current_level_nodes:
                # ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆå¤šä¸ªæ€ç»´åˆ†æ”¯
                thoughts = await self.thought_generator.generate_thoughts(
                    parent_thought=node.content,
                    num_thoughts=breadth,
                    context={
                        "depth": current_depth,
                        "path": node.get_path(),
                        "problem": problem
                    }
                )
                
                # è¯„ä¼°æ¯ä¸ªæ€ç»´çš„è´¨é‡
                for i, thought in enumerate(thoughts):
                    # è¯„ä¼°æ€ç»´è´¨é‡
                    evaluation = await self.thought_evaluator.evaluate(
                        thought=thought,
                        parent=node,
                        problem_context=problem
                    )
                    
                    # åˆ›å»ºå­èŠ‚ç‚¹
                    child_node = ThoughtNode(
                        content=thought,
                        depth=current_depth + 1,
                        parent=node,
                        path_id=f"{node.path_id}_{i}",
                        confidence=evaluation.confidence,
                        quality_score=evaluation.quality_score,
                        reasoning_type=evaluation.reasoning_type
                    )
                    
                    # æ·»åŠ åˆ°æ ‘ä¸­
                    thought_tree.add_node(child_node)
                    node.add_child(child_node)
        
        # ä½¿ç”¨å¯å‘å¼æœç´¢æ‰¾åˆ°æœ€ä¼˜è·¯å¾„
        best_paths = await self.find_best_reasoning_paths(
            thought_tree, 
            top_k=3
        )
        
        # é€‰æ‹©æœ€ç»ˆç­”æ¡ˆ
        final_answer = await self.synthesize_final_answer(best_paths)
        
        return ReasoningResult(
            conclusion=final_answer.content,
            confidence=final_answer.confidence,
            reasoning_chain=self.extract_reasoning_chain(best_paths[0]),
            reasoning_type=ReasoningType.TREE_OF_THOUGHT,
            metadata={
                "tree_depth": depth,
                "tree_breadth": breadth,
                "total_nodes": thought_tree.node_count(),
                "paths_explored": len(thought_tree.get_all_paths()),
                "best_paths": len(best_paths)
            },
            thought_tree=thought_tree  # ä¿å­˜å®Œæ•´çš„æ€ç»´æ ‘ç”¨äºŽåˆ†æž
        )
    
    async def find_best_reasoning_paths(self, 
                                      thought_tree: ThoughtTree, 
                                      top_k: int = 3) -> List[ThoughtPath]:
        """æ‰¾åˆ°æœ€ä½³æŽ¨ç†è·¯å¾„"""
        
        all_paths = thought_tree.get_all_leaf_paths()
        path_evaluations = []
        
        for path in all_paths:
            # è¯„ä¼°æ•´æ¡è·¯å¾„çš„è´¨é‡
            path_score = await self.evaluate_path_quality(path)
            
            path_evaluations.append(PathEvaluation(
                path=path,
                overall_score=path_score.overall_score,
                coherence_score=path_score.coherence_score,
                logic_score=path_score.logic_score,
                completeness_score=path_score.completeness_score,
                confidence=path_score.confidence
            ))
        
        # æŒ‰ç»¼åˆå¾—åˆ†æŽ’åº
        path_evaluations.sort(key=lambda x: x.overall_score, reverse=True)
        
        return [eval.path for eval in path_evaluations[:top_k]]
```

---

## ðŸ’¾ è®°å¿†ç³»ç»Ÿ (Memory System)

> **Agentçš„"è®°å¿†å®«æ®¿" - å¤šå±‚æ¬¡è®°å¿†ç®¡ç†å’ŒçŸ¥è¯†å­˜å‚¨**

### æ¦‚å¿µå’Œä½œç”¨

è®°å¿†ç³»ç»Ÿä¸ºAgentæä¾›å¤šå±‚æ¬¡çš„ä¿¡æ¯å­˜å‚¨å’Œæ£€ç´¢èƒ½åŠ›ï¼Œæ¨¡æ‹Ÿäººç±»çš„è®°å¿†æœºåˆ¶ï¼Œæ”¯æŒçŸ­æœŸè®°å¿†ã€é•¿æœŸè®°å¿†å’Œä¸åŒç±»åž‹çš„çŸ¥è¯†å­˜å‚¨ã€‚

**æ ¸å¿ƒä½œç”¨**:
- **ä¿¡æ¯æŒä¹…åŒ–**: ä¿å­˜é‡è¦çš„ç»éªŒå’ŒçŸ¥è¯†
- **çŸ¥è¯†æ£€ç´¢**: å¿«é€Ÿæ‰¾åˆ°ç›¸å…³çš„åŽ†å²ä¿¡æ¯
- **å­¦ä¹ æ”¯æŒ**: ä¸ºå­¦ä¹ è¿‡ç¨‹æä¾›è®°å¿†åŸºç¡€
- **ä¸Šä¸‹æ–‡ç»´æŠ¤**: ç»´æŠ¤å¯¹è¯å’Œä»»åŠ¡çš„è¿žç»­æ€§

### æ ¸å¿ƒç»„ä»¶

#### ðŸ”„ å·¥ä½œè®°å¿† (Working Memory)

**æ¦‚å¿µ**: ä¸´æ—¶å­˜å‚¨å’Œå¤„ç†å½“å‰ä»»åŠ¡ç›¸å…³ä¿¡æ¯ï¼ŒåŸºäºŽMiller's 7Â±2è§„å¾‹è®¾è®¡

**ä½œç”¨**:
- ç»´æŠ¤å½“å‰ä»»åŠ¡çš„ä¸Šä¸‹æ–‡
- ä¸´æ—¶å­˜å‚¨ä¸­é—´è®¡ç®—ç»“æžœ
- æ”¯æŒæ³¨æ„åŠ›æœºåˆ¶
- ç®¡ç†è®¤çŸ¥è´Ÿè½½
- å®žçŽ°çŸ­æœŸçŠ¶æ€ç®¡ç†
- æä¾›å®žæ—¶ä¿¡æ¯ç¼“å­˜

**å®žçŽ°ç¤ºä¾‹**:
```python
class WorkingMemory:
    """å·¥ä½œè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self, capacity: int = 7):  # åŸºäºŽMiller's 7Â±2 è§„å¾‹
        self.capacity = capacity
        self.active_items: List[MemoryItem] = []
        self.attention_weights: Dict[str, float] = {}
        self.decay_factor = 0.95  # è®°å¿†è¡°å‡å› å­
        
    async def store_item(self, item: MemoryItem, attention_weight: float = 1.0):
        """å­˜å‚¨è®°å¿†é¡¹"""
        
        # æ£€æŸ¥å®¹é‡é™åˆ¶
        if len(self.active_items) >= self.capacity:
            # ç§»é™¤æ³¨æ„åŠ›æƒé‡æœ€ä½Žçš„é¡¹
            await self.evict_least_attended_item()
        
        # æ·»åŠ æ–°é¡¹
        item.activation_level = attention_weight
        item.timestamp = datetime.now()
        self.active_items.append(item)
        self.attention_weights[item.id] = attention_weight
        
        # æ›´æ–°å…¶ä»–é¡¹çš„æ¿€æ´»æ°´å¹³
        await self.update_activation_levels()
    
    async def retrieve_relevant_items(self, query: str, top_k: int = 3) -> List[MemoryItem]:
        """æ£€ç´¢ç›¸å…³è®°å¿†é¡¹"""
        
        relevance_scores = []
        
        for item in self.active_items:
            # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
            semantic_similarity = await self.calculate_semantic_similarity(query, item.content)
            attention_weight = self.attention_weights.get(item.id, 0.0)
            temporal_factor = self.calculate_temporal_factor(item.timestamp)
            
            # ç»¼åˆå¾—åˆ†
            relevance_score = (
                semantic_similarity * 0.5 +
                attention_weight * 0.3 +
                temporal_factor * 0.2
            )
            
            relevance_scores.append((item, relevance_score))
        
        # æŽ’åºå¹¶è¿”å›žtop-k
        relevance_scores.sort(key=lambda x: x[1], reverse=True)
        return [item for item, score in relevance_scores[:top_k]]
    
    async def update_attention(self, item_id: str, new_weight: float):
        """æ›´æ–°æ³¨æ„åŠ›æƒé‡"""
        if item_id in self.attention_weights:
            self.attention_weights[item_id] = new_weight
            
            # æ›´æ–°å¯¹åº”é¡¹çš„æ¿€æ´»æ°´å¹³
            for item in self.active_items:
                if item.id == item_id:
                    item.activation_level = new_weight
                    break
```

#### ðŸ“š æƒ…æ™¯è®°å¿† (Episodic Memory)

**æ¦‚å¿µ**: å­˜å‚¨å…·ä½“çš„äº‹ä»¶å’Œç»åŽ†ï¼Œæ”¯æŒè·¨ä¼šè¯çš„æŒä¹…åŒ–è®°å¿†

**ä½œç”¨**:
- è®°å½•ç‰¹å®šçš„äº¤äº’åŽ†å²
- æ”¯æŒç»éªŒå›žé¡¾å’Œå­¦ä¹ 
- æä¾›ä¸Šä¸‹æ–‡å‚è€ƒ
- æ”¯æŒå› æžœå…³ç³»åˆ†æž
- å­˜å‚¨å¯¹è¯åŽ†å²è®°å½•
- ç»´æŠ¤ä»»åŠ¡æ‰§è¡Œè½¨è¿¹
- æ”¯æŒç»éªŒäº‹ä»¶å­˜å‚¨

**å®žçŽ°ç¤ºä¾‹**:
```python
class EpisodicMemory:
    """æƒ…èŠ‚è®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.episodes: List[Episode] = []
        self.episode_index = EpisodeIndex()
        self.retrieval_engine = EpisodeRetrievalEngine()
        
    async def store_episode(self, episode: Episode):
        """å­˜å‚¨æƒ…èŠ‚è®°å¿†"""
        
        # å¢žå¼ºæƒ…èŠ‚ä¿¡æ¯
        enhanced_episode = await self.enhance_episode(episode)
        
        # å­˜å‚¨åˆ°è®°å¿†åº“
        self.episodes.append(enhanced_episode)
        
        # æ›´æ–°ç´¢å¼•
        await self.episode_index.add_episode(enhanced_episode)
        
        # è§¦å‘è®°å¿†æ•´åˆ
        await self.trigger_memory_consolidation(enhanced_episode)
    
    async def retrieve_similar_episodes(self, 
                                      query_episode: Episode, 
                                      similarity_threshold: float = 0.7,
                                      max_results: int = 5) -> List[EpisodeMatch]:
        """æ£€ç´¢ç›¸ä¼¼æƒ…èŠ‚"""
        
        matches = []
        
        for stored_episode in self.episodes:
            # è®¡ç®—æƒ…èŠ‚ç›¸ä¼¼æ€§
            similarity = await self.calculate_episode_similarity(
                query_episode, stored_episode
            )
            
            if similarity >= similarity_threshold:
                matches.append(EpisodeMatch(
                    episode=stored_episode,
                    similarity_score=similarity,
                    matching_aspects=self.identify_matching_aspects(
                        query_episode, stored_episode
                    )
                ))
        
        # æŒ‰ç›¸ä¼¼æ€§æŽ’åº
        matches.sort(key=lambda x: x.similarity_score, reverse=True)
        return matches[:max_results]
    
    async def enhance_episode(self, episode: Episode) -> Episode:
        """å¢žå¼ºæƒ…èŠ‚ä¿¡æ¯"""
        
        # æå–å…³é”®ä¿¡æ¯
        key_entities = await self.extract_entities(episode.description)
        
        # è¯†åˆ«æƒ…æ„Ÿè‰²å½©
        emotional_tone = await self.analyze_emotional_tone(episode)
        
        # åˆ†æžå› æžœå…³ç³»
        causal_relations = await self.identify_causal_relations(episode)
        
        # è®¡ç®—é‡è¦æ€§è¯„åˆ†
        importance_score = await self.calculate_importance(episode)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = await self.generate_episode_summary(episode)
        
        return Episode(
            id=episode.id,
            timestamp=episode.timestamp,
            description=episode.description,
            participants=episode.participants,
            context=episode.context,
            outcome=episode.outcome,
            # å¢žå¼ºä¿¡æ¯
            key_entities=key_entities,
            emotional_tone=emotional_tone,
            causal_relations=causal_relations,
            importance_score=importance_score,
            summary=summary,
            embedding=await self.generate_episode_embedding(episode)
        )
```

#### ðŸ§  è¯­ä¹‰è®°å¿† (Semantic Memory)

**æ¦‚å¿µ**: å­˜å‚¨ä¸€èˆ¬æ€§çŸ¥è¯†å’Œæ¦‚å¿µ

**ä½œç”¨**:
- å­˜å‚¨äº‹å®žæ€§çŸ¥è¯†
- ç»´æŠ¤æ¦‚å¿µå…³ç³»ç½‘ç»œ
- æ”¯æŒæŽ¨ç†å’Œç†è§£
- æä¾›çŸ¥è¯†æ£€ç´¢æœåŠ¡

**å®žçŽ°ç¤ºä¾‹**:
```python
class SemanticMemory:
    """è¯­ä¹‰è®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.knowledge_graph = KnowledgeGraph()
        self.concept_embeddings = ConceptEmbeddingSpace()
        self.fact_database = FactDatabase()
        self.relation_extractor = RelationExtractor()
        
    async def store_knowledge(self, knowledge: Knowledge):
        """å­˜å‚¨è¯­ä¹‰çŸ¥è¯†"""
        
        if isinstance(knowledge, Fact):
            await self.store_fact(knowledge)
        elif isinstance(knowledge, Concept):
            await self.store_concept(knowledge)
        elif isinstance(knowledge, Relation):
            await self.store_relation(knowledge)
        else:
            await self.store_complex_knowledge(knowledge)
    
    async def store_concept(self, concept: Concept):
        """å­˜å‚¨æ¦‚å¿µçŸ¥è¯†"""
        
        # ç”Ÿæˆæ¦‚å¿µåµŒå…¥
        embedding = await self.concept_embeddings.generate_embedding(concept)
        
        # æ·»åŠ åˆ°çŸ¥è¯†å›¾è°±
        await self.knowledge_graph.add_concept_node(
            concept_id=concept.id,
            name=concept.name,
            definition=concept.definition,
            attributes=concept.attributes,
            embedding=embedding
        )
        
        # è¯†åˆ«ä¸ŽçŽ°æœ‰æ¦‚å¿µçš„å…³ç³»
        related_concepts = await self.find_related_concepts(concept)
        
        for related_concept, relation_type in related_concepts:
            await self.knowledge_graph.add_relation(
                source=concept.id,
                target=related_concept.id,
                relation_type=relation_type,
                confidence=self.calculate_relation_confidence(concept, related_concept)
            )
    
    async def query_knowledge(self, query: KnowledgeQuery) -> KnowledgeQueryResult:
        """æŸ¥è¯¢è¯­ä¹‰çŸ¥è¯†"""
        
        if query.query_type == QueryType.FACTUAL:
            return await self.query_facts(query)
        elif query.query_type == QueryType.CONCEPTUAL:
            return await self.query_concepts(query)
        elif query.query_type == QueryType.RELATIONAL:
            return await self.query_relations(query)
        else:
            return await self.complex_query(query)
    
    async def query_concepts(self, query: KnowledgeQuery) -> KnowledgeQueryResult:
        """æŸ¥è¯¢æ¦‚å¿µçŸ¥è¯†"""
        
        # è§£æžæŸ¥è¯¢æ„å›¾
        query_intent = await self.parse_query_intent(query.text)
        
        # æŸ¥æ‰¾ç›¸å…³æ¦‚å¿µ
        if query_intent.type == "definition":
            # æŸ¥æ‰¾æ¦‚å¿µå®šä¹‰
            concepts = await self.knowledge_graph.find_concepts_by_name(
                query_intent.target_concept
            )
            
            results = []
            for concept in concepts:
                results.append(KnowledgeItem(
                    type="concept_definition",
                    content=concept.definition,
                    confidence=concept.confidence,
                    source=concept.source
                ))
        
        elif query_intent.type == "relation":
            # æŸ¥æ‰¾æ¦‚å¿µå…³ç³»
            relations = await self.knowledge_graph.find_relations(
                source=query_intent.source_concept,
                target=query_intent.target_concept,
                relation_type=query_intent.relation_type
            )
            
            results = []
            for relation in relations:
                results.append(KnowledgeItem(
                    type="concept_relation",
                    content=f"{relation.source} {relation.type} {relation.target}",
                    confidence=relation.confidence,
                    metadata=relation.metadata
                ))
        
        return KnowledgeQueryResult(
            query=query,
            results=results,
            total_results=len(results),
            processing_time=self.calculate_processing_time()
        )
```

#### âš™ï¸ ç¨‹åºè®°å¿† (Procedural Memory)

**æ¦‚å¿µ**: å­˜å‚¨æŠ€èƒ½ã€æµç¨‹å’Œæ“ä½œæ¨¡å¼ï¼Œæ”¯æŒè‡ªåŠ¨åŒ–æ‰§è¡Œ

**ä½œç”¨**:
- å­˜å‚¨æŠ€èƒ½å’Œæµç¨‹
- ç»´æŠ¤å·¥å…·ä½¿ç”¨æ¨¡å¼
- æ”¯æŒå†³ç­–ç­–ç•¥åº“
- å®žçŽ°è‡ªåŠ¨åŒ–æ“ä½œ
- ä¼˜åŒ–æ‰§è¡Œæ•ˆçŽ‡

**å®žçŽ°ç¤ºä¾‹**:
```python
class ProceduralMemory:
    """ç¨‹åºè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.skill_registry = SkillRegistry()
        self.workflow_templates = WorkflowTemplateManager()
        self.decision_patterns = DecisionPatternLibrary()
        self.tool_usage_patterns = ToolUsagePatternManager()
        
    async def store_skill(self, skill: Skill):
        """å­˜å‚¨æŠ€èƒ½"""
        
        # æŠ€èƒ½éªŒè¯
        validated_skill = await self.validate_skill(skill)
        
        # ç”ŸæˆæŠ€èƒ½åµŒå…¥
        skill_embedding = await self.generate_skill_embedding(validated_skill)
        
        # å­˜å‚¨åˆ°æŠ€èƒ½æ³¨å†Œè¡¨
        await self.skill_registry.register_skill(
            skill_id=validated_skill.id,
            name=validated_skill.name,
            description=validated_skill.description,
            parameters=validated_skill.parameters,
            implementation=validated_skill.implementation,
            embedding=skill_embedding,
            performance_metrics=validated_skill.performance_metrics
        )
        
        # æ›´æ–°ç›¸å…³æŠ€èƒ½å…³ç³»
        await self.update_skill_relationships(validated_skill)
    
    async def retrieve_relevant_skills(self, task: UniversalTask, top_k: int = 5) -> List[SkillMatch]:
        """æ£€ç´¢ç›¸å…³æŠ€èƒ½"""
        
        # åˆ†æžä»»åŠ¡éœ€æ±‚
        task_requirements = await self.analyze_task_requirements(task)
        
        # æŠ€èƒ½åŒ¹é…
        skill_matches = []
        for skill in await self.skill_registry.get_all_skills():
            match_score = await self.calculate_skill_match_score(
                task_requirements, skill
            )
            
            if match_score > 0.5:  # åŒ¹é…é˜ˆå€¼
                skill_matches.append(SkillMatch(
                    skill=skill,
                    match_score=match_score,
                    applicability_score=await self.calculate_applicability(skill, task)
                ))
        
        # æŽ’åºå¹¶è¿”å›žtop-k
        skill_matches.sort(key=lambda x: x.match_score, reverse=True)
        return skill_matches[:top_k]
    
    async def store_workflow_template(self, template: WorkflowTemplate):
        """å­˜å‚¨å·¥ä½œæµæ¨¡æ¿"""
        
        # æ¨¡æ¿ä¼˜åŒ–
        optimized_template = await self.optimize_workflow_template(template)
        
        # å­˜å‚¨æ¨¡æ¿
        await self.workflow_templates.store_template(optimized_template)
        
        # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
        await self.update_template_usage_stats(optimized_template)
```

#### ðŸ§  å…ƒè®°å¿† (Meta Memory)

**æ¦‚å¿µ**: ç®¡ç†è®°å¿†ç³»ç»Ÿæœ¬èº«ï¼Œå®žçŽ°è®°å¿†çš„è‡ªæˆ‘ä¼˜åŒ–

**ä½œç”¨**:
- è®°å¿†ç®¡ç†ç­–ç•¥
- è®°å¿†æ£€ç´¢ä¼˜åŒ–
- è®°å¿†è´¨é‡è¯„ä¼°
- è®°å¿†ç³»ç»Ÿè‡ªæˆ‘æ”¹è¿›
- è®°å¿†ç­–ç•¥å­¦ä¹ 

**å®žçŽ°ç¤ºä¾‹**:
```python
class MetaMemory:
    """å…ƒè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.memory_policies = MemoryPolicyManager()
        self.retrieval_optimizer = RetrievalOptimizer()
        self.quality_assessor = MemoryQualityAssessor()
        self.learning_engine = MemoryLearningEngine()
        
    async def optimize_memory_retrieval(self, query: MemoryQuery) -> OptimizedRetrievalStrategy:
        """ä¼˜åŒ–è®°å¿†æ£€ç´¢ç­–ç•¥"""
        
        # åˆ†æžæŸ¥è¯¢ç‰¹å¾
        query_features = await self.analyze_query_features(query)
        
        # é€‰æ‹©æœ€ä½³æ£€ç´¢ç­–ç•¥
        retrieval_strategy = await self.select_optimal_strategy(query_features)
        
        # ä¼˜åŒ–æ£€ç´¢å‚æ•°
        optimized_params = await self.optimize_retrieval_parameters(
            strategy=retrieval_strategy,
            query_features=query_features
        )
        
        return OptimizedRetrievalStrategy(
            strategy=retrieval_strategy,
            parameters=optimized_params,
            expected_performance=await self.predict_retrieval_performance(
                strategy=retrieval_strategy,
                parameters=optimized_params
            )
        )
    
    async def assess_memory_quality(self, memory_item: MemoryItem) -> MemoryQualityReport:
        """è¯„ä¼°è®°å¿†è´¨é‡"""
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        relevance_score = await self.calculate_relevance_score(memory_item)
        accuracy_score = await self.calculate_accuracy_score(memory_item)
        completeness_score = await self.calculate_completeness_score(memory_item)
        consistency_score = await self.calculate_consistency_score(memory_item)
        
        # ç»¼åˆè´¨é‡è¯„åˆ†
        overall_quality = self.calculate_overall_quality([
            relevance_score,
            accuracy_score,
            completeness_score,
            consistency_score
        ])
        
        return MemoryQualityReport(
            memory_id=memory_item.id,
            relevance_score=relevance_score,
            accuracy_score=accuracy_score,
            completeness_score=completeness_score,
            consistency_score=consistency_score,
            overall_quality=overall_quality,
            improvement_suggestions=await self.generate_improvement_suggestions(memory_item)
        )
    
    async def learn_memory_patterns(self, memory_usage_data: List[MemoryUsageRecord]):
        """å­¦ä¹ è®°å¿†ä½¿ç”¨æ¨¡å¼"""
        
        # åˆ†æžä½¿ç”¨æ¨¡å¼
        usage_patterns = await self.analyze_usage_patterns(memory_usage_data)
        
        # è¯†åˆ«ä¼˜åŒ–æœºä¼š
        optimization_opportunities = await self.identify_optimization_opportunities(usage_patterns)
        
        # æ›´æ–°è®°å¿†ç­–ç•¥
        await self.update_memory_policies(optimization_opportunities)
        
        # ä¼˜åŒ–æ£€ç´¢ç®—æ³•
        await self.optimize_retrieval_algorithms(usage_patterns)
```

---

## ðŸ“š å­¦ä¹ æ¨¡å— (Learning Module)

> **Agentçš„"æˆé•¿å¼•æ“Ž" - è‡ªé€‚åº”å­¦ä¹ å’ŒæŠ€èƒ½èŽ·å–**

### æ¦‚å¿µå’Œä½œç”¨

å­¦ä¹ æ¨¡å—ä½¿Agentå…·å¤‡æŒç»­å­¦ä¹ å’Œè‡ªæˆ‘æ”¹è¿›çš„èƒ½åŠ›ï¼Œé€šè¿‡ä¸åŒçš„å­¦ä¹ æ–¹å¼èŽ·å–æ–°çŸ¥è¯†ã€æ”¹è¿›æ€§èƒ½ã€é€‚åº”çŽ¯å¢ƒå˜åŒ–ã€‚

**æ ¸å¿ƒä½œç”¨**:
- **æŠ€èƒ½èŽ·å–**: å­¦ä¹ æ–°çš„æŠ€èƒ½å’Œèƒ½åŠ›
- **æ€§èƒ½ä¼˜åŒ–**: é€šè¿‡ç»éªŒæ”¹è¿›æ‰§è¡Œæ•ˆæžœ
- **çŸ¥è¯†æ›´æ–°**: æŒç»­æ›´æ–°å’Œå®Œå–„çŸ¥è¯†åº“
- **é€‚åº”æ€§è°ƒæ•´**: æ ¹æ®çŽ¯å¢ƒå˜åŒ–è°ƒæ•´è¡Œä¸º

### æ ¸å¿ƒç»„ä»¶

#### ðŸŽ¯ ç›‘ç£å­¦ä¹  (Supervised Learning)

**æ¦‚å¿µ**: åŸºäºŽæ ‡æ³¨æ•°æ®è¿›è¡Œå­¦ä¹ 

**ä½œç”¨**:
- ä»Žç”¨æˆ·åé¦ˆä¸­å­¦ä¹ 
- æ”¹è¿›ä»»åŠ¡æ‰§è¡Œè´¨é‡
- å­¦ä¹ æ–°çš„åˆ†ç±»å’Œé¢„æµ‹ä»»åŠ¡
- ä¼˜åŒ–å†³ç­–ç­–ç•¥

**å®žçŽ°ç¤ºä¾‹**:
```python
class SupervisedLearning:
    """ç›‘ç£å­¦ä¹ æ¨¡å—"""
    
    def __init__(self):
        self.training_data_collector = TrainingDataCollector()
        self.model_trainer = ModelTrainer()
        self.performance_evaluator = PerformanceEvaluator()
        self.model_registry = ModelRegistry()
        
    async def learn_from_feedback(self, 
                                task: UniversalTask,
                                agent_response: UniversalResult,
                                user_feedback: UserFeedback):
        """ä»Žç”¨æˆ·åé¦ˆä¸­å­¦ä¹ """
        
        # æ”¶é›†è®­ç»ƒæ•°æ®
        training_example = await self.training_data_collector.create_example(
            input_data=task,
            agent_output=agent_response,
            ground_truth=user_feedback.corrected_response,
            feedback_score=user_feedback.satisfaction_score
        )
        
        # æ·»åŠ åˆ°è®­ç»ƒé›†
        await self.training_data_collector.add_example(training_example)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒ
        if await self.should_retrain():
            await self.retrain_model(task.task_type)
    
    async def retrain_model(self, task_type: TaskType):
        """é‡æ–°è®­ç»ƒæ¨¡åž‹"""
        
        # èŽ·å–è®­ç»ƒæ•°æ®
        training_data = await self.training_data_collector.get_training_data(task_type)
        
        # æ•°æ®é¢„å¤„ç†
        processed_data = await self.preprocess_training_data(training_data)
        
        # æ¨¡åž‹è®­ç»ƒ
        trained_model = await self.model_trainer.train(
            data=processed_data,
            model_type=self.select_model_type(task_type),
            hyperparameters=self.get_hyperparameters(task_type)
        )
        
        # æ¨¡åž‹è¯„ä¼°
        evaluation_result = await self.performance_evaluator.evaluate(
            model=trained_model,
            test_data=processed_data.test_set
        )
        
        # å¦‚æžœæ€§èƒ½æå‡ï¼Œåˆ™æ›´æ–°æ¨¡åž‹
        if evaluation_result.performance > self.get_current_performance(task_type):
            await self.model_registry.update_model(task_type, trained_model)
            
            # è®°å½•å­¦ä¹ æˆæžœ
            await self.record_learning_achievement(
                task_type=task_type,
                old_performance=self.get_current_performance(task_type),
                new_performance=evaluation_result.performance,
                improvement=evaluation_result.performance - self.get_current_performance(task_type)
            )
```

#### ðŸ”„ å¼ºåŒ–å­¦ä¹  (Reinforcement Learning)

**æ¦‚å¿µ**: é€šè¿‡è¯•é”™å’Œå¥–åŠ±ä¿¡å·è¿›è¡Œå­¦ä¹ 

**ä½œç”¨**:
- ä¼˜åŒ–å†³ç­–ç­–ç•¥
- å­¦ä¹ æœ€ä¼˜è¡ŒåŠ¨åºåˆ—
- é€‚åº”åŠ¨æ€çŽ¯å¢ƒ
- æœ€å¤§åŒ–é•¿æœŸå¥–åŠ±

**å®žçŽ°ç¤ºä¾‹**:
```python
class ReinforcementLearning:
    """å¼ºåŒ–å­¦ä¹ æ¨¡å—"""
    
    def __init__(self):
        self.policy_network = PolicyNetwork()
        self.value_network = ValueNetwork()
        self.experience_buffer = ExperienceBuffer()
        self.reward_calculator = RewardCalculator()
        
    async def learn_from_experience(self, 
                                  state: AgentState,
                                  action: AgentAction,
                                  next_state: AgentState,
                                  reward: float,
                                  done: bool):
        """ä»Žç»éªŒä¸­å­¦ä¹ """
        
        # å­˜å‚¨ç»éªŒ
        experience = Experience(
            state=state,
            action=action,
            reward=reward,
            next_state=next_state,
            done=done,
            timestamp=datetime.now()
        )
        
        await self.experience_buffer.store(experience)
        
        # å¦‚æžœç¼“å†²åŒºè¶³å¤Ÿå¤§ï¼Œå¼€å§‹è®­ç»ƒ
        if len(self.experience_buffer) >= self.min_buffer_size:
            await self.train_policy()
    
    async def train_policy(self):
        """è®­ç»ƒç­–ç•¥ç½‘ç»œ"""
        
        # é‡‡æ ·ç»éªŒæ‰¹æ¬¡
        batch = await self.experience_buffer.sample_batch(self.batch_size)
        
        # è®¡ç®—ç›®æ ‡å€¼
        targets = await self.calculate_targets(batch)
        
        # æ›´æ–°ä»·å€¼ç½‘ç»œ
        value_loss = await self.value_network.update(
            states=[exp.state for exp in batch],
            targets=targets
        )
        
        # è®¡ç®—ç­–ç•¥æ¢¯åº¦
        advantages = await self.calculate_advantages(batch, targets)
        
        # æ›´æ–°ç­–ç•¥ç½‘ç»œ
        policy_loss = await self.policy_network.update(
            states=[exp.state for exp in batch],
            actions=[exp.action for exp in batch],
            advantages=advantages
        )
        
        # è®°å½•è®­ç»ƒæŒ‡æ ‡
        await self.record_training_metrics(
            value_loss=value_loss,
            policy_loss=policy_loss,
            average_reward=np.mean([exp.reward for exp in batch])
        )
    
    async def select_action(self, state: AgentState, exploration_rate: float = 0.1) -> AgentAction:
        """é€‰æ‹©è¡ŒåŠ¨ï¼ˆå¸¦æŽ¢ç´¢ï¼‰"""
        
        # Îµ-è´ªå©ªç­–ç•¥
        if random.random() < exploration_rate:
            # éšæœºæŽ¢ç´¢
            return await self.sample_random_action(state)
        else:
            # åˆ©ç”¨å½“å‰ç­–ç•¥
            action_probabilities = await self.policy_network.predict(state)
            return self.sample_action_from_probabilities(action_probabilities)
```

#### ðŸ§  å…ƒå­¦ä¹  (Meta Learning)

**æ¦‚å¿µ**: å­¦ä¹ å¦‚ä½•å­¦ä¹ çš„èƒ½åŠ›

**ä½œç”¨**:
- å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡
- ä¼˜åŒ–å­¦ä¹ ç­–ç•¥
- è¿ç§»å­¦ä¹ ç»éªŒ
- æé«˜å­¦ä¹ æ•ˆçŽ‡

**å®žçŽ°ç¤ºä¾‹**:
```python
class MetaLearning:
    """å…ƒå­¦ä¹ æ¨¡å—"""
    
    def __init__(self):
        self.meta_learner = MetaLearner()
        self.task_similarity_analyzer = TaskSimilarityAnalyzer()
        self.learning_strategy_selector = LearningStrategySelector()
        self.transfer_learning_engine = TransferLearningEngine()
        
    async def adapt_to_new_task(self, 
                              new_task: UniversalTask,
                              few_shot_examples: List[TaskExample]) -> AdaptationResult:
        """å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡"""
        
        # åˆ†æžä»»åŠ¡ç‰¹å¾
        task_features = await self.analyze_task_features(new_task)
        
        # æŸ¥æ‰¾ç›¸ä¼¼çš„åŽ†å²ä»»åŠ¡
        similar_tasks = await self.task_similarity_analyzer.find_similar_tasks(
            task_features, similarity_threshold=0.7
        )
        
        # é€‰æ‹©æœ€ä½³å­¦ä¹ ç­–ç•¥
        learning_strategy = await self.learning_strategy_selector.select_strategy(
            new_task=new_task,
            similar_tasks=similar_tasks,
            available_examples=few_shot_examples
        )
        
        # æ‰§è¡Œå¿«é€Ÿé€‚åº”
        adaptation_result = await self.execute_adaptation(
            task=new_task,
            strategy=learning_strategy,
            examples=few_shot_examples,
            similar_tasks=similar_tasks
        )
        
        return adaptation_result
    
    async def execute_adaptation(self,
                               task: UniversalTask,
                               strategy: LearningStrategy,
                               examples: List[TaskExample],
                               similar_tasks: List[Task]) -> AdaptationResult:
        """æ‰§è¡Œå¿«é€Ÿé€‚åº”"""
        
        if strategy.type == StrategyType.FEW_SHOT_LEARNING:
            return await self.few_shot_adaptation(task, examples)
        
        elif strategy.type == StrategyType.TRANSFER_LEARNING:
            return await self.transfer_learning_adaptation(task, similar_tasks)
        
        elif strategy.type == StrategyType.GRADIENT_BASED_META_LEARNING:
            return await self.gradient_based_adaptation(task, examples)
        
        else:
            return await self.hybrid_adaptation(task, examples, similar_tasks, strategy)
    
    async def few_shot_adaptation(self, 
                                task: UniversalTask, 
                                examples: List[TaskExample]) -> AdaptationResult:
        """å°‘æ ·æœ¬å­¦ä¹ é€‚åº”"""
        
        # æž„å»ºæç¤ºæ¨¡æ¿
        prompt_template = await self.build_few_shot_prompt(task, examples)
        
        # å¿«é€Ÿå¾®è°ƒ
        adapted_model = await self.meta_learner.quick_adapt(
            base_model=self.get_base_model(task.task_type),
            examples=examples,
            adaptation_steps=strategy.adaptation_steps
        )
        
        # éªŒè¯é€‚åº”æ•ˆæžœ
        validation_result = await self.validate_adaptation(adapted_model, task)
        
        return AdaptationResult(
            adapted_model=adapted_model,
            prompt_template=prompt_template,
            validation_score=validation_result.score,
            adaptation_time=validation_result.adaptation_time,
            confidence=validation_result.confidence
        )
```

---

## ðŸ’¬ é€šä¿¡ç®¡ç†å™¨ (Communication Manager)

> **Agentçš„"ç¥žç»ç½‘ç»œ" - å®žçŽ°Agenté—´çš„åä½œå’Œä¿¡æ¯äº¤æ¢**

### æ¦‚å¿µå’Œä½œç”¨

é€šä¿¡ç®¡ç†å™¨è´Ÿè´£Agentä¹‹é—´çš„ä¿¡æ¯äº¤æ¢å’Œåä½œåè°ƒï¼Œæ”¯æŒä¸åŒçš„é€šä¿¡æ¨¡å¼å’Œåè®®ï¼Œç¡®ä¿å¤šAgentç³»ç»Ÿçš„æœ‰æ•ˆåä½œã€‚

**æ ¸å¿ƒä½œç”¨**:
- **ä¿¡æ¯ä¼ é€’**: åœ¨Agentä¹‹é—´ä¼ é€’æ¶ˆæ¯å’Œæ•°æ®
- **åä½œåè°ƒ**: åè°ƒå¤šAgentçš„åä½œè¡Œä¸º
- **åè®®ç®¡ç†**: ç®¡ç†ä¸åŒçš„é€šä¿¡åè®®å’Œè§„èŒƒ
- **å†²çªè§£å†³**: å¤„ç†Agenté—´çš„å†²çªå’Œç«žäº‰

### æ ¸å¿ƒç»„ä»¶

#### ðŸ“¨ æ¶ˆæ¯æ€»çº¿ (Message Bus)

**æ¦‚å¿µ**: ä¸­å¤®åŒ–çš„æ¶ˆæ¯ä¼ é€’ç³»ç»Ÿ

**ä½œç”¨**:
- å¼‚æ­¥æ¶ˆæ¯ä¼ é€’
- æ¶ˆæ¯è·¯ç”±å’Œåˆ†å‘
- æ¶ˆæ¯æŒä¹…åŒ–å­˜å‚¨
- æ¶ˆæ¯ä¼˜å…ˆçº§ç®¡ç†

**å®žçŽ°ç¤ºä¾‹**:
```python
class MessageBus:
    """æ¶ˆæ¯æ€»çº¿ç³»ç»Ÿ"""
    
    def __init__(self):
        self.message_queue = MessageQueue()
        self.routing_engine = MessageRoutingEngine()
        self.subscription_manager = SubscriptionManager()
        self.message_persistence = MessagePersistence()
        
    async def publish_message(self, 
                            sender_id: str,
                            message: Message,
                            routing_key: str = None) -> MessagePublishResult:
        """å‘å¸ƒæ¶ˆæ¯"""
        
        # æ¶ˆæ¯éªŒè¯å’Œå¢žå¼º
        enhanced_message = await self.enhance_message(message, sender_id)
        
        # ç¡®å®šè·¯ç”±ç­–ç•¥
        routing_strategy = await self.routing_engine.determine_routing(
            message=enhanced_message,
            routing_key=routing_key
        )
        
        # æŸ¥æ‰¾è®¢é˜…è€…
        subscribers = await self.subscription_manager.find_subscribers(
            message_type=enhanced_message.type,
            routing_key=routing_key,
            sender_id=sender_id
        )
        
        # æ¶ˆæ¯åˆ†å‘
        delivery_results = []
        for subscriber in subscribers:
            delivery_result = await self.deliver_message(
                message=enhanced_message,
                subscriber=subscriber,
                delivery_strategy=routing_strategy.delivery_strategy
            )
            delivery_results.append(delivery_result)
        
        # æ¶ˆæ¯æŒä¹…åŒ–
        if enhanced_message.persistent:
            await self.message_persistence.store_message(enhanced_message)
        
        return MessagePublishResult(
            message_id=enhanced_message.id,
            delivery_results=delivery_results,
            total_subscribers=len(subscribers),
            successful_deliveries=len([r for r in delivery_results if r.success])
        )
    
    async def subscribe(self, 
                      subscriber_id: str,
                      message_types: List[MessageType],
                      filters: List[MessageFilter] = None) -> SubscriptionResult:
        """è®¢é˜…æ¶ˆæ¯"""
        
        subscription = Subscription(
            subscriber_id=subscriber_id,
            message_types=message_types,
            filters=filters or [],
            created_at=datetime.now(),
            active=True
        )
        
        # æ³¨å†Œè®¢é˜…
        await self.subscription_manager.add_subscription(subscription)
        
        return SubscriptionResult(
            subscription_id=subscription.id,
            subscriber_id=subscriber_id,
            subscribed_types=message_types
        )
```

#### ðŸ¤ å›¢é˜Ÿåè®® (Team Protocol)

**æ¦‚å¿µ**: å®šä¹‰å¤šAgentåä½œçš„è§„èŒƒå’Œåè®®

**ä½œç”¨**:
- åä½œæ¨¡å¼å®šä¹‰
- è§’è‰²åˆ†å·¥ç®¡ç†
- åè°ƒæœºåˆ¶å®žçŽ°
- å†²çªè§£å†³ç­–ç•¥

**å®žçŽ°ç¤ºä¾‹**:
```python
class TeamProtocol:
    """å›¢é˜Ÿåä½œåè®®"""
    
    def __init__(self):
        self.collaboration_patterns = CollaborationPatternRegistry()
        self.role_manager = RoleManager()
        self.coordination_engine = CoordinationEngine()
        self.conflict_resolver = ConflictResolver()
        
    async def initiate_collaboration(self,
                                   agents: List[AgentIdentity],
                                   collaboration_goal: Goal,
                                   pattern: CollaborationPattern) -> CollaborationSession:
        """å¯åŠ¨åä½œä¼šè¯"""
        
        # åˆ›å»ºåä½œä¼šè¯
        session = CollaborationSession(
            session_id=self.generate_session_id(),
            participants=agents,
            goal=collaboration_goal,
            pattern=pattern,
            status=CollaborationStatus.INITIALIZING
        )
        
        # åˆ†é…è§’è‰²
        role_assignments = await self.role_manager.assign_roles(
            agents=agents,
            pattern=pattern,
            goal=collaboration_goal
        )
        
        # åˆå§‹åŒ–åè°ƒæœºåˆ¶
        coordination_context = await self.coordination_engine.initialize(
            session=session,
            role_assignments=role_assignments
        )
        
        # å»ºç«‹é€šä¿¡é€šé“
        communication_channels = await self.setup_communication_channels(
            session=session,
            pattern=pattern
        )
        
        # å¯åŠ¨åä½œ
        session.status = CollaborationStatus.ACTIVE
        session.role_assignments = role_assignments
        session.coordination_context = coordination_context
        session.communication_channels = communication_channels
        
        return session
    
    async def coordinate_agents(self, 
                              session: CollaborationSession,
                              current_state: CollaborationState) -> CoordinationResult:
        """åè°ƒAgentè¡Œä¸º"""
        
        # åˆ†æžå½“å‰çŠ¶æ€
        state_analysis = await self.analyze_collaboration_state(current_state)
        
        # æ£€æµ‹æ½œåœ¨å†²çª
        conflicts = await self.conflict_resolver.detect_conflicts(
            session=session,
            current_state=current_state
        )
        
        # ç”Ÿæˆåè°ƒæŒ‡ä»¤
        coordination_instructions = []
        
        for agent_id in session.participants:
            agent_instruction = await self.generate_agent_instruction(
                agent_id=agent_id,
                session=session,
                state_analysis=state_analysis,
                conflicts=conflicts
            )
            coordination_instructions.append(agent_instruction)
        
        # å¤„ç†å†²çª
        if conflicts:
            conflict_resolution = await self.conflict_resolver.resolve_conflicts(
                conflicts=conflicts,
                session=session
            )
            
            # æ›´æ–°åè°ƒæŒ‡ä»¤
            coordination_instructions = await self.update_instructions_with_resolution(
                instructions=coordination_instructions,
                resolution=conflict_resolution
            )
        
        return CoordinationResult(
            instructions=coordination_instructions,
            conflicts_resolved=len(conflicts) if conflicts else 0,
            coordination_quality=state_analysis.coordination_quality,
            next_coordination_time=self.calculate_next_coordination_time(state_analysis)
        )
```

---

## ðŸ”„ è®¤çŸ¥å¾ªçŽ¯å’Œé›†æˆ

### è®¤çŸ¥å¾ªçŽ¯æµç¨‹

```mermaid
graph TB
    subgraph "è®¤çŸ¥å¾ªçŽ¯ (Cognitive Loop)"
        PERCEPTION[ðŸ‘ï¸ æ„ŸçŸ¥]
        REASONING[ðŸ§  æŽ¨ç†]
        MEMORY[ðŸ’¾ è®°å¿†]
        LEARNING[ðŸ“š å­¦ä¹ ]
        COMMUNICATION[ðŸ’¬ é€šä¿¡]
        ACTION[âš¡ è¡ŒåŠ¨]
    end
    
    PERCEPTION --> REASONING
    REASONING --> MEMORY
    MEMORY --> REASONING
    REASONING --> ACTION
    ACTION --> LEARNING
    LEARNING --> MEMORY
    MEMORY --> PERCEPTION
    COMMUNICATION -.-> PERCEPTION
    COMMUNICATION -.-> REASONING
    COMMUNICATION -.-> LEARNING
    ACTION --> COMMUNICATION
```

### é›†æˆæž¶æž„

```python
class CognitiveAgent:
    """è®¤çŸ¥Agent - é›†æˆæ‰€æœ‰è®¤çŸ¥æ¨¡å—"""
    
    def __init__(self, identity: AgentIdentity):
        self.identity = identity
        
        # è®¤çŸ¥æ¨¡å—
        self.perception_engine = PerceptionEngine()
        self.reasoning_engine = ReasoningEngine()
        self.memory_system = MemorySystem()
        self.learning_module = LearningModule()
        self.communication_manager = CommunicationManager()
        
        # è®¤çŸ¥çŠ¶æ€
        self.cognitive_state = CognitiveState.IDLE
        self.current_context = UniversalContext()
        
    async def execute(self, task: UniversalTask, context: UniversalContext) -> UniversalResult:
        """æ‰§è¡Œå®Œæ•´çš„è®¤çŸ¥å¾ªçŽ¯"""
        
        self.cognitive_state = CognitiveState.PROCESSING
        
        try:
            # 1. æ„ŸçŸ¥é˜¶æ®µ
            perception_result = await self.perception_engine.perceive(
                input_data=task.content,
                context=context
            )
            
            # 2. è®°å¿†æ£€ç´¢
            relevant_memories = await self.memory_system.retrieve_relevant_memories(
                query=task.content,
                context=perception_result
            )
            
            # 3. æŽ¨ç†é˜¶æ®µ
            reasoning_result = await self.reasoning_engine.reason(
                perception_input=perception_result,
                memories=relevant_memories,
                task_goal=task.goal
            )
            
            # 4. è¡ŒåŠ¨æ‰§è¡Œ
            action_result = await self.execute_actions(reasoning_result.actions)
            
            # 5. è®°å¿†å­˜å‚¨
            await self.memory_system.store_episode(
                task=task,
                perception=perception_result,
                reasoning=reasoning_result,
                actions=action_result
            )
            
            # 6. å­¦ä¹ æ›´æ–°
            await self.learning_module.learn_from_experience(
                task=task,
                result=action_result,
                success=action_result.success
            )
            
            self.cognitive_state = CognitiveState.IDLE
            
            return UniversalResult(
                content=action_result.output,
                status=ResultStatus.SUCCESS if action_result.success else ResultStatus.FAILURE,
                metadata={
                    "perception_confidence": perception_result.confidence,
                    "reasoning_type": reasoning_result.reasoning_type,
                    "memories_used": len(relevant_memories),
                    "actions_executed": len(reasoning_result.actions)
                }
            )
            
        except Exception as e:
            self.cognitive_state = CognitiveState.ERROR
            return UniversalResult(
                content=f"Cognitive processing error: {str(e)}",
                status=ResultStatus.FAILURE
            )
```

---

*è®¤çŸ¥æž¶æž„å±‚æ–‡æ¡£ v2.0 - åˆ†å±‚è®°å¿†å¢žå¼ºç‰ˆæœ¬*  
*æœ€åŽæ›´æ–°: 2024å¹´12æœˆ20æ—¥*  
*æ–‡æ¡£ç¼–å·: ADC-ARCH-06* 