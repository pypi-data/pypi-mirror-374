# 04. é€‚é…å™¨å±‚ (Adapter Layer)

> **å¤šæ¡†æ¶ç»Ÿä¸€çš„æ¡¥æ¢ - å°†ä¸åŒAIæ¡†æ¶é€‚é…åˆ°ç»Ÿä¸€æŠ½è±¡æ¥å£**

## ğŸ¯ å±‚çº§æ¦‚è¿°

é€‚é…å™¨å±‚æ˜¯Agent Development Centerå®ç°**æ¡†æ¶æ— å…³æ€§**çš„å…³é”®å±‚çº§ã€‚å®ƒå°†å„ç§ä¸»æµAI Agentæ¡†æ¶ï¼ˆAutoGenã€OpenAIã€LangGraphã€CrewAIç­‰ï¼‰çš„ç‰¹å®šæ¦‚å¿µå’Œæ¥å£è½¬æ¢ä¸ºæˆ‘ä»¬çš„ç»Ÿä¸€æŠ½è±¡ï¼Œä½¿ä¸Šå±‚åº”ç”¨å¯ä»¥é€æ˜åœ°åˆ‡æ¢åº•å±‚æ¡†æ¶ã€‚

### æ ¸å¿ƒèŒè´£
1. **ğŸ”„ æ¡†æ¶è½¬æ¢**: å°†ä¸åŒæ¡†æ¶çš„æ¦‚å¿µæ˜ å°„åˆ°ç»Ÿä¸€æŠ½è±¡
2. **âš¡ èƒ½åŠ›é€‚é…**: é€‚é…ä¸åŒæ¡†æ¶çš„èƒ½åŠ›å’Œç‰¹æ€§
3. **ğŸ”Œ æ¥å£ç»Ÿä¸€**: æä¾›ä¸€è‡´çš„è°ƒç”¨æ¥å£
4. **ğŸ› ï¸ æ‰©å±•æ”¯æŒ**: æ”¯æŒæ–°æ¡†æ¶çš„å¿«é€Ÿæ¥å…¥
5. **ğŸ“Š æ€§èƒ½ä¼˜åŒ–**: é’ˆå¯¹ä¸åŒæ¡†æ¶è¿›è¡Œæ€§èƒ½ä¼˜åŒ–

### è®¾è®¡ç†å¿µ
- **é€æ˜åˆ‡æ¢**: ä¸Šå±‚åº”ç”¨æ— æ„ŸçŸ¥çš„æ¡†æ¶åˆ‡æ¢
- **èƒ½åŠ›æ˜ å°„**: æ™ºèƒ½æ˜ å°„ä¸åŒæ¡†æ¶çš„èƒ½åŠ›
- **æ€§èƒ½ä¼˜å…ˆ**: å……åˆ†åˆ©ç”¨å„æ¡†æ¶çš„æ€§èƒ½ç‰¹ç‚¹
- **æ‰©å±•å‹å¥½**: æ–°æ¡†æ¶å¯å¿«é€Ÿæ¥å…¥

---

## ğŸ—ï¸ é€‚é…å™¨æ¶æ„è®¾è®¡

### é€‚é…å™¨å±‚æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ¡†æ¶æŠ½è±¡å±‚ (ä¸Šå±‚)                          â”‚
â”‚   UniversalAgent â”‚ UniversalTask â”‚ UniversalContext â”‚ ...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    ç»Ÿä¸€é€‚é…å™¨æ¥å£
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é€‚é…å™¨å±‚ (Adapter Layer)                  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  AutoGen   â”‚ â”‚   OpenAI   â”‚ â”‚ LangGraph  â”‚ â”‚   CrewAI   â”‚ â”‚
â”‚  â”‚  Adapter   â”‚ â”‚  Adapter   â”‚ â”‚  Adapter   â”‚ â”‚  Adapter   â”‚ â”‚
â”‚  â”‚            â”‚ â”‚            â”‚ â”‚            â”‚ â”‚            â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚ â”‚Concept â”‚ â”‚ â”‚ â”‚Functionâ”‚ â”‚ â”‚ â”‚ State  â”‚ â”‚ â”‚ â”‚ Role   â”‚ â”‚ â”‚
â”‚  â”‚ â”‚Mapping â”‚ â”‚ â”‚ â”‚Calling â”‚ â”‚ â”‚ â”‚Machine â”‚ â”‚ â”‚ â”‚Mapping â”‚ â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚ â”‚Message â”‚ â”‚ â”‚ â”‚Stream  â”‚ â”‚ â”‚ â”‚ Graph  â”‚ â”‚ â”‚ â”‚Process â”‚ â”‚ â”‚
â”‚  â”‚ â”‚Routing â”‚ â”‚ â”‚ â”‚Handlingâ”‚ â”‚ â”‚ â”‚Executionâ”‚ â”‚ â”‚ â”‚Mgmt    â”‚ â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    æ¡†æ¶ç‰¹å®šæ¥å£
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº•å±‚æ¡†æ¶ (å…·ä½“å®ç°)                        â”‚
â”‚    AutoGen     â”‚     OpenAI     â”‚   LangGraph   â”‚   CrewAI   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶å…³ç³»

1. **BaseAdapter**: æ‰€æœ‰é€‚é…å™¨çš„åŸºç¡€æ¥å£
2. **FrameworkCapability**: æ¡†æ¶èƒ½åŠ›æè¿°å’Œæ˜ å°„
3. **ConceptTranslator**: æ¦‚å¿µè½¬æ¢å™¨
4. **AdapterRegistry**: é€‚é…å™¨æ³¨å†Œå’Œç®¡ç†
5. **PerformanceOptimizer**: æ€§èƒ½ä¼˜åŒ–å™¨

---

## ğŸ”§ åŸºç¡€é€‚é…å™¨æ¥å£

### BaseAdapter è®¾è®¡

**æ¦‚å¿µ**: æ‰€æœ‰æ¡†æ¶é€‚é…å™¨å¿…é¡»å®ç°çš„ç»Ÿä¸€æ¥å£

**ä½œç”¨**:
- å®šä¹‰æ ‡å‡†çš„é€‚é…å™¨å¥‘çº¦
- ç¡®ä¿æ¥å£ä¸€è‡´æ€§
- æ”¯æŒå¤šæ€è°ƒç”¨
- æä¾›åŸºç¡€åŠŸèƒ½

**å®ç°ç¤ºä¾‹**:
```python
class BaseAdapter(ABC):
    """æ¡†æ¶é€‚é…å™¨åŸºç¡€æ¥å£"""
    
    def __init__(self, config: AdapterConfig):
        self.config = config
        self.framework_name = self.get_framework_name()
        self.capabilities = self.get_framework_capabilities()
        self.performance_optimizer = PerformanceOptimizer(self.framework_name)
        
    @abstractmethod
    def get_framework_name(self) -> str:
        """è·å–æ¡†æ¶åç§°"""
        pass
    
    @abstractmethod
    def get_framework_capabilities(self) -> List[FrameworkCapability]:
        """è·å–æ¡†æ¶æ”¯æŒçš„èƒ½åŠ›åˆ—è¡¨"""
        pass
    
    @abstractmethod
    async def translate_context(self, context: UniversalContext) -> Any:
        """å°†UniversalContextè½¬æ¢ä¸ºç›®æ ‡æ¡†æ¶çš„ä¸Šä¸‹æ–‡æ ¼å¼"""
        pass
    
    @abstractmethod
    async def translate_task(self, task: UniversalTask) -> Any:
        """å°†UniversalTaskè½¬æ¢ä¸ºç›®æ ‡æ¡†æ¶çš„ä»»åŠ¡æ ¼å¼"""
        pass
    
    @abstractmethod
    async def translate_result(self, framework_result: Any) -> UniversalResult:
        """å°†æ¡†æ¶ç»“æœè½¬æ¢ä¸ºUniversalResult"""
        pass
    
    @abstractmethod
    async def execute_task(self, 
                         task: UniversalTask, 
                         context: UniversalContext) -> UniversalResult:
        """æ‰§è¡Œä»»åŠ¡ - å®Œæ•´çš„é€‚é…æµç¨‹"""
        pass
    
    async def validate_compatibility(self, task: UniversalTask) -> CompatibilityResult:
        """éªŒè¯ä»»åŠ¡ä¸æ¡†æ¶çš„å…¼å®¹æ€§"""
        
        required_capabilities = task.get_required_capabilities()
        supported_capabilities = [cap.name for cap in self.capabilities]
        
        missing_capabilities = [
            cap for cap in required_capabilities 
            if cap not in supported_capabilities
        ]
        
        compatibility_score = (
            len(required_capabilities) - len(missing_capabilities)
        ) / len(required_capabilities) if required_capabilities else 1.0
        
        return CompatibilityResult(
            is_compatible=len(missing_capabilities) == 0,
            compatibility_score=compatibility_score,
            missing_capabilities=missing_capabilities,
            supported_capabilities=supported_capabilities,
            recommendations=self.generate_compatibility_recommendations(missing_capabilities)
        )
    
    async def optimize_for_task(self, task: UniversalTask) -> OptimizationConfig:
        """ä¸ºç‰¹å®šä»»åŠ¡ä¼˜åŒ–é€‚é…å™¨é…ç½®"""
        return await self.performance_optimizer.optimize(task, self.config)
```

### èƒ½åŠ›æ˜ å°„ç³»ç»Ÿ

**æ¦‚å¿µ**: å°†ä¸åŒæ¡†æ¶çš„èƒ½åŠ›æ˜ å°„åˆ°ç»Ÿä¸€çš„èƒ½åŠ›æ¨¡å‹

**ä½œç”¨**:
- ç»Ÿä¸€èƒ½åŠ›æè¿°æ ‡å‡†
- æ”¯æŒèƒ½åŠ›å‘ç°å’ŒåŒ¹é…
- å®ç°èƒ½åŠ›ç­‰çº§è¯„ä¼°
- æä¾›èƒ½åŠ›æ›¿ä»£å»ºè®®

**å®ç°ç¤ºä¾‹**:
```python
class CapabilityMapper:
    """èƒ½åŠ›æ˜ å°„å™¨"""
    
    def __init__(self):
        self.capability_registry = CapabilityRegistry()
        self.mapping_rules = self.load_mapping_rules()
        
    async def map_framework_capabilities(self, 
                                       framework_name: str,
                                       native_capabilities: List[Any]) -> List[FrameworkCapability]:
        """æ˜ å°„æ¡†æ¶åŸç”Ÿèƒ½åŠ›åˆ°ç»Ÿä¸€èƒ½åŠ›æ¨¡å‹"""
        
        mapped_capabilities = []
        
        for native_cap in native_capabilities:
            # æŸ¥æ‰¾æ˜ å°„è§„åˆ™
            mapping_rule = self.find_mapping_rule(framework_name, native_cap)
            
            if mapping_rule:
                # åº”ç”¨æ˜ å°„è§„åˆ™
                universal_capability = await self.apply_mapping_rule(
                    native_capability=native_cap,
                    mapping_rule=mapping_rule
                )
                mapped_capabilities.append(universal_capability)
            else:
                # åˆ›å»ºæ–°çš„æ˜ å°„è§„åˆ™
                new_mapping = await self.create_new_mapping(
                    framework_name=framework_name,
                    native_capability=native_cap
                )
                mapped_capabilities.append(new_mapping.universal_capability)
        
        return mapped_capabilities
    
    def find_mapping_rule(self, framework_name: str, native_capability: Any) -> MappingRule:
        """æŸ¥æ‰¾é€‚ç”¨çš„æ˜ å°„è§„åˆ™"""
        
        for rule in self.mapping_rules:
            if (rule.framework_name == framework_name and 
                rule.matches_native_capability(native_capability)):
                return rule
        
        return None
    
    async def apply_mapping_rule(self, 
                               native_capability: Any, 
                               mapping_rule: MappingRule) -> FrameworkCapability:
        """åº”ç”¨æ˜ å°„è§„åˆ™"""
        
        return FrameworkCapability(
            name=mapping_rule.universal_name,
            description=mapping_rule.universal_description,
            capability_type=mapping_rule.capability_type,
            parameters=await mapping_rule.map_parameters(native_capability),
            constraints=await mapping_rule.map_constraints(native_capability),
            performance_metrics=await mapping_rule.estimate_performance(native_capability),
            native_capability=native_capability,
            framework_name=mapping_rule.framework_name
        )
```

---

## ğŸ¤– AutoGené€‚é…å™¨

### æ¦‚å¿µæ˜ å°„

**AutoGenæ ¸å¿ƒæ¦‚å¿µ**:
- `ConversableAgent`: å¯å¯¹è¯çš„Agent
- `GroupChat`: å¤šAgentç¾¤èŠ
- `UserProxyAgent`: ç”¨æˆ·ä»£ç†Agent
- `AssistantAgent`: åŠ©æ‰‹Agent

**æ˜ å°„åˆ°ç»Ÿä¸€æŠ½è±¡**:
- `ConversableAgent` â†’ `UniversalAgent`
- `GroupChat` â†’ `UniversalTeam` + `CommunicationManager`
- `Message` â†’ `UniversalContext.ContextEntry`

### å®ç°ç¤ºä¾‹

```python
class AutoGenAdapter(BaseAdapter):
    """AutoGenæ¡†æ¶é€‚é…å™¨"""
    
    def __init__(self, config: AdapterConfig):
        super().__init__(config)
        self.autogen_config = self.load_autogen_config()
        self.agent_registry = AutoGenAgentRegistry()
        self.group_chat_manager = GroupChatManager()
        
    def get_framework_name(self) -> str:
        return "AutoGen"
    
    def get_framework_capabilities(self) -> List[FrameworkCapability]:
        return [
            FrameworkCapability(
                name="multi_agent_conversation",
                description="Multi-agent conversational workflow",
                capability_type=CapabilityType.COLLABORATION,
                performance_level=PerformanceLevel.HIGH
            ),
            FrameworkCapability(
                name="code_execution",
                description="Code execution with user proxy",
                capability_type=CapabilityType.TOOL_EXECUTION,
                performance_level=PerformanceLevel.HIGH
            ),
            FrameworkCapability(
                name="human_in_loop",
                description="Human-in-the-loop interaction",
                capability_type=CapabilityType.HUMAN_INTERACTION,
                performance_level=PerformanceLevel.HIGH
            )
        ]
    
    async def translate_context(self, context: UniversalContext) -> List[Dict[str, Any]]:
        """å°†UniversalContextè½¬æ¢ä¸ºAutoGenæ¶ˆæ¯æ ¼å¼"""
        
        messages = []
        
        for entry in context.entries:
            if entry.key.startswith("message_"):
                # è½¬æ¢ä¸ºAutoGenæ¶ˆæ¯æ ¼å¼
                autogen_message = {
                    "role": entry.metadata.get("role", "user"),
                    "content": entry.content,
                    "name": entry.metadata.get("sender_name", "user")
                }
                
                # æ·»åŠ AutoGenç‰¹æœ‰å­—æ®µ
                if "tool_calls" in entry.metadata:
                    autogen_message["tool_calls"] = entry.metadata["tool_calls"]
                
                if "function_call" in entry.metadata:
                    autogen_message["function_call"] = entry.metadata["function_call"]
                
                messages.append(autogen_message)
        
        return messages
    
    async def translate_task(self, task: UniversalTask) -> AutoGenTaskConfig:
        """å°†UniversalTaskè½¬æ¢ä¸ºAutoGenä»»åŠ¡é…ç½®"""
        
        # åˆ†æä»»åŠ¡ç±»å‹
        if task.task_type == TaskType.MULTI_AGENT_COLLABORATION:
            return await self.create_group_chat_config(task)
        elif task.task_type == TaskType.CODE_GENERATION:
            return await self.create_code_gen_config(task)
        else:
            return await self.create_single_agent_config(task)
    
    async def create_group_chat_config(self, task: UniversalTask) -> AutoGenTaskConfig:
        """åˆ›å»ºç¾¤èŠä»»åŠ¡é…ç½®"""
        
        # åˆ†æéœ€è¦çš„Agentè§’è‰²
        required_roles = await self.analyze_required_roles(task)
        
        # åˆ›å»ºAutoGen Agents
        agents = []
        for role in required_roles:
            agent_config = {
                "name": role.name,
                "system_message": role.system_message,
                "llm_config": self.get_llm_config_for_role(role),
                "human_input_mode": role.human_input_mode,
                "max_consecutive_auto_reply": role.max_auto_reply
            }
            
            if role.type == "assistant":
                agent = autogen.AssistantAgent(**agent_config)
            elif role.type == "user_proxy":
                agent = autogen.UserProxyAgent(**agent_config)
            else:
                agent = autogen.ConversableAgent(**agent_config)
            
            agents.append(agent)
        
        # åˆ›å»ºGroupChat
        group_chat = autogen.GroupChat(
            agents=agents,
            messages=[],
            max_round=task.metadata.get("max_rounds", 10),
            speaker_selection_method=task.metadata.get("selection_method", "auto")
        )
        
        # åˆ›å»ºGroupChatManager
        manager = autogen.GroupChatManager(
            groupchat=group_chat,
            llm_config=self.get_manager_llm_config()
        )
        
        return AutoGenTaskConfig(
            task_type="group_chat",
            agents=agents,
            group_chat=group_chat,
            manager=manager,
            initial_message=task.content
        )
    
    async def execute_task(self, 
                         task: UniversalTask, 
                         context: UniversalContext) -> UniversalResult:
        """æ‰§è¡ŒAutoGenä»»åŠ¡"""
        
        try:
            # è½¬æ¢ä»»åŠ¡é…ç½®
            autogen_config = await self.translate_task(task)
            
            # è½¬æ¢ä¸Šä¸‹æ–‡
            messages = await self.translate_context(context)
            
            # æ‰§è¡Œä»»åŠ¡
            if autogen_config.task_type == "group_chat":
                result = await self.execute_group_chat(autogen_config, messages)
            else:
                result = await self.execute_single_agent(autogen_config, messages)
            
            # è½¬æ¢ç»“æœ
            return await self.translate_result(result)
            
        except Exception as e:
            return UniversalResult(
                content=f"AutoGen execution error: {str(e)}",
                status=ResultStatus.FAILURE,
                metadata={"error_type": type(e).__name__, "framework": "AutoGen"}
            )
    
    async def execute_group_chat(self, 
                               config: AutoGenTaskConfig, 
                               messages: List[Dict]) -> AutoGenResult:
        """æ‰§è¡Œç¾¤èŠä»»åŠ¡"""
        
        # è®¾ç½®åˆå§‹æ¶ˆæ¯å†å²
        if messages:
            config.group_chat.messages = messages
        
        # å¯åŠ¨ç¾¤èŠ
        chat_result = await config.manager.a_initiate_chat(
            config.group_chat,
            message=config.initial_message,
            clear_history=len(messages) == 0
        )
        
        return AutoGenResult(
            messages=config.group_chat.messages,
            final_message=chat_result.summary if hasattr(chat_result, 'summary') else None,
            participants=[agent.name for agent in config.agents],
            total_rounds=len(config.group_chat.messages),
            execution_metadata={
                "chat_terminated": chat_result.chat_terminated,
                "termination_reason": getattr(chat_result, 'termination_reason', None)
            }
        )
```

---

## ğŸ”— OpenAIé€‚é…å™¨

### æ¦‚å¿µæ˜ å°„

**OpenAIæ ¸å¿ƒæ¦‚å¿µ**:
- `ChatCompletion`: èŠå¤©å®ŒæˆAPI
- `Function Calling`: å‡½æ•°è°ƒç”¨
- `Assistant API`: åŠ©æ‰‹API
- `Tools`: å·¥å…·é›†æˆ

**æ˜ å°„åˆ°ç»Ÿä¸€æŠ½è±¡**:
- `ChatCompletion` â†’ `UniversalAgent.execute()`
- `Function` â†’ `AgentCapability`
- `Assistant` â†’ `UniversalAgent`
- `Thread` â†’ `UniversalContext`

### å®ç°ç¤ºä¾‹

```python
class OpenAIAdapter(BaseAdapter):
    """OpenAIæ¡†æ¶é€‚é…å™¨"""
    
    def __init__(self, config: AdapterConfig):
        super().__init__(config)
        self.client = AsyncOpenAI(api_key=config.api_key)
        self.function_registry = FunctionRegistry()
        self.assistant_manager = AssistantManager()
        
    def get_framework_name(self) -> str:
        return "OpenAI"
    
    def get_framework_capabilities(self) -> List[FrameworkCapability]:
        return [
            FrameworkCapability(
                name="function_calling",
                description="Advanced function calling with JSON schema",
                capability_type=CapabilityType.TOOL_EXECUTION,
                performance_level=PerformanceLevel.HIGH
            ),
            FrameworkCapability(
                name="streaming_response",
                description="Real-time streaming responses",
                capability_type=CapabilityType.STREAMING,
                performance_level=PerformanceLevel.HIGH
            ),
            FrameworkCapability(
                name="vision_understanding",
                description="Image and visual content understanding",
                capability_type=CapabilityType.MULTIMODAL,
                performance_level=PerformanceLevel.HIGH
            ),
            FrameworkCapability(
                name="code_interpreter",
                description="Built-in code execution environment",
                capability_type=CapabilityType.CODE_EXECUTION,
                performance_level=PerformanceLevel.MEDIUM
            )
        ]
    
    async def translate_capabilities_to_functions(self, 
                                                capabilities: List[AgentCapability]) -> List[Dict]:
        """å°†Agentèƒ½åŠ›è½¬æ¢ä¸ºOpenAI Functionå®šä¹‰"""
        
        functions = []
        
        for capability in capabilities:
            if capability == AgentCapability.WEB_SEARCH:
                functions.append({
                    "type": "function",
                    "function": {
                        "name": "web_search",
                        "description": "Search the web for current information",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "query": {
                                    "type": "string", 
                                    "description": "Search query string"
                                },
                                "max_results": {
                                    "type": "integer", 
                                    "default": 5,
                                    "description": "Maximum number of results to return"
                                },
                                "time_range": {
                                    "type": "string",
                                    "enum": ["day", "week", "month", "year", "all"],
                                    "default": "all",
                                    "description": "Time range for search results"
                                }
                            },
                            "required": ["query"]
                        }
                    }
                })
            
            elif capability == AgentCapability.CODE_EXECUTION:
                functions.append({
                    "type": "function",
                    "function": {
                        "name": "execute_code",
                        "description": "Execute Python code in a secure environment",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "code": {
                                    "type": "string",
                                    "description": "Python code to execute"
                                },
                                "timeout": {
                                    "type": "integer",
                                    "default": 30,
                                    "description": "Execution timeout in seconds"
                                },
                                "environment": {
                                    "type": "string",
                                    "enum": ["python3", "jupyter"],
                                    "default": "python3",
                                    "description": "Execution environment"
                                }
                            },
                            "required": ["code"]
                        }
                    }
                })
            
            elif capability == AgentCapability.FILE_OPERATIONS:
                functions.append({
                    "type": "function",
                    "function": {
                        "name": "file_operations",
                        "description": "Perform file system operations",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "operation": {
                                    "type": "string",
                                    "enum": ["read", "write", "list", "delete", "create_dir"],
                                    "description": "File operation to perform"
                                },
                                "path": {
                                    "type": "string",
                                    "description": "File or directory path"
                                },
                                "content": {
                                    "type": "string",
                                    "description": "Content for write operations"
                                }
                            },
                            "required": ["operation", "path"]
                        }
                    }
                })
        
        return functions
    
    async def execute_with_function_calling(self, 
                                          messages: List[Dict], 
                                          functions: List[Dict],
                                          stream: bool = False) -> UniversalResult:
        """ä½¿ç”¨Function Callingæ‰§è¡Œä»»åŠ¡"""
        
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": self.config.model or "gpt-4o",
                "messages": messages,
                "tools": functions,
                "tool_choice": "auto" if functions else None,
                "stream": stream,
                "temperature": self.config.temperature or 0.7,
                "max_tokens": self.config.max_tokens
            }
            
            # æ‰§è¡Œè¯·æ±‚
            if stream:
                return await self.execute_streaming_request(request_params)
            else:
                return await self.execute_standard_request(request_params)
                
        except Exception as e:
            return UniversalResult(
                content=f"OpenAI API error: {str(e)}",
                status=ResultStatus.FAILURE,
                metadata={"error_type": type(e).__name__, "framework": "OpenAI"}
            )
    
    async def execute_standard_request(self, params: Dict) -> UniversalResult:
        """æ‰§è¡Œæ ‡å‡†è¯·æ±‚"""
        
        response = await self.client.chat.completions.create(**params)
        
        # å¤„ç†å‡½æ•°è°ƒç”¨
        message = response.choices[0].message
        function_results = []
        
        if message.tool_calls:
            # æ‰§è¡Œå‡½æ•°è°ƒç”¨
            for tool_call in message.tool_calls:
                function_result = await self.execute_function_call(tool_call)
                function_results.append(function_result)
                
                # æ·»åŠ å‡½æ•°ç»“æœåˆ°æ¶ˆæ¯å†å²
                params["messages"].append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(function_result.result)
                })
            
            # è·å–æœ€ç»ˆå“åº”
            final_response = await self.client.chat.completions.create(**params)
            final_message = final_response.choices[0].message
        else:
            final_message = message
            final_response = response
        
        return UniversalResult(
            content=final_message.content,
            status=ResultStatus.SUCCESS,
            metadata={
                "model": final_response.model,
                "tokens_used": final_response.usage.total_tokens,
                "function_calls": len(function_results),
                "function_results": [fr.to_dict() for fr in function_results],
                "finish_reason": final_response.choices[0].finish_reason
            }
        )
    
    async def execute_function_call(self, tool_call) -> FunctionResult:
        """æ‰§è¡Œå‡½æ•°è°ƒç”¨"""
        
        function_name = tool_call.function.name
        function_args = json.loads(tool_call.function.arguments)
        
        # æŸ¥æ‰¾å¹¶æ‰§è¡Œå‡½æ•°
        function_handler = self.function_registry.get_handler(function_name)
        
        if function_handler:
            result = await function_handler.execute(function_args)
            return FunctionResult(
                function_name=function_name,
                arguments=function_args,
                result=result,
                success=True,
                execution_time=result.get("execution_time", 0)
            )
        else:
            return FunctionResult(
                function_name=function_name,
                arguments=function_args,
                result={"error": f"Function {function_name} not found"},
                success=False,
                execution_time=0
            )
```

---

## ğŸ•¸ï¸ LangGraphé€‚é…å™¨

### æ¦‚å¿µæ˜ å°„

**LangGraphæ ¸å¿ƒæ¦‚å¿µ**:
- `StateGraph`: çŠ¶æ€å›¾å·¥ä½œæµ
- `Node`: å›¾ä¸­çš„èŠ‚ç‚¹
- `Edge`: èŠ‚ç‚¹é—´çš„è¿æ¥
- `State`: å›¾çš„çŠ¶æ€

**æ˜ å°„åˆ°ç»Ÿä¸€æŠ½è±¡**:
- `StateGraph` â†’ `CognitiveAgent` çš„è®¤çŸ¥æµç¨‹
- `Node` â†’ è®¤çŸ¥æ¨¡å—çš„å¤„ç†æ­¥éª¤
- `State` â†’ `UniversalContext`
- `Edge` â†’ è®¤çŸ¥æµç¨‹çš„æ§åˆ¶é€»è¾‘

### å®ç°ç¤ºä¾‹

```python
class LangGraphAdapter(BaseAdapter):
    """LangGraphæ¡†æ¶é€‚é…å™¨"""
    
    def __init__(self, config: AdapterConfig):
        super().__init__(config)
        self.graph_builder = GraphBuilder()
        self.state_manager = StateManager()
        self.node_registry = NodeRegistry()
        
    def get_framework_name(self) -> str:
        return "LangGraph"
    
    def get_framework_capabilities(self) -> List[FrameworkCapability]:
        return [
            FrameworkCapability(
                name="state_machine_workflow",
                description="Complex state machine based workflows",
                capability_type=CapabilityType.WORKFLOW,
                performance_level=PerformanceLevel.HIGH
            ),
            FrameworkCapability(
                name="conditional_routing",
                description="Dynamic conditional flow routing",
                capability_type=CapabilityType.CONTROL_FLOW,
                performance_level=PerformanceLevel.HIGH
            ),
            FrameworkCapability(
                name="parallel_execution",
                description="Parallel node execution support",
                capability_type=CapabilityType.PARALLEL_PROCESSING,
                performance_level=PerformanceLevel.MEDIUM
            ),
            FrameworkCapability(
                name="checkpointing",
                description="State checkpointing and recovery",
                capability_type=CapabilityType.PERSISTENCE,
                performance_level=PerformanceLevel.MEDIUM
            )
        ]
    
    async def translate_context(self, context: UniversalContext) -> Dict[str, Any]:
        """å°†UniversalContextè½¬æ¢ä¸ºLangGraphçš„State"""
        
        state = {
            "messages": [],
            "context_data": {},
            "intermediate_steps": [],
            "agent_scratchpad": "",
            "current_step": "start",
            "metadata": {}
        }
        
        # è½¬æ¢ä¸Šä¸‹æ–‡æ¡ç›®
        for entry in context.entries:
            if entry.key.startswith("message_"):
                state["messages"].append({
                    "role": entry.metadata.get("role", "user"),
                    "content": entry.content,
                    "timestamp": entry.timestamp,
                    "metadata": entry.metadata
                })
            elif entry.key.startswith("step_"):
                state["intermediate_steps"].append({
                    "step_id": entry.key,
                    "content": entry.content,
                    "metadata": entry.metadata
                })
            else:
                state["context_data"][entry.key] = entry.content
        
        # æ·»åŠ å…¨å±€å…ƒæ•°æ®
        state["metadata"] = {
            "context_id": context.context_id,
            "created_at": context.created_at,
            "total_entries": len(context.entries)
        }
        
        return state
    
    async def create_cognitive_workflow_graph(self, 
                                            agent_config: Dict[str, Any]) -> StateGraph:
        """åˆ›å»ºè®¤çŸ¥å·¥ä½œæµå›¾"""
        
        # å®šä¹‰çŠ¶æ€ç»“æ„
        from langgraph import StateGraph
        from typing_extensions import TypedDict
        
        class AgentState(TypedDict):
            messages: List[Dict]
            context_data: Dict[str, Any]
            intermediate_steps: List[Dict]
            agent_scratchpad: str
            current_step: str
            perception_result: Dict
            reasoning_result: Dict
            action_plan: Dict
            execution_result: Dict
            metadata: Dict
        
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ è®¤çŸ¥èŠ‚ç‚¹
        workflow.add_node("perceive", self.perception_node)
        workflow.add_node("reason", self.reasoning_node)
        workflow.add_node("plan", self.planning_node)
        workflow.add_node("act", self.action_node)
        workflow.add_node("reflect", self.reflection_node)
        workflow.add_node("learn", self.learning_node)
        
        # æ·»åŠ è¾¹å’Œæ¡ä»¶è·¯ç”±
        workflow.add_edge(START, "perceive")
        workflow.add_edge("perceive", "reason")
        
        # æ¡ä»¶è·¯ç”±ï¼šæ ¹æ®æ¨ç†ç»“æœå†³å®šä¸‹ä¸€æ­¥
        workflow.add_conditional_edges(
            "reason",
            self.should_plan_or_act,
            {
                "plan": "plan",
                "act": "act",
                "reflect": "reflect"
            }
        )
        
        workflow.add_edge("plan", "act")
        workflow.add_edge("act", "reflect")
        
        # åæ€åçš„æ¡ä»¶è·¯ç”±
        workflow.add_conditional_edges(
            "reflect",
            self.should_continue_or_end,
            {
                "reason": "reason",
                "learn": "learn",
                "end": END
            }
        )
        
        workflow.add_edge("learn", END)
        
        return workflow.compile(checkpointer=self.create_checkpointer())
    
    async def perception_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æ„ŸçŸ¥èŠ‚ç‚¹"""
        
        # è·å–æœ€æ–°æ¶ˆæ¯
        latest_message = state["messages"][-1] if state["messages"] else None
        
        if latest_message:
            # æ‰§è¡Œå¤šæ¨¡æ€æ„ŸçŸ¥
            perception_engine = PerceptionEngine()
            perception_result = await perception_engine.perceive(
                input_data=latest_message["content"],
                context=state["context_data"]
            )
            
            # æ›´æ–°çŠ¶æ€
            state["perception_result"] = {
                "input_analysis": perception_result.input_analysis,
                "intent": perception_result.intent,
                "entities": perception_result.entities,
                "confidence": perception_result.confidence
            }
            
            state["current_step"] = "perception_complete"
            state["agent_scratchpad"] += f"æ„ŸçŸ¥ç»“æœ: {perception_result.summary}\n"
        
        return state
    
    async def reasoning_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨ç†èŠ‚ç‚¹"""
        
        reasoning_engine = ReasoningEngine()
        
        # åŸºäºæ„ŸçŸ¥ç»“æœè¿›è¡Œæ¨ç†
        reasoning_result = await reasoning_engine.reason(
            perception_input=state.get("perception_result", {}),
            context=state["context_data"],
            previous_steps=state["intermediate_steps"]
        )
        
        # æ›´æ–°çŠ¶æ€
        state["reasoning_result"] = {
            "reasoning_type": reasoning_result.reasoning_type,
            "conclusion": reasoning_result.conclusion,
            "confidence": reasoning_result.confidence,
            "reasoning_chain": reasoning_result.reasoning_chain
        }
        
        state["current_step"] = "reasoning_complete"
        state["agent_scratchpad"] += f"æ¨ç†ç»“æœ: {reasoning_result.conclusion}\n"
        
        return state
    
    def should_plan_or_act(self, state: Dict[str, Any]) -> str:
        """å†³å®šæ˜¯å¦éœ€è¦åˆ¶å®šè®¡åˆ’"""
        
        reasoning_result = state.get("reasoning_result", {})
        
        # å¦‚æœæ¨ç†ç»“æœè¡¨æ˜éœ€è¦å¤æ‚è¡ŒåŠ¨ï¼Œåˆ™å…ˆåˆ¶å®šè®¡åˆ’
        if reasoning_result.get("complexity", "simple") == "complex":
            return "plan"
        elif reasoning_result.get("confidence", 0) < 0.7:
            return "reflect"
        else:
            return "act"
    
    def should_continue_or_end(self, state: Dict[str, Any]) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æˆ–ç»“æŸ"""
        
        reflection_result = state.get("reflection_result", {})
        
        if reflection_result.get("should_retry", False):
            return "reason"
        elif reflection_result.get("needs_learning", False):
            return "learn"
        else:
            return "end"
    
    async def execute_task(self, 
                         task: UniversalTask, 
                         context: UniversalContext) -> UniversalResult:
        """æ‰§è¡ŒLangGraphä»»åŠ¡"""
        
        try:
            # åˆ›å»ºå·¥ä½œæµå›¾
            workflow_graph = await self.create_cognitive_workflow_graph({
                "task_type": task.task_type,
                "complexity": task.metadata.get("complexity", "medium")
            })
            
            # è½¬æ¢åˆå§‹çŠ¶æ€
            initial_state = await self.translate_context(context)
            initial_state["task"] = {
                "content": task.content,
                "type": task.task_type.value,
                "goal": task.goal
            }
            
            # æ‰§è¡Œå·¥ä½œæµ
            final_state = await workflow_graph.ainvoke(initial_state)
            
            # è½¬æ¢ç»“æœ
            return await self.translate_result(final_state)
            
        except Exception as e:
            return UniversalResult(
                content=f"LangGraph execution error: {str(e)}",
                status=ResultStatus.FAILURE,
                metadata={"error_type": type(e).__name__, "framework": "LangGraph"}
            )
```

---

## ğŸ“Š é€‚é…å™¨æ³¨å†Œå’Œç®¡ç†

### AdapterRegistry

**æ¦‚å¿µ**: ç®¡ç†æ‰€æœ‰å¯ç”¨é€‚é…å™¨çš„æ³¨å†Œä¸­å¿ƒ

**ä½œç”¨**:
- é€‚é…å™¨æ³¨å†Œå’Œå‘ç°
- èƒ½åŠ›åŒ¹é…å’Œé€‰æ‹©
- è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
- æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

**å®ç°ç¤ºä¾‹**:
```python
class AdapterRegistry:
    """é€‚é…å™¨æ³¨å†Œä¸­å¿ƒ"""
    
    def __init__(self):
        self.adapters: Dict[str, BaseAdapter] = {}
        self.capability_index: Dict[str, List[str]] = {}
        self.performance_monitor = AdapterPerformanceMonitor()
        self.load_balancer = AdapterLoadBalancer()
        
    async def register_adapter(self, adapter: BaseAdapter):
        """æ³¨å†Œé€‚é…å™¨"""
        
        framework_name = adapter.get_framework_name()
        self.adapters[framework_name] = adapter
        
        # ç´¢å¼•èƒ½åŠ›
        capabilities = adapter.get_framework_capabilities()
        for capability in capabilities:
            if capability.name not in self.capability_index:
                self.capability_index[capability.name] = []
            self.capability_index[capability.name].append(framework_name)
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        await self.performance_monitor.start_monitoring(adapter)
        
        print(f"Adapter {framework_name} registered successfully")
    
    async def select_best_adapter(self, 
                                task: UniversalTask,
                                selection_criteria: SelectionCriteria = None) -> AdapterSelection:
        """é€‰æ‹©æœ€ä½³é€‚é…å™¨"""
        
        # è·å–ä»»åŠ¡æ‰€éœ€èƒ½åŠ›
        required_capabilities = task.get_required_capabilities()
        
        # æŸ¥æ‰¾æ”¯æŒæ‰€éœ€èƒ½åŠ›çš„é€‚é…å™¨
        candidate_adapters = []
        
        for framework_name, adapter in self.adapters.items():
            compatibility = await adapter.validate_compatibility(task)
            
            if compatibility.is_compatible:
                candidate_adapters.append({
                    "adapter": adapter,
                    "framework_name": framework_name,
                    "compatibility_score": compatibility.compatibility_score,
                    "performance_metrics": await self.performance_monitor.get_metrics(framework_name)
                })
        
        if not candidate_adapters:
            raise NoCompatibleAdapterError(f"No adapter found for task type: {task.task_type}")
        
        # åº”ç”¨é€‰æ‹©ç­–ç•¥
        if selection_criteria:
            best_adapter = await self.apply_selection_criteria(candidate_adapters, selection_criteria)
        else:
            # é»˜è®¤é€‰æ‹©ç­–ç•¥ï¼šå…¼å®¹æ€§ + æ€§èƒ½
            best_adapter = max(candidate_adapters, key=lambda x: 
                x["compatibility_score"] * 0.6 + 
                x["performance_metrics"].average_score * 0.4
            )
        
        return AdapterSelection(
            adapter=best_adapter["adapter"],
            framework_name=best_adapter["framework_name"],
            selection_reason=f"Best match with score: {best_adapter['compatibility_score']:.2f}",
            alternatives=[c["framework_name"] for c in candidate_adapters if c != best_adapter]
        )
    
    async def execute_with_fallback(self,
                                  task: UniversalTask,
                                  context: UniversalContext,
                                  max_retries: int = 3) -> UniversalResult:
        """æ‰§è¡Œä»»åŠ¡ï¼Œæ”¯æŒæ•…éšœè½¬ç§»"""
        
        adapter_selection = await self.select_best_adapter(task)
        
        for attempt in range(max_retries):
            try:
                # å°è¯•æ‰§è¡Œä»»åŠ¡
                result = await adapter_selection.adapter.execute_task(task, context)
                
                # è®°å½•æˆåŠŸæ‰§è¡Œ
                await self.performance_monitor.record_success(
                    adapter_selection.framework_name, task, result
                )
                
                return result
                
            except Exception as e:
                # è®°å½•å¤±è´¥
                await self.performance_monitor.record_failure(
                    adapter_selection.framework_name, task, e
                )
                
                if attempt < max_retries - 1:
                    # é€‰æ‹©å¤‡é€‰é€‚é…å™¨
                    if adapter_selection.alternatives:
                        fallback_name = adapter_selection.alternatives[attempt]
                        adapter_selection.adapter = self.adapters[fallback_name]
                        adapter_selection.framework_name = fallback_name
                        print(f"Falling back to {fallback_name} after error: {str(e)}")
                    else:
                        raise e
                else:
                    raise e
```

---

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### æ¡†æ¶ç‰¹å®šä¼˜åŒ–

1. **AutoGenä¼˜åŒ–**:
   - æ¶ˆæ¯å†å²ç®¡ç†ä¼˜åŒ–
   - Agentè§’è‰²ç¼“å­˜
   - GroupChatæ€§èƒ½è°ƒä¼˜

2. **OpenAIä¼˜åŒ–**:
   - Function Callingæ‰¹é‡å¤„ç†
   - æµå¼å“åº”ä¼˜åŒ–
   - Tokenä½¿ç”¨ä¼˜åŒ–

3. **LangGraphä¼˜åŒ–**:
   - çŠ¶æ€æ£€æŸ¥ç‚¹ä¼˜åŒ–
   - èŠ‚ç‚¹æ‰§è¡Œå¹¶è¡ŒåŒ–
   - å†…å­˜ä½¿ç”¨ä¼˜åŒ–

### é€šç”¨ä¼˜åŒ–ç­–ç•¥

```python
class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    async def optimize_for_framework(self, 
                                   framework_name: str, 
                                   task: UniversalTask) -> OptimizationConfig:
        """ä¸ºç‰¹å®šæ¡†æ¶ä¼˜åŒ–é…ç½®"""
        
        if framework_name == "OpenAI":
            return await self.optimize_openai(task)
        elif framework_name == "AutoGen":
            return await self.optimize_autogen(task)
        elif framework_name == "LangGraph":
            return await self.optimize_langgraph(task)
        else:
            return await self.default_optimization(task)
    
    async def optimize_openai(self, task: UniversalTask) -> OptimizationConfig:
        """OpenAIç‰¹å®šä¼˜åŒ–"""
        
        config = OptimizationConfig()
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´å‚æ•°
        if task.task_type == TaskType.TEXT_GENERATION:
            config.temperature = 0.7
            config.max_tokens = 2000
        elif task.task_type == TaskType.CODE_GENERATION:
            config.temperature = 0.1
            config.max_tokens = 4000
        elif task.task_type == TaskType.ANALYSIS:
            config.temperature = 0.3
            config.max_tokens = 1500
        
        # å¯ç”¨æµå¼å¤„ç†ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if task.metadata.get("streaming", False):
            config.stream = True
            config.chunk_size = 1024
        
        # Function callingä¼˜åŒ–
        if task.get_required_capabilities():
            config.parallel_function_calls = True
            config.function_call_timeout = 30
        
        return config
```

---

*é€‚é…å™¨å±‚æ–‡æ¡£ v1.0*  
*æœ€åæ›´æ–°: 2024å¹´12æœˆ19æ—¥*  
*æ–‡æ¡£ç¼–å·: ADC-ARCH-04* 