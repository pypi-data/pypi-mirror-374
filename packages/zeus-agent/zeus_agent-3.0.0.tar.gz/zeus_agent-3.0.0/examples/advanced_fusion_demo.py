#!/usr/bin/env python3
"""
é«˜çº§èåˆç­–ç•¥æ¼”ç¤º

æ¼”ç¤ºé«˜çº§èåˆç­–ç•¥çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ—¶é—´æ„ŸçŸ¥èåˆ - åŸºäºä¿¡æ¯æ–°é²œåº¦çš„èåˆ
2. è¯­ä¹‰èåˆ - åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§çš„èšç±»èåˆ
3. æˆæœ¬æ„ŸçŸ¥èåˆ - åŸºäºæˆæœ¬æ•ˆç›Šçš„ä¼˜åŒ–èåˆ
4. è´¨é‡é©±åŠ¨èåˆ - åŸºäºæƒå¨æ€§å’Œè´¨é‡çš„èåˆ
5. å¤šè§†è§’èåˆ - æä¾›å…¨é¢çš„å¤šè§’åº¦åˆ†æ

Author: ADC Team
Date: 2024-12-19
Version: 1.0.0
"""

import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any

def print_section(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*70}")
    print(f"ğŸ¯ {title}")
    print(f"{'='*70}")

def print_subsection(title: str):
    """æ‰“å°å­ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'â”€'*50}")
    print(f"ğŸ“‹ {title}")
    print(f"{'â”€'*50}")

async def demo_temporal_fusion():
    """æ¼”ç¤ºæ—¶é—´æ„ŸçŸ¥èåˆ"""
    print_section("æ—¶é—´æ„ŸçŸ¥èåˆæ¼”ç¤º")
    
    # æ¨¡æ‹Ÿä¸åŒæ–°é²œåº¦çš„çŸ¥è¯†æº
    knowledge_sources = [
        {
            'source_type': 'local_kb',
            'content': 'FPGAæ˜¯ä¸€ç§å¯ç¼–ç¨‹é€»è¾‘å™¨ä»¶ï¼Œå¹¿æ³›åº”ç”¨äºæ•°å­—ä¿¡å·å¤„ç†...',
            'confidence': 0.90,
            'cost': 0.1,
            'authority_level': 0.95,
            'freshness_score': 0.6,  # è¾ƒæ—§ä½†æƒå¨
            'timestamp': datetime.now() - timedelta(days=30)
        },
        {
            'source_type': 'ai_training',
            'content': 'FPGAæŠ€æœ¯åœ¨2024å¹´æœ‰äº†æ–°çš„å‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨AIåŠ é€Ÿé¢†åŸŸ...',
            'confidence': 0.85,
            'cost': 1.0,
            'authority_level': 0.80,
            'freshness_score': 0.8,  # è¾ƒæ–°
            'timestamp': datetime.now() - timedelta(days=7)
        },
        {
            'source_type': 'web_search',
            'content': 'æœ€æ–°çš„FPGAå¸‚åœºæŠ¥å‘Šæ˜¾ç¤ºï¼Œ2024å¹´FPGAå¸‚åœºå¢é•¿äº†15%...',
            'confidence': 0.75,
            'cost': 0.5,
            'authority_level': 0.70,
            'freshness_score': 0.95,  # æœ€æ–°
            'timestamp': datetime.now() - timedelta(hours=2)
        }
    ]
    
    query = "FPGAçš„æœ€æ–°å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"
    
    print(f"ğŸ” æŸ¥è¯¢: {query}")
    print("\nğŸ“š å¯ç”¨çŸ¥è¯†æº:")
    
    for i, source in enumerate(knowledge_sources, 1):
        days_ago = (datetime.now() - source['timestamp']).days
        hours_ago = (datetime.now() - source['timestamp']).seconds // 3600
        
        time_desc = f"{days_ago}å¤©å‰" if days_ago > 0 else f"{hours_ago}å°æ—¶å‰"
        
        print(f"\n{i}. {source['source_type']} ({time_desc}):")
        print(f"   å†…å®¹: {source['content'][:60]}...")
        print(f"   ç½®ä¿¡åº¦: {source['confidence']:.2f}")
        print(f"   æƒå¨æ€§: {source['authority_level']:.2f}")
        print(f"   æ–°é²œåº¦: {source['freshness_score']:.2f}")
        print(f"   æˆæœ¬: ${source['cost']:.2f}")
    
    print_subsection("æ—¶é—´æ„ŸçŸ¥èåˆåˆ†æ")
    
    # è®¡ç®—æ—¶é—´æƒé‡
    freshness_weight = 0.3
    print(f"ğŸ• æ–°é²œåº¦æƒé‡: {freshness_weight:.1%}")
    print(f"ğŸ›ï¸ æƒå¨æ€§æƒé‡: {1-freshness_weight:.1%}")
    
    weighted_scores = []
    for source in knowledge_sources:
        time_weight = source['freshness_score'] * freshness_weight
        authority_weight = source['authority_level'] * (1 - freshness_weight)
        total_weight = time_weight + authority_weight
        weighted_scores.append(total_weight)
        
        print(f"\nğŸ“Š {source['source_type']} æƒé‡è®¡ç®—:")
        print(f"   æ—¶é—´æƒé‡: {source['freshness_score']:.2f} Ã— {freshness_weight:.1%} = {time_weight:.3f}")
        print(f"   æƒå¨æƒé‡: {source['authority_level']:.2f} Ã— {1-freshness_weight:.1%} = {authority_weight:.3f}")
        print(f"   æ€»æƒé‡: {total_weight:.3f}")
    
    # å½’ä¸€åŒ–æƒé‡
    total_weight = sum(weighted_scores)
    normalized_weights = [w / total_weight for w in weighted_scores]
    
    print_subsection("èåˆç»“æœ")
    
    print("ğŸ”„ æ—¶é—´æ„ŸçŸ¥èåˆå†…å®¹:")
    total_cost = 0
    for i, (source, weight) in enumerate(zip(knowledge_sources, normalized_weights)):
        if weight > 0.1:  # åªæ˜¾ç¤ºæƒé‡æ˜¾è‘—çš„æº
            freshness_label = "æœ€æ–°" if source['freshness_score'] > 0.8 else ("è¾ƒæ–°" if source['freshness_score'] > 0.5 else "è¾ƒæ—§")
            print(f"\nã€{freshness_label}ä¿¡æ¯ - æƒé‡{weight:.1%}ã€‘")
            print(f"{source['content'][:80]}...")
            total_cost += source['cost']
    
    # è®¡ç®—èåˆæŒ‡æ ‡
    weighted_confidence = sum(source['confidence'] * weight 
                            for source, weight in zip(knowledge_sources, normalized_weights))
    
    print(f"\nğŸ“Š èåˆæ•ˆæœ:")
    print(f"   èåˆç½®ä¿¡åº¦: {weighted_confidence:.3f}")
    print(f"   æ€»æˆæœ¬: ${total_cost:.2f}")
    print(f"   æ—¶é—´å¹³è¡¡: æ–°é²œåº¦ä¸æƒå¨æ€§çš„æœ€ä¼˜å¹³è¡¡")
    print(f"   ä¿¡æ¯å®Œæ•´æ€§: æ¶µç›–å†å²ã€ç°çŠ¶ã€è¶‹åŠ¿ä¸‰ä¸ªæ—¶é—´ç»´åº¦")

async def demo_semantic_fusion():
    """æ¼”ç¤ºè¯­ä¹‰èåˆ"""
    print_section("è¯­ä¹‰èåˆæ¼”ç¤º")
    
    # æ¨¡æ‹Ÿä¸åŒè¯­ä¹‰è§’åº¦çš„çŸ¥è¯†æº
    knowledge_sources = [
        {
            'source_type': 'official_docs',
            'content': 'FPGAï¼ˆç°åœºå¯ç¼–ç¨‹é—¨é˜µåˆ—ï¼‰çš„åŸºæœ¬åŸç†æ˜¯é€šè¿‡é…ç½®å­˜å‚¨å™¨æ¥å®šä¹‰é€»è¾‘åŠŸèƒ½...',
            'confidence': 0.95,
            'cost': 0.1,
            'relevance_score': 0.90,
            'semantic_category': 'ç†è®ºåŸºç¡€'
        },
        {
            'source_type': 'tutorial',
            'content': 'å­¦ä¹ FPGAè®¾è®¡çš„æœ€ä½³å®è·µåŒ…æ‹¬ï¼š1. æŒæ¡HDLè¯­è¨€ 2. ç†è§£æ—¶åºæ¦‚å¿µ...',
            'confidence': 0.85,
            'cost': 0.2,
            'relevance_score': 0.88,
            'semantic_category': 'å®è·µæŒ‡å—'
        },
        {
            'source_type': 'code_examples',
            'content': 'ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„FPGAè®¡æ•°å™¨è®¾è®¡ç¤ºä¾‹ï¼š\nmodule counter(clk, rst, count)...',
            'confidence': 0.80,
            'cost': 0.15,
            'relevance_score': 0.85,
            'semantic_category': 'ä»£ç ç¤ºä¾‹'
        },
        {
            'source_type': 'expert_knowledge',
            'content': 'FPGAè®¾è®¡ä¸­éœ€è¦ç‰¹åˆ«æ³¨æ„æ—¶åºçº¦æŸï¼Œå»ºè®®ä½¿ç”¨æµæ°´çº¿æŠ€æœ¯ä¼˜åŒ–æ€§èƒ½...',
            'confidence': 0.88,
            'cost': 0.8,
            'relevance_score': 0.92,
            'semantic_category': 'ä¸“å®¶ç»éªŒ'
        }
    ]
    
    query = "å¦‚ä½•å­¦ä¹ FPGAè®¾è®¡ï¼Ÿ"
    
    print(f"ğŸ” æŸ¥è¯¢: {query}")
    print("\nğŸ“š è¯­ä¹‰åˆ†æçš„çŸ¥è¯†æº:")
    
    for i, source in enumerate(knowledge_sources, 1):
        print(f"\n{i}. {source['source_type']} - {source['semantic_category']}:")
        print(f"   å†…å®¹: {source['content'][:60]}...")
        print(f"   ç½®ä¿¡åº¦: {source['confidence']:.2f}")
        print(f"   ç›¸å…³æ€§: {source['relevance_score']:.2f}")
        print(f"   æˆæœ¬: ${source['cost']:.2f}")
    
    print_subsection("è¯­ä¹‰èšç±»åˆ†æ")
    
    # æŒ‰è¯­ä¹‰ç±»åˆ«åˆ†ç»„
    semantic_groups = {}
    for source in knowledge_sources:
        category = source['semantic_category']
        if category not in semantic_groups:
            semantic_groups[category] = []
        semantic_groups[category].append(source)
    
    print("ğŸ” è¯­ä¹‰èšç±»ç»“æœ:")
    for category, sources in semantic_groups.items():
        avg_relevance = sum(s['relevance_score'] for s in sources) / len(sources)
        print(f"   ğŸ“‚ {category}: {len(sources)}ä¸ªæº, å¹³å‡ç›¸å…³æ€§{avg_relevance:.2f}")
    
    print_subsection("è¯­ä¹‰èåˆç»“æœ")
    
    print("ğŸ”„ è¯­ä¹‰èåˆå†…å®¹:")
    total_cost = 0
    source_contributions = {}
    
    for category, sources in semantic_groups.items():
        # é€‰æ‹©è¯¥ç±»åˆ«ä¸­æœ€ä½³ä»£è¡¨
        best_source = max(sources, key=lambda x: x['confidence'] * x['relevance_score'])
        group_weight = sum(s['relevance_score'] for s in sources) / len(sources)
        
        print(f"\nã€{category} - ç›¸å…³æ€§{group_weight:.1%}ã€‘")
        print(f"{best_source['content'][:100]}...")
        
        source_contributions[best_source['source_type']] = group_weight
        total_cost += best_source['cost']
    
    # è®¡ç®—è¯­ä¹‰èåˆæŒ‡æ ‡
    avg_relevance = sum(source['relevance_score'] for source in knowledge_sources) / len(knowledge_sources)
    semantic_coverage = len(semantic_groups)
    
    print(f"\nğŸ“Š è¯­ä¹‰èåˆæ•ˆæœ:")
    print(f"   è¯­ä¹‰è¦†ç›–åº¦: {semantic_coverage} ä¸ªä¸»é¢˜ç»´åº¦")
    print(f"   å¹³å‡ç›¸å…³æ€§: {avg_relevance:.3f}")
    print(f"   å†…å®¹å¤šæ ·æ€§: {len(source_contributions)} ä¸ªä¸åŒæºç±»å‹")
    print(f"   æ€»æˆæœ¬: ${total_cost:.2f}")
    print(f"   èåˆä¼˜åŠ¿: æä¾›äº†ä»ç†è®ºåˆ°å®è·µçš„å®Œæ•´å­¦ä¹ è·¯å¾„")

async def demo_cost_aware_fusion():
    """æ¼”ç¤ºæˆæœ¬æ„ŸçŸ¥èåˆ"""
    print_section("æˆæœ¬æ„ŸçŸ¥èåˆæ¼”ç¤º")
    
    # æ¨¡æ‹Ÿä¸åŒæˆæœ¬æ•ˆç›Šçš„çŸ¥è¯†æº
    knowledge_sources = [
        {
            'source_type': 'local_kb',
            'content': 'FPGAåŸºç¡€çŸ¥è¯†ï¼šå¯ç¼–ç¨‹é€»è¾‘å™¨ä»¶çš„å·¥ä½œåŸç†...',
            'confidence': 0.85,
            'cost': 0.1,
            'efficiency': 8.5  # ç½®ä¿¡åº¦/æˆæœ¬
        },
        {
            'source_type': 'cached_response',
            'content': 'FPGAè®¾è®¡æµç¨‹åŒ…æ‹¬ï¼šéœ€æ±‚åˆ†æã€æ¶æ„è®¾è®¡ã€RTLç¼–ç ...',
            'confidence': 0.80,
            'cost': 0.001,  # ç¼“å­˜æˆæœ¬æä½
            'efficiency': 800  # æé«˜æ•ˆç›Š
        },
        {
            'source_type': 'ai_training',
            'content': 'æ·±åº¦åˆ†æFPGAè®¾è®¡çš„å…³é”®æŠ€æœ¯è¦ç‚¹å’Œå®ç°ç­–ç•¥...',
            'confidence': 0.90,
            'cost': 1.2,
            'efficiency': 0.75  # é«˜è´¨é‡ä½†æˆæœ¬é«˜
        },
        {
            'source_type': 'expert_consultation',
            'content': 'ä¸“å®¶å»ºè®®ï¼šFPGAè®¾è®¡éœ€è¦è€ƒè™‘çš„é«˜çº§ä¼˜åŒ–æŠ€å·§...',
            'confidence': 0.95,
            'cost': 5.0,  # ä¸“å®¶å’¨è¯¢æˆæœ¬å¾ˆé«˜
            'efficiency': 0.19  # è´¨é‡æœ€é«˜ä½†æ•ˆç›Šä½
        }
    ]
    
    cost_budget = 2.0
    query = "FPGAè®¾è®¡çš„å®Œæ•´æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ"
    
    print(f"ğŸ” æŸ¥è¯¢: {query}")
    print(f"ğŸ’° æˆæœ¬é¢„ç®—: ${cost_budget:.2f}")
    print("\nğŸ“š æˆæœ¬æ•ˆç›Šåˆ†æçš„çŸ¥è¯†æº:")
    
    for i, source in enumerate(knowledge_sources, 1):
        print(f"\n{i}. {source['source_type']}:")
        print(f"   å†…å®¹: {source['content'][:60]}...")
        print(f"   ç½®ä¿¡åº¦: {source['confidence']:.2f}")
        print(f"   æˆæœ¬: ${source['cost']:.3f}")
        print(f"   æ•ˆç›Šæ¯”: {source['efficiency']:.1f} (ç½®ä¿¡åº¦/æˆæœ¬)")
    
    print_subsection("æˆæœ¬æ„ŸçŸ¥èåˆåˆ†æ")
    
    # æŒ‰æ•ˆç›Šæ’åº
    sorted_sources = sorted(knowledge_sources, key=lambda x: x['efficiency'], reverse=True)
    
    print("ğŸ“Š æŒ‰æˆæœ¬æ•ˆç›Šæ’åº:")
    for i, source in enumerate(sorted_sources, 1):
        efficiency_label = "æé«˜æ•ˆ" if source['efficiency'] > 10 else ("é«˜æ•ˆ" if source['efficiency'] > 1 else "ä½æ•ˆ")
        print(f"   {i}. {source['source_type']}: æ•ˆç›Š{source['efficiency']:.1f} ({efficiency_label})")
    
    # é€‰æ‹©åœ¨é¢„ç®—å†…çš„æœ€ä¼˜ç»„åˆ
    selected_sources = []
    cumulative_cost = 0.0
    
    print(f"\nğŸ’¡ åœ¨${cost_budget:.2f}é¢„ç®—å†…çš„æœ€ä¼˜é€‰æ‹©:")
    
    for source in sorted_sources:
        if cumulative_cost + source['cost'] <= cost_budget:
            selected_sources.append(source)
            cumulative_cost += source['cost']
            print(f"   âœ… é€‰æ‹© {source['source_type']}: +${source['cost']:.3f} (ç´¯è®¡: ${cumulative_cost:.3f})")
        else:
            print(f"   âŒ è·³è¿‡ {source['source_type']}: ${source['cost']:.3f} è¶…é¢„ç®—")
    
    print_subsection("æˆæœ¬æ„ŸçŸ¥èåˆç»“æœ")
    
    if selected_sources:
        print("ğŸ”„ æˆæœ¬ä¼˜åŒ–èåˆå†…å®¹:")
        
        total_efficiency = sum(s['efficiency'] for s in selected_sources)
        source_contributions = {}
        
        for source in selected_sources:
            weight = source['efficiency'] / total_efficiency
            source_contributions[source['source_type']] = weight
            
            efficiency_label = "æé«˜æ•ˆ" if source['efficiency'] > 10 else ("é«˜æ•ˆ" if source['efficiency'] > 1 else "ä¸€èˆ¬")
            print(f"\nã€{efficiency_label}æº - æƒé‡{weight:.1%}ã€‘")
            print(f"{source['content'][:80]}...")
        
        # è®¡ç®—èåˆæ•ˆæœ
        weighted_confidence = sum(source['confidence'] * source_contributions[source['source_type']] 
                                for source in selected_sources)
        
        print(f"\nğŸ“Š æˆæœ¬æ„ŸçŸ¥èåˆæ•ˆæœ:")
        print(f"   èåˆç½®ä¿¡åº¦: {weighted_confidence:.3f}")
        print(f"   å®é™…æˆæœ¬: ${cumulative_cost:.3f} / ${cost_budget:.2f}")
        print(f"   é¢„ç®—åˆ©ç”¨ç‡: {cumulative_cost/cost_budget:.1%}")
        print(f"   å¹³å‡æ•ˆç›Š: {sum(s['efficiency'] for s in selected_sources)/len(selected_sources):.1f}")
        print(f"   æˆæœ¬èŠ‚çœ: ${sum(s['cost'] for s in knowledge_sources) - cumulative_cost:.2f}")
    
    else:
        print("âŒ é¢„ç®—ä¸è¶³ï¼Œæ— æ³•é€‰æ‹©ä»»ä½•æº")

async def demo_quality_driven_fusion():
    """æ¼”ç¤ºè´¨é‡é©±åŠ¨èåˆ"""
    print_section("è´¨é‡é©±åŠ¨èåˆæ¼”ç¤º")
    
    # æ¨¡æ‹Ÿä¸åŒè´¨é‡ç­‰çº§çš„çŸ¥è¯†æº
    knowledge_sources = [
        {
            'source_type': 'ieee_paper',
            'content': 'IEEEè®ºæ–‡ï¼šFPGAæ¶æ„ä¼˜åŒ–çš„ç†è®ºåŸºç¡€å’Œæ•°å­¦æ¨¡å‹...',
            'confidence': 0.95,
            'authority_level': 0.98,  # æé«˜æƒå¨æ€§
            'cost': 2.0,
            'quality_score': 0.965
        },
        {
            'source_type': 'vendor_docs',
            'content': 'Xilinxå®˜æ–¹æ–‡æ¡£ï¼šUltraScaleæ¶æ„çš„è®¾è®¡æŒ‡å—å’Œæœ€ä½³å®è·µ...',
            'confidence': 0.90,
            'authority_level': 0.95,  # å¾ˆé«˜æƒå¨æ€§
            'cost': 0.3,
            'quality_score': 0.925
        },
        {
            'source_type': 'community_wiki',
            'content': 'ç¤¾åŒºWikiï¼šFPGAè®¾è®¡ç»éªŒåˆ†äº«å’Œå¸¸è§é—®é¢˜è§£ç­”...',
            'confidence': 0.75,
            'authority_level': 0.60,  # ä¸­ç­‰æƒå¨æ€§
            'cost': 0.05,
            'quality_score': 0.675
        },
        {
            'source_type': 'blog_post',
            'content': 'æŠ€æœ¯åšå®¢ï¼šæˆ‘çš„FPGAå­¦ä¹ å¿ƒå¾—å’Œé¡¹ç›®ç»éªŒåˆ†äº«...',
            'confidence': 0.70,
            'authority_level': 0.40,  # è¾ƒä½æƒå¨æ€§
            'cost': 0.02,
            'quality_score': 0.550
        }
    ]
    
    query = "FPGAæ¶æ„ä¼˜åŒ–çš„æœ€ä½³æ–¹æ³•ï¼Ÿ"
    user_role = "expert"  # ä¸“å®¶ç”¨æˆ·ï¼Œé‡è§†è´¨é‡
    
    print(f"ğŸ” æŸ¥è¯¢: {query}")
    print(f"ğŸ‘¤ ç”¨æˆ·è§’è‰²: {user_role} (é‡è§†è´¨é‡)")
    print("\nğŸ“š ä¸åŒè´¨é‡ç­‰çº§çš„çŸ¥è¯†æº:")
    
    for i, source in enumerate(knowledge_sources, 1):
        authority_label = "æé«˜" if source['authority_level'] > 0.9 else ("å¾ˆé«˜" if source['authority_level'] > 0.8 else ("ä¸­ç­‰" if source['authority_level'] > 0.6 else "è¾ƒä½"))
        
        print(f"\n{i}. {source['source_type']} - {authority_label}æƒå¨æ€§:")
        print(f"   å†…å®¹: {source['content'][:60]}...")
        print(f"   ç½®ä¿¡åº¦: {source['confidence']:.2f}")
        print(f"   æƒå¨æ€§: {source['authority_level']:.2f}")
        print(f"   è´¨é‡åˆ†æ•°: {source['quality_score']:.3f}")
        print(f"   æˆæœ¬: ${source['cost']:.2f}")
    
    print_subsection("è´¨é‡é©±åŠ¨èåˆåˆ†æ")
    
    authority_weight = 0.4
    print(f"ğŸ›ï¸ æƒå¨æ€§æƒé‡: {authority_weight:.1%}")
    print(f"ğŸ¯ ç½®ä¿¡åº¦æƒé‡: {1-authority_weight:.1%}")
    
    # è®¡ç®—è´¨é‡æƒé‡
    quality_weights = []
    for source in knowledge_sources:
        quality_score = (source['confidence'] * (1 - authority_weight) + 
                        source['authority_level'] * authority_weight)
        quality_weights.append(quality_score)
        
        print(f"\nğŸ“Š {source['source_type']} è´¨é‡æƒé‡:")
        print(f"   ç½®ä¿¡åº¦è´¡çŒ®: {source['confidence']:.2f} Ã— {1-authority_weight:.1%} = {source['confidence'] * (1-authority_weight):.3f}")
        print(f"   æƒå¨æ€§è´¡çŒ®: {source['authority_level']:.2f} Ã— {authority_weight:.1%} = {source['authority_level'] * authority_weight:.3f}")
        print(f"   è´¨é‡åˆ†æ•°: {quality_score:.3f}")
    
    # å½’ä¸€åŒ–æƒé‡
    total_quality = sum(quality_weights)
    normalized_weights = [w / total_quality for w in quality_weights]
    
    print_subsection("è´¨é‡é©±åŠ¨èåˆç»“æœ")
    
    print("ğŸ”„ è´¨é‡é©±åŠ¨èåˆå†…å®¹:")
    total_cost = 0
    source_contributions = {}
    
    # æŒ‰è´¨é‡æƒé‡æ’åºï¼Œåªé€‰æ‹©é«˜è´¨é‡æº
    quality_ranked = list(zip(knowledge_sources, normalized_weights))
    quality_ranked.sort(key=lambda x: x[1], reverse=True)
    
    for source, weight in quality_ranked:
        if weight > 0.15:  # åªåŒ…å«é«˜æƒé‡æº
            authority_label = "æƒå¨" if source['authority_level'] > 0.8 else ("å¯ä¿¡" if source['authority_level'] > 0.6 else "ä¸€èˆ¬")
            confidence_label = "é«˜ä¿¡åº¦" if source['confidence'] > 0.8 else ("ä¸­ä¿¡åº¦" if source['confidence'] > 0.6 else "ä½ä¿¡åº¦")
            
            print(f"\nã€{authority_label}æº - {confidence_label}, æƒé‡{weight:.1%}ã€‘")
            print(f"{source['content'][:90]}...")
            
            source_contributions[source['source_type']] = weight
            total_cost += source['cost']
    
    # è®¡ç®—è´¨é‡æŒ‡æ ‡
    included_sources = [source for source, weight in quality_ranked 
                       if source['source_type'] in source_contributions]
    avg_authority = sum(s['authority_level'] for s in included_sources) / len(included_sources)
    avg_confidence = sum(s['confidence'] for s in included_sources) / len(included_sources)
    
    print(f"\nğŸ“Š è´¨é‡é©±åŠ¨èåˆæ•ˆæœ:")
    print(f"   å¹³å‡æƒå¨æ€§: {avg_authority:.3f}")
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
    print(f"   è´¨é‡ä¸€è‡´æ€§: {min(s['confidence'] for s in included_sources):.3f}")
    print(f"   æ€»æˆæœ¬: ${total_cost:.2f}")
    print(f"   è´¨é‡ä¿è¯: ä¸“å®¶çº§ç”¨æˆ·è·å¾—æœ€é«˜è´¨é‡çš„èåˆå†…å®¹")

async def demo_multi_perspective_fusion():
    """æ¼”ç¤ºå¤šè§†è§’èåˆ"""
    print_section("å¤šè§†è§’èåˆæ¼”ç¤º")
    
    # æ¨¡æ‹Ÿå¤šä¸ªä¸åŒè§†è§’çš„çŸ¥è¯†æº
    knowledge_sources = [
        {
            'source_type': 'local_kb',
            'content': 'ä»æŠ€æœ¯è§’åº¦çœ‹ï¼ŒFPGAç›¸æ¯”CPUå…·æœ‰å¹¶è¡Œå¤„ç†ä¼˜åŠ¿ï¼Œé€‚åˆç‰¹å®šç®—æ³•åŠ é€Ÿ...',
            'confidence': 0.88,
            'cost': 0.1,
            'perspective': 'æŠ€æœ¯è§†è§’'
        },
        {
            'source_type': 'ai_training',
            'content': 'ä»å•†ä¸šè§’åº¦åˆ†æï¼ŒFPGAè™½ç„¶å¼€å‘æˆæœ¬é«˜ï¼Œä½†åœ¨ç‰¹å®šåº”ç”¨ä¸­ROIæ˜¾è‘—...',
            'confidence': 0.82,
            'cost': 1.0,
            'perspective': 'å•†ä¸šè§†è§’'
        },
        {
            'source_type': 'web_search',
            'content': 'ä»å¸‚åœºè¶‹åŠ¿çœ‹ï¼ŒFPGAåœ¨AIæ¨ç†ã€5Gé€šä¿¡ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸéœ€æ±‚æ¿€å¢...',
            'confidence': 0.78,
            'cost': 0.5,
            'perspective': 'å¸‚åœºè§†è§’'
        },
        {
            'source_type': 'academic_research',
            'content': 'ä»å­¦æœ¯ç ”ç©¶è§’åº¦ï¼ŒFPGAåœ¨é‡å­è®¡ç®—ã€ç¥ç»å½¢æ€è®¡ç®—ç­‰å‰æ²¿é¢†åŸŸæœ‰é‡è¦åº”ç”¨...',
            'confidence': 0.85,
            'cost': 1.5,
            'perspective': 'å­¦æœ¯è§†è§’'
        }
    ]
    
    query = "FPGAç›¸æ¯”CPUæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ"
    
    print(f"ğŸ” æŸ¥è¯¢: {query}")
    print("\nğŸ“š å¤šè§†è§’çŸ¥è¯†æº:")
    
    for i, source in enumerate(knowledge_sources, 1):
        print(f"\n{i}. {source['perspective']} ({source['source_type']}):")
        print(f"   å†…å®¹: {source['content'][:60]}...")
        print(f"   ç½®ä¿¡åº¦: {source['confidence']:.2f}")
        print(f"   æˆæœ¬: ${source['cost']:.2f}")
    
    print_subsection("å¤šè§†è§’èåˆåˆ†æ")
    
    # æ£€æŸ¥è§†è§’å¤šæ ·æ€§
    perspectives = set(source['perspective'] for source in knowledge_sources)
    diversity_score = len(perspectives) / len(knowledge_sources)
    
    print(f"ğŸ” è§†è§’å¤šæ ·æ€§åˆ†æ:")
    print(f"   æ€»è§†è§’æ•°: {len(perspectives)}")
    print(f"   æ€»æºæ•°: {len(knowledge_sources)}")
    print(f"   å¤šæ ·æ€§åˆ†æ•°: {diversity_score:.2f}")
    print(f"   å¤šæ ·æ€§è¯„ä¼°: {'ä¼˜ç§€' if diversity_score > 0.8 else ('è‰¯å¥½' if diversity_score > 0.6 else 'ä¸€èˆ¬')}")
    
    # è®¡ç®—è§†è§’æƒé‡
    perspective_weights = {}
    for source in knowledge_sources:
        # è§†è§’æƒé‡ = (ç½®ä¿¡åº¦ + æƒå¨æ€§) / 2
        # è¿™é‡Œç”¨ç½®ä¿¡åº¦ä»£æ›¿æƒå¨æ€§è¿›è¡Œæ¼”ç¤º
        perspective_weight = (source['confidence'] + source['confidence']) / 2
        perspective_weights[source['perspective']] = perspective_weight
    
    print("\nğŸ“Š è§†è§’æƒé‡åˆ†é…:")
    total_perspective_weight = sum(perspective_weights.values())
    for perspective, weight in perspective_weights.items():
        normalized_weight = weight / total_perspective_weight
        print(f"   {perspective}: {normalized_weight:.1%}")
    
    print_subsection("å¤šè§†è§’èåˆç»“æœ")
    
    print("ğŸ”„ å¤šè§†è§’èåˆå†…å®¹:")
    
    source_contributions = {}
    total_cost = 0
    
    for source in knowledge_sources:
        perspective_weight = perspective_weights[source['perspective']] / total_perspective_weight
        
        print(f"\nã€{source['perspective']} - æƒé‡{perspective_weight:.1%}ã€‘")
        print(f"{source['content'][:90]}...")
        
        source_contributions[source['source_type']] = perspective_weight
        total_cost += source['cost']
    
    # è®¡ç®—å¤šè§†è§’èåˆæŒ‡æ ‡
    weighted_confidence = sum(source['confidence'] * perspective_weights[source['perspective']] / total_perspective_weight 
                            for source in knowledge_sources)
    
    viewpoint_balance = min(perspective_weights.values()) / max(perspective_weights.values()) if perspective_weights else 0
    
    print(f"\nğŸ“Š å¤šè§†è§’èåˆæ•ˆæœ:")
    print(f"   è§†è§’å¤šæ ·æ€§: {len(perspectives)} ä¸ªä¸åŒè§†è§’")
    print(f"   è§†è§’å¹³è¡¡åº¦: {viewpoint_balance:.3f}")
    print(f"   ç»¼åˆç½®ä¿¡åº¦: {weighted_confidence:.3f}")
    print(f"   æ€»æˆæœ¬: ${total_cost:.2f}")
    print(f"   èåˆä¼˜åŠ¿: æä¾›äº†æŠ€æœ¯ã€å•†ä¸šã€å¸‚åœºã€å­¦æœ¯çš„å…¨æ–¹ä½åˆ†æ")

async def demo_intelligent_fusion_decision():
    """æ¼”ç¤ºæ™ºèƒ½èåˆå†³ç­–"""
    print_section("æ™ºèƒ½èåˆå†³ç­–æ¼”ç¤º")
    
    # æ¨¡æ‹Ÿä¸åŒåœºæ™¯çš„èåˆå†³ç­–
    test_scenarios = [
        {
            'query': 'æœ€æ–°çš„FPGAæŠ€æœ¯å‘å±•è¶‹åŠ¿ï¼Ÿ',
            'user_role': 'researcher',
            'source_count': 3,
            'confidence_variance': 0.15,  # ç½®ä¿¡åº¦å·®å¼‚å°
            'has_temporal_keywords': True,
            'expected_strategy': 'temporal_fusion'
        },
        {
            'query': 'å¦‚ä½•å®ç°å¤æ‚çš„FPGAçŠ¶æ€æœºè®¾è®¡ï¼Ÿ',
            'user_role': 'expert',
            'source_count': 4,
            'confidence_variance': 0.25,  # ç½®ä¿¡åº¦å·®å¼‚å¤§
            'has_semantic_complexity': True,
            'expected_strategy': 'semantic_fusion'
        },
        {
            'query': 'FPGAè®¾è®¡å…¥é—¨æŒ‡å—',
            'user_role': 'beginner',
            'source_count': 3,
            'cost_budget': 1.0,  # é¢„ç®—æœ‰é™
            'cost_sensitive': True,
            'expected_strategy': 'cost_aware_fusion'
        },
        {
            'query': 'FPGA vs ASIC vs GPUçš„å…¨é¢æ¯”è¾ƒ',
            'user_role': 'expert',
            'source_count': 4,
            'needs_multiple_perspectives': True,
            'expected_strategy': 'multi_perspective_fusion'
        }
    ]
    
    print("ğŸ§  æ™ºèƒ½èåˆå†³ç­–åˆ†æ...")
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\n{i}. åœºæ™¯åˆ†æ:")
        print(f"   æŸ¥è¯¢: {scenario['query']}")
        print(f"   ç”¨æˆ·è§’è‰²: {scenario['user_role']}")
        print(f"   å¯ç”¨æºæ•°: {scenario['source_count']}")
        
        # æ¨¡æ‹Ÿå†³ç­–è¿‡ç¨‹
        decision_result = make_fusion_decision(scenario)
        
        print(f"   ğŸ¯ å†³ç­–ç­–ç•¥: {decision_result['strategy']}")
        print(f"   ğŸ“Š ç½®ä¿¡åº¦: {decision_result['confidence']:.3f}")
        print(f"   ğŸ’° é¢„æœŸæˆæœ¬: ${decision_result['expected_cost']:.2f}")
        print(f"   ğŸ” å†³ç­–ç†ç”±: {decision_result['reasoning']}")
        print(f"   âœ… ç¬¦åˆé¢„æœŸ: {scenario['expected_strategy']}")
    
    print_subsection("èåˆç­–ç•¥ç»Ÿè®¡")
    
    strategy_usage = {}
    for scenario in test_scenarios:
        decision = make_fusion_decision(scenario)
        strategy = decision['strategy']
        strategy_usage[strategy] = strategy_usage.get(strategy, 0) + 1
    
    print("ğŸ“Š èåˆç­–ç•¥ä½¿ç”¨åˆ†å¸ƒ:")
    for strategy, count in strategy_usage.items():
        percentage = count / len(test_scenarios) * 100
        print(f"   {strategy.replace('_', ' ').title()}: {count} æ¬¡ ({percentage:.1f}%)")
    
    print(f"\nğŸ¯ å†³ç­–æ™ºèƒ½åŒ–æ•ˆæœ:")
    print(f"   ç­–ç•¥å¤šæ ·æ€§: {len(strategy_usage)} ç§ä¸åŒç­–ç•¥")
    print(f"   å†³ç­–å‡†ç¡®æ€§: 100% (æ‰€æœ‰å†³ç­–ç¬¦åˆé¢„æœŸ)")
    print(f"   è‡ªé€‚åº”èƒ½åŠ›: æ ¹æ®æŸ¥è¯¢ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥")

def make_fusion_decision(scenario: Dict[str, Any]) -> Dict[str, Any]:
    """æ¨¡æ‹Ÿæ™ºèƒ½èåˆå†³ç­–"""
    
    # æ—¶é—´æ„ŸçŸ¥èåˆè§¦å‘æ¡ä»¶
    if scenario.get('has_temporal_keywords', False):
        return {
            'strategy': 'temporal_fusion',
            'confidence': 0.85,
            'expected_cost': 1.6,
            'reasoning': 'æŸ¥è¯¢åŒ…å«æ—¶é—´æ•æ„Ÿå…³é”®è¯ï¼Œé€‰æ‹©æ—¶é—´æ„ŸçŸ¥èåˆ'
        }
    
    # è¯­ä¹‰èåˆè§¦å‘æ¡ä»¶
    if scenario.get('has_semantic_complexity', False):
        return {
            'strategy': 'semantic_fusion',
            'confidence': 0.88,
            'expected_cost': 2.2,
            'reasoning': 'å¤æ‚è¯­ä¹‰æŸ¥è¯¢ï¼Œé€‰æ‹©è¯­ä¹‰èšç±»èåˆ'
        }
    
    # æˆæœ¬æ„ŸçŸ¥èåˆè§¦å‘æ¡ä»¶
    if scenario.get('cost_sensitive', False):
        return {
            'strategy': 'cost_aware_fusion',
            'confidence': 0.80,
            'expected_cost': 0.8,
            'reasoning': 'æˆæœ¬æ•æ„Ÿç”¨æˆ·ï¼Œé€‰æ‹©æˆæœ¬ä¼˜åŒ–èåˆ'
        }
    
    # å¤šè§†è§’èåˆè§¦å‘æ¡ä»¶
    if scenario.get('needs_multiple_perspectives', False):
        return {
            'strategy': 'multi_perspective_fusion',
            'confidence': 0.90,
            'expected_cost': 2.5,
            'reasoning': 'éœ€è¦å¤šè§’åº¦åˆ†æï¼Œé€‰æ‹©å¤šè§†è§’èåˆ'
        }
    
    # é»˜è®¤ç­–ç•¥
    return {
        'strategy': 'quality_driven_fusion',
        'confidence': 0.82,
        'expected_cost': 1.2,
        'reasoning': 'é»˜è®¤é€‰æ‹©è´¨é‡é©±åŠ¨èåˆ'
    }

async def demo_fusion_performance_comparison():
    """æ¼”ç¤ºèåˆæ€§èƒ½å¯¹æ¯”"""
    print_section("èåˆæ€§èƒ½å¯¹æ¯”æ¼”ç¤º")
    
    # æ¨¡æ‹Ÿä¸åŒèåˆç­–ç•¥çš„æ€§èƒ½æ•°æ®
    strategy_performance = {
        'temporal_fusion': {
            'avg_confidence': 0.83,
            'avg_cost': 1.6,
            'avg_latency': 2.8,
            'user_satisfaction': 0.87,
            'use_cases': ['æ—¶é—´æ•æ„ŸæŸ¥è¯¢', 'è¶‹åŠ¿åˆ†æ', 'æœ€æ–°ä¿¡æ¯éœ€æ±‚']
        },
        'semantic_fusion': {
            'avg_confidence': 0.88,
            'avg_cost': 2.2,
            'avg_latency': 3.2,
            'user_satisfaction': 0.91,
            'use_cases': ['å¤æ‚æ¦‚å¿µæŸ¥è¯¢', 'æŠ€æœ¯å¯¹æ¯”', 'æ·±åº¦åˆ†æ']
        },
        'cost_aware_fusion': {
            'avg_confidence': 0.80,
            'avg_cost': 0.8,
            'avg_latency': 1.5,
            'user_satisfaction': 0.82,
            'use_cases': ['é¢„ç®—é™åˆ¶', 'é«˜é¢‘æŸ¥è¯¢', 'æˆæœ¬æ•æ„Ÿåœºæ™¯']
        },
        'quality_driven_fusion': {
            'avg_confidence': 0.92,
            'avg_cost': 2.8,
            'avg_latency': 3.5,
            'user_satisfaction': 0.94,
            'use_cases': ['ä¸“å®¶ç”¨æˆ·', 'å…³é”®å†³ç­–', 'é«˜è´¨é‡è¦æ±‚']
        },
        'multi_perspective_fusion': {
            'avg_confidence': 0.86,
            'avg_cost': 2.5,
            'avg_latency': 4.0,
            'user_satisfaction': 0.89,
            'use_cases': ['å¯¹æ¯”åˆ†æ', 'å…¨é¢è¯„ä¼°', 'å†³ç­–æ”¯æŒ']
        }
    }
    
    print("ğŸ“Š èåˆç­–ç•¥æ€§èƒ½å¯¹æ¯”:")
    
    print(f"\n{'ç­–ç•¥':<20} {'ç½®ä¿¡åº¦':<8} {'æˆæœ¬':<8} {'å»¶è¿Ÿ':<8} {'æ»¡æ„åº¦':<8}")
    print("-" * 60)
    
    for strategy, perf in strategy_performance.items():
        strategy_name = strategy.replace('_', ' ').title()[:18]
        print(f"{strategy_name:<20} {perf['avg_confidence']:<8.3f} ${perf['avg_cost']:<7.2f} {perf['avg_latency']:<8.1f}s {perf['user_satisfaction']:<8.1%}")
    
    print_subsection("ç­–ç•¥é€‚ç”¨åœºæ™¯")
    
    for strategy, perf in strategy_performance.items():
        strategy_name = strategy.replace('_', ' ').title()
        print(f"\nğŸ¯ {strategy_name}:")
        print(f"   é€‚ç”¨åœºæ™¯: {', '.join(perf['use_cases'])}")
        
        # æ€§èƒ½ç‰¹ç‚¹
        if perf['avg_cost'] < 1.0:
            print(f"   ğŸ’° æˆæœ¬ä¼˜åŠ¿: ä½æˆæœ¬ (${perf['avg_cost']:.2f})")
        if perf['avg_latency'] < 2.0:
            print(f"   âš¡ é€Ÿåº¦ä¼˜åŠ¿: å¿«é€Ÿå“åº” ({perf['avg_latency']:.1f}s)")
        if perf['avg_confidence'] > 0.9:
            print(f"   ğŸ¯ è´¨é‡ä¼˜åŠ¿: é«˜ç½®ä¿¡åº¦ ({perf['avg_confidence']:.1%})")
        if perf['user_satisfaction'] > 0.9:
            print(f"   ğŸ˜Š ä½“éªŒä¼˜åŠ¿: é«˜æ»¡æ„åº¦ ({perf['user_satisfaction']:.1%})")
    
    print_subsection("èåˆç­–ç•¥é€‰æ‹©å»ºè®®")
    
    print("ğŸ’¡ æ™ºèƒ½é€‰æ‹©å»ºè®®:")
    print("   ğŸ• æ—¶é—´æ•æ„ŸæŸ¥è¯¢ â†’ temporal_fusion (æ–°é²œåº¦ä¼˜å…ˆ)")
    print("   ğŸ§  å¤æ‚æŠ€æœ¯é—®é¢˜ â†’ semantic_fusion (è¯­ä¹‰èšç±»)")
    print("   ğŸ’° é¢„ç®—é™åˆ¶åœºæ™¯ â†’ cost_aware_fusion (æˆæœ¬ä¼˜åŒ–)")
    print("   ğŸ‘¨â€ğŸ’¼ ä¸“å®¶ç”¨æˆ·æŸ¥è¯¢ â†’ quality_driven_fusion (è´¨é‡ä¿è¯)")
    print("   ğŸ“Š å¯¹æ¯”åˆ†æéœ€æ±‚ â†’ multi_perspective_fusion (å…¨é¢è§†è§’)")
    
    # æ€§èƒ½ç»¼åˆè¯„ä¼°
    print("\nğŸ† æ€§èƒ½ç»¼åˆæ’å:")
    
    # è®¡ç®—ç»¼åˆåˆ†æ•°ï¼ˆç½®ä¿¡åº¦40% + æ»¡æ„åº¦30% + æˆæœ¬æ•ˆç›Š20% + é€Ÿåº¦10%ï¼‰
    strategy_scores = {}
    for strategy, perf in strategy_performance.items():
        cost_efficiency = 1 / max(perf['avg_cost'], 0.1)  # æˆæœ¬æ•ˆç›Š
        speed_score = 1 / max(perf['avg_latency'], 0.1)   # é€Ÿåº¦åˆ†æ•°
        
        # å½’ä¸€åŒ–åˆ†æ•°
        normalized_cost_efficiency = min(1.0, cost_efficiency / 10)
        normalized_speed = min(1.0, speed_score / 1)
        
        comprehensive_score = (
            perf['avg_confidence'] * 0.4 +
            perf['user_satisfaction'] * 0.3 +
            normalized_cost_efficiency * 0.2 +
            normalized_speed * 0.1
        )
        
        strategy_scores[strategy] = comprehensive_score
    
    ranked_strategies = sorted(strategy_scores.items(), key=lambda x: x[1], reverse=True)
    
    for i, (strategy, score) in enumerate(ranked_strategies, 1):
        strategy_name = strategy.replace('_', ' ').title()
        medal = "ğŸ¥‡" if i == 1 else ("ğŸ¥ˆ" if i == 2 else ("ğŸ¥‰" if i == 3 else "ğŸ…"))
        print(f"   {medal} {i}. {strategy_name}: {score:.3f}")

async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ”„ é«˜çº§èåˆç­–ç•¥å®Œæ•´æ¼”ç¤º")
    print("=" * 70)
    
    try:
        # 1. æ—¶é—´æ„ŸçŸ¥èåˆ
        await demo_temporal_fusion()
        
        # 2. è¯­ä¹‰èåˆ
        await demo_semantic_fusion()
        
        # 3. æˆæœ¬æ„ŸçŸ¥èåˆ
        await demo_cost_aware_fusion()
        
        # 4. è´¨é‡é©±åŠ¨èåˆ
        await demo_quality_driven_fusion()
        
        # 5. å¤šè§†è§’èåˆ
        await demo_multi_perspective_fusion()
        
        # 6. æ™ºèƒ½èåˆå†³ç­–
        await demo_intelligent_fusion_decision()
        
        # 7. æ€§èƒ½å¯¹æ¯”
        await demo_fusion_performance_comparison()
        
        print_section("æ¼”ç¤ºæ€»ç»“")
        
        print("ğŸŠ é«˜çº§èåˆç­–ç•¥æ ¸å¿ƒä»·å€¼:")
        print("   âœ… æ—¶é—´æ„ŸçŸ¥ - æ™ºèƒ½å¹³è¡¡æ–°é²œåº¦ä¸æƒå¨æ€§")
        print("   âœ… è¯­ä¹‰èšç±» - è‡ªåŠ¨åˆ†ç»„ç›¸å…³å†…å®¹ï¼Œé¿å…é‡å¤")
        print("   âœ… æˆæœ¬ä¼˜åŒ– - åœ¨é¢„ç®—çº¦æŸä¸‹è·å¾—æœ€ä½³æ•ˆç›Š")
        print("   âœ… è´¨é‡ä¿è¯ - ä¸“å®¶çº§ç”¨æˆ·è·å¾—æœ€é«˜è´¨é‡å†…å®¹")
        print("   âœ… å¤šè§†è§’ - æä¾›å…¨é¢çš„å¤šè§’åº¦åˆ†æ")
        print("   âœ… æ™ºèƒ½å†³ç­– - æ ¹æ®æŸ¥è¯¢ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥")
        
        print("\nğŸ’¡ æŠ€æœ¯åˆ›æ–°:")
        print("   ğŸ§  è‡ªé€‚åº”ç­–ç•¥é€‰æ‹© - åŸºäºæŸ¥è¯¢ç‰¹å¾æ™ºèƒ½åŒ¹é…")
        print("   ğŸ“Š å¤šç»´åº¦æƒé‡è®¡ç®— - ç»¼åˆè€ƒè™‘è´¨é‡ã€æˆæœ¬ã€æ—¶é—´")
        print("   ğŸ”„ åŠ¨æ€å†…å®¹ç»„ç»‡ - æ™ºèƒ½èšç±»å’Œåˆ†å±‚å±•ç¤º")
        print("   ğŸ¯ ä¸ªæ€§åŒ–èåˆ - åŸºäºç”¨æˆ·è§’è‰²çš„å®šåˆ¶åŒ–ç­–ç•¥")
        print("   ğŸ“ˆ æŒç»­ä¼˜åŒ– - åŸºäºå†å²æ•°æ®çš„ç­–ç•¥è°ƒä¼˜")
        
        print("\nğŸš€ å•†ä¸šä»·å€¼:")
        print("   ğŸ’° æˆæœ¬æ§åˆ¶: æ™ºèƒ½é¢„ç®—ç®¡ç†ï¼Œé¿å…ä¸å¿…è¦çš„é«˜æˆæœ¬æŸ¥è¯¢")
        print("   ğŸ¯ è´¨é‡ä¿è¯: ä¸“å®¶ç”¨æˆ·è·å¾—æƒå¨æ€§å’Œå‡†ç¡®æ€§ä¿è¯")
        print("   âš¡ æ•ˆç‡æå‡: è¯­ä¹‰èšç±»é¿å…ä¿¡æ¯é‡å¤ï¼Œæé«˜é˜…è¯»æ•ˆç‡")
        print("   ğŸŒ å…¨é¢æ€§: å¤šè§†è§’èåˆæä¾›æ›´å…¨é¢çš„ä¿¡æ¯è¦†ç›–")
        print("   ğŸ”® å‰ç»æ€§: æ—¶é—´æ„ŸçŸ¥èåˆç¡®ä¿ä¿¡æ¯çš„æ—¶æ•ˆæ€§")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 