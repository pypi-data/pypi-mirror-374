#!/usr/bin/env python3
"""
Prompt Engineering Demo - æç¤ºè¯å·¥ç¨‹æ¼”ç¤º
æ¼”ç¤ºADCä¸­æç¤ºè¯å·¥ç¨‹ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½
"""

import asyncio
import logging
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æç¤ºè¯å·¥ç¨‹æ¨¡å—
from layers.framework.prompt_engineering import (
    PromptManager,
    PromptTemplate,
    PromptOptimizer,
    PromptConverter,
    PromptAnalyzer,
    TemplateType,
    PromptCategory
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def demo_prompt_engineering():
    """æ¼”ç¤ºæç¤ºè¯å·¥ç¨‹åŠŸèƒ½"""
    logger.info("ğŸš€ === ADC æç¤ºè¯å·¥ç¨‹ç³»ç»Ÿæ¼”ç¤º ===")
    
    # åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨
    prompt_manager = PromptManager()
    
    try:
        # æ¼”ç¤º1: æ¨¡æ¿ç®¡ç†
        logger.info("\nğŸ“‹ æ¼”ç¤º1: æç¤ºè¯æ¨¡æ¿ç®¡ç†")
        
        # åˆ—å‡ºæ‰€æœ‰æ¨¡æ¿
        templates = prompt_manager.list_templates()
        logger.info(f"âœ… ç³»ç»Ÿå†…ç½®æ¨¡æ¿æ•°é‡: {len(templates)}")
        
        for template in templates[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæ¨¡æ¿
            logger.info(f"  - {template['name']} ({template['template_type']})")
        
        # æ¼”ç¤º2: åˆ›å»ºç³»ç»Ÿæç¤ºè¯
        logger.info("\nğŸ¯ æ¼”ç¤º2: åˆ›å»ºç³»ç»Ÿæç¤ºè¯")
        
        system_prompt = await prompt_manager.create_system_prompt(
            agent_type="programming",
            capabilities=["Python", "JavaScript", "SQL"],
            personality="professional",
            context="Webå¼€å‘é¡¹ç›®"
        )
        
        logger.info("âœ… ç¼–ç¨‹åŠ©æ‰‹ç³»ç»Ÿæç¤ºè¯åˆ›å»ºæˆåŠŸ:")
        logger.info(f"   é•¿åº¦: {len(system_prompt)} å­—ç¬¦")
        logger.info(f"   åŒ…å«å…³é”®è¯: {'Python' in system_prompt}, {'JavaScript' in system_prompt}")
        
        # æ¼”ç¤º3: åˆ›å»ºå·¥ä½œæµæç¤ºè¯
        logger.info("\nâš™ï¸ æ¼”ç¤º3: åˆ›å»ºå·¥ä½œæµæç¤ºè¯")
        
        workflow_prompt = await prompt_manager.create_workflow_prompt(
            workflow_name="æ•°æ®åˆ†æå·¥ä½œæµ",
            step_name="æ•°æ®æ¸…æ´—",
            step_type="data_processing",
            step_description="æ¸…æ´—å’Œé¢„å¤„ç†è¾“å…¥æ•°æ®",
            expected_output="æ¸…æ´—åçš„æ•°æ®é›†",
            previous_steps=["æ•°æ®æ”¶é›†"],
            current_input="åŸå§‹CSVæ•°æ®",
            available_resources=["pandas", "numpy"],
            constraints=["å†…å­˜é™åˆ¶: 8GB", "æ—¶é—´é™åˆ¶: 30åˆ†é’Ÿ"]
        )
        
        logger.info("âœ… å·¥ä½œæµæ­¥éª¤æç¤ºè¯åˆ›å»ºæˆåŠŸ:")
        logger.info(f"   é•¿åº¦: {len(workflow_prompt)} å­—ç¬¦")
        logger.info(f"   åŒ…å«æ­¥éª¤ä¿¡æ¯: {'æ•°æ®æ¸…æ´—' in workflow_prompt}")
        
        # æ¼”ç¤º4: æç¤ºè¯ä¼˜åŒ–
        logger.info("\nğŸ”§ æ¼”ç¤º4: æç¤ºè¯ä¼˜åŒ–")
        
        # åˆ›å»ºä¸€ä¸ªéœ€è¦ä¼˜åŒ–çš„æç¤ºè¯
        raw_prompt = """
        Please, could you very kindly help me with this task? 
        You should maybe possibly create some code for me.
        I'm not really sure what I need exactly, but perhaps you could do something useful.
        """
        
        optimizer = PromptOptimizer()
        optimized_prompt = await optimizer.optimize_prompt(
            raw_prompt,
            TemplateType.SYSTEM_PROMPT,
            "advanced"
        )
        
        logger.info("âœ… æç¤ºè¯ä¼˜åŒ–å®Œæˆ:")
        logger.info(f"   åŸå§‹é•¿åº¦: {len(raw_prompt)} å­—ç¬¦")
        logger.info(f"   ä¼˜åŒ–åé•¿åº¦: {len(optimized_prompt)} å­—ç¬¦")
        logger.info(f"   ç§»é™¤äº†å†—ä½™è¯æ±‡: {'please' not in optimized_prompt.lower()}")
        
        # æ¼”ç¤º5: æç¤ºè¯åˆ†æ
        logger.info("\nğŸ“Š æ¼”ç¤º5: æç¤ºè¯è´¨é‡åˆ†æ")
        
        analyzer = PromptAnalyzer()
        analysis = await analyzer.analyze_prompt(system_prompt)
        
        logger.info("âœ… æç¤ºè¯åˆ†æå®Œæˆ:")
        logger.info(f"   æ€»ä½“è¯„åˆ†: {analysis['overall_score']}/100")
        logger.info(f"   è´¨é‡è¯„åˆ†: {analysis['quality_scores']}")
        logger.info(f"   é£é™©ç­‰çº§: {analysis['risk_assessment']['risk_level']}")
        logger.info(f"   å»ºè®®æ•°é‡: {len(analysis['suggestions'])}")
        
        if analysis['suggestions']:
            logger.info("   æ”¹è¿›å»ºè®®:")
            for suggestion in analysis['suggestions'][:3]:
                logger.info(f"     - {suggestion}")
        
        # æ¼”ç¤º6: æ ¼å¼è½¬æ¢
        logger.info("\nğŸ”„ æ¼”ç¤º6: æç¤ºè¯æ ¼å¼è½¬æ¢")
        
        converter = PromptConverter()
        
        # è½¬æ¢ä¸ºä¸åŒæ¡†æ¶æ ¼å¼
        openai_format = converter.convert_to_openai_format(system_prompt, "general")
        autogen_format = converter.convert_to_autogen_format(system_prompt, "general")
        
        logger.info("âœ… æ ¼å¼è½¬æ¢å®Œæˆ:")
        logger.info(f"   OpenAIæ ¼å¼é•¿åº¦: {len(openai_format)} å­—ç¬¦")
        logger.info(f"   AutoGenæ ¼å¼é•¿åº¦: {len(autogen_format)} å­—ç¬¦")
        logger.info(f"   æ”¯æŒçš„æ ¼å¼: {converter.get_supported_formats()}")
        
        # æ¼”ç¤º7: æ‰¹é‡åˆ›å»ºæç¤ºè¯
        logger.info("\nğŸ“¦ æ¼”ç¤º7: æ‰¹é‡åˆ›å»ºæç¤ºè¯")
        
        batch_requests = [
            {
                "template_id": "system_assistant",
                "variables": {"context": "é€šç”¨åŠ©æ‰‹"},
                "optimization_level": "basic"
            },
            {
                "template_id": "analysis_assistant", 
                "variables": {
                    "analysis_type": "æ•°æ®åˆ†æ",
                    "data_context": "ç”¨æˆ·æ•°æ®",
                    "output_format": "JSONæ ¼å¼"
                },
                "optimization_level": "advanced"
            }
        ]
        
        batch_results = await prompt_manager.batch_create_prompts(batch_requests)
        
        logger.info("âœ… æ‰¹é‡åˆ›å»ºå®Œæˆ:")
        for i, result in enumerate(batch_results, 1):
            if result['success']:
                logger.info(f"   æç¤ºè¯ {i}: åˆ›å»ºæˆåŠŸ ({len(result['data']['content'])} å­—ç¬¦)")
            else:
                logger.info(f"   æç¤ºè¯ {i}: åˆ›å»ºå¤±è´¥ - {result['error']}")
        
        # æ¼”ç¤º8: æç¤ºè¯é“¾
        logger.info("\nğŸ”— æ¼”ç¤º8: æç¤ºè¯é“¾åˆ›å»º")
        
        chain_config = [
            {
                "step_id": "step_1",
                "template_id": "system_assistant",
                "variables": {"context": "ç¬¬ä¸€æ­¥ï¼šç†è§£éœ€æ±‚"},
                "optimization_level": "basic"
            },
            {
                "step_id": "step_2", 
                "template_id": "analysis_assistant",
                "variables": {
                    "analysis_type": "éœ€æ±‚åˆ†æ",
                    "data_context": "ç”¨æˆ·è¾“å…¥",
                    "output_format": "ç»“æ„åŒ–åˆ†æ"
                },
                "optimization_level": "advanced",
                "output_variables": {
                    "analysis_result": "analysis_output"
                }
            }
        ]
        
        chain_results = await prompt_manager.create_prompt_chain(chain_config)
        
        logger.info("âœ… æç¤ºè¯é“¾åˆ›å»ºå®Œæˆ:")
        for step in chain_results:
            if step['success']:
                logger.info(f"   æ­¥éª¤ {step['step_id']}: æˆåŠŸ")
            else:
                logger.info(f"   æ­¥éª¤ {step['step_id']}: å¤±è´¥ - {step['error']}")
        
        # æ€»ç»“
        logger.info("\nğŸ‰ === æç¤ºè¯å·¥ç¨‹æ¼”ç¤ºå®Œæˆ ===")
        logger.info("âœ… æç¤ºè¯æ¨¡æ¿ç®¡ç†åŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… ç³»ç»Ÿæç¤ºè¯åˆ›å»ºåŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… å·¥ä½œæµæç¤ºè¯åˆ›å»ºåŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… æç¤ºè¯åˆ†æåŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… æ ¼å¼è½¬æ¢åŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… æ‰¹é‡åˆ›å»ºåŠŸèƒ½æ­£å¸¸")
        logger.info("âœ… æç¤ºè¯é“¾åŠŸèƒ½æ­£å¸¸")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False


async def demo_custom_template():
    """æ¼”ç¤ºè‡ªå®šä¹‰æ¨¡æ¿åˆ›å»º"""
    logger.info("\nğŸ¨ === è‡ªå®šä¹‰æ¨¡æ¿åˆ›å»ºæ¼”ç¤º ===")
    
    try:
        # åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿
        custom_template = PromptTemplate(
            template_id="custom_code_review",
            name="ä»£ç å®¡æŸ¥åŠ©æ‰‹",
            description="ä¸“é—¨ç”¨äºä»£ç å®¡æŸ¥çš„æç¤ºè¯æ¨¡æ¿",
            template_type=TemplateType.SYSTEM_PROMPT,
            category=PromptCategory.PROGRAMMING,
            content="""You are an expert code reviewer specializing in {{languages}}.

Your code review expertise includes:
- Code quality and best practices
- Security vulnerabilities and risks
- Performance optimization opportunities
- Maintainability and readability
- Testing coverage and quality

Review guidelines:
- Be constructive and specific in feedback
- Provide actionable suggestions for improvement
- Consider both technical and business requirements
- Highlight critical issues that need immediate attention
- Suggest alternative approaches when appropriate

Code to review: {{code_snippet}}
Programming language: {{languages}}
Review focus: {{review_focus}}
Output format: {{output_format}}""",
            variables=["languages", "code_snippet", "review_focus", "output_format"],
            tags=["code-review", "programming", "quality"]
        )
        
        # æ³¨å†Œæ¨¡æ¿
        prompt_manager = PromptManager()
        prompt_manager.register_template(custom_template)
        
        # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿
        review_prompt = await prompt_manager.create_prompt(
            template_id="custom_code_review",
            variables={
                "languages": "Python, JavaScript",
                "code_snippet": "def calculate_sum(a, b): return a + b",
                "review_focus": "security and performance",
                "output_format": "structured feedback"
            },
            optimization_level="advanced"
        )
        
        logger.info("âœ… è‡ªå®šä¹‰æ¨¡æ¿åˆ›å»ºå’Œä½¿ç”¨æˆåŠŸ:")
        logger.info(f"   æ¨¡æ¿åç§°: {custom_template.name}")
        logger.info(f"   æ¨¡æ¿ç±»å‹: {custom_template.template_type.value}")
        logger.info(f"   å˜é‡æ•°é‡: {len(custom_template.variables)}")
        logger.info(f"   ç”Ÿæˆçš„æç¤ºè¯é•¿åº¦: {len(review_prompt['content'])} å­—ç¬¦")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ è‡ªå®šä¹‰æ¨¡æ¿æ¼”ç¤ºå¤±è´¥: {e}")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    success1 = await demo_prompt_engineering()
    success2 = await demo_custom_template()
    
    if success1 and success2:
        logger.info("\nğŸŠ === æ‰€æœ‰æ¼”ç¤ºæˆåŠŸå®Œæˆ ===")
        return True
    else:
        logger.error("\nâŒ === éƒ¨åˆ†æ¼”ç¤ºå¤±è´¥ ===")
        return False


if __name__ == "__main__":
    asyncio.run(main()) 