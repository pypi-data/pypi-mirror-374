"""
çŸ¥è¯†è·¯ç”±å†³ç­–ç³»ç»Ÿ
æ™ºèƒ½å†³å®šä½•æ—¶ä½¿ç”¨çŸ¥è¯†åº“ vs AIè®­ç»ƒçŸ¥è¯† vs ç½‘ç»œæœç´¢

å†³ç­–ç­–ç•¥ï¼š
1. é¢†åŸŸä¸“ä¸šæ€§è¯„ä¼°
2. çŸ¥è¯†æ–°é²œåº¦è¦æ±‚
3. ç½®ä¿¡åº¦é˜ˆå€¼
4. æŸ¥è¯¢å¤æ‚åº¦åˆ†æ
5. æˆæœ¬æ•ˆç›Šè€ƒè™‘
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import re

logger = logging.getLogger(__name__)


class KnowledgeSourceType(Enum):
    """çŸ¥è¯†æºç±»å‹"""
    LOCAL_KNOWLEDGE_BASE = "local_kb"      # æœ¬åœ°çŸ¥è¯†åº“
    AI_TRAINING_DATA = "ai_training"       # AIè®­ç»ƒæ•°æ®
    WEB_SEARCH = "web_search"              # ç½‘ç»œæœç´¢
    HYBRID = "hybrid"                      # æ··åˆæ¨¡å¼


class QueryComplexity(Enum):
    """æŸ¥è¯¢å¤æ‚åº¦"""
    SIMPLE = "simple"          # ç®€å•æŸ¥è¯¢ï¼ˆæ¦‚å¿µã€å®šä¹‰ï¼‰
    MODERATE = "moderate"      # ä¸­ç­‰æŸ¥è¯¢ï¼ˆæ–¹æ³•ã€ç¤ºä¾‹ï¼‰
    COMPLEX = "complex"        # å¤æ‚æŸ¥è¯¢ï¼ˆåˆ†æã€è®¾è®¡ï¼‰
    CREATIVE = "creative"      # åˆ›é€ æ€§æŸ¥è¯¢ï¼ˆç”Ÿæˆã€åˆ›æ–°ï¼‰


class QueryDomain(Enum):
    """æŸ¥è¯¢é¢†åŸŸ"""
    FPGA_SPECIFIC = "fpga_specific"        # FPGAä¸“ä¸šçŸ¥è¯†
    GENERAL_TECH = "general_tech"          # é€šç”¨æŠ€æœ¯çŸ¥è¯†
    CURRENT_EVENTS = "current_events"      # æ—¶äº‹åŠ¨æ€
    CREATIVE_TASK = "creative_task"        # åˆ›é€ æ€§ä»»åŠ¡


@dataclass
class QueryAnalysis:
    """æŸ¥è¯¢åˆ†æç»“æœ"""
    query: str
    complexity: QueryComplexity
    domain: QueryDomain
    keywords: List[str]
    requires_latest_info: bool = False
    requires_creativity: bool = False
    requires_precision: bool = True
    confidence: float = 1.0


@dataclass
class KnowledgeSourceDecision:
    """çŸ¥è¯†æºå†³ç­–ç»“æœ"""
    primary_source: KnowledgeSourceType
    secondary_sources: List[KnowledgeSourceType] = field(default_factory=list)
    reasoning: str = ""
    confidence: float = 1.0
    estimated_cost: float = 0.0
    expected_latency: float = 0.0


@dataclass
class KnowledgeSourceCapability:
    """çŸ¥è¯†æºèƒ½åŠ›æè¿°"""
    source_type: KnowledgeSourceType
    strengths: List[str]
    weaknesses: List[str]
    cost_per_query: float  # ç›¸å¯¹æˆæœ¬
    avg_latency: float     # å¹³å‡å»¶è¿Ÿï¼ˆç§’ï¼‰
    coverage_domains: List[QueryDomain]
    freshness_score: float  # çŸ¥è¯†æ–°é²œåº¦ 0-1


class KnowledgeRouter:
    """
    çŸ¥è¯†è·¯ç”±å†³ç­–ç³»ç»Ÿ
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æŸ¥è¯¢æ„å›¾åˆ†æ
    - çŸ¥è¯†æºèƒ½åŠ›è¯„ä¼°
    - æ™ºèƒ½è·¯ç”±å†³ç­–
    - æˆæœ¬æ•ˆç›Šä¼˜åŒ–
    - å¤šæºèåˆç­–ç•¥
    """
    
    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†è·¯ç”±å™¨"""
        
        # å®šä¹‰å„çŸ¥è¯†æºçš„èƒ½åŠ›ç‰¹å¾
        self.source_capabilities = {
            KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE: KnowledgeSourceCapability(
                source_type=KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE,
                strengths=[
                    "FPGAä¸“ä¸šçŸ¥è¯†æ·±åº¦",
                    "å“åº”é€Ÿåº¦å¿«",
                    "æˆæœ¬ä½",
                    "ç¦»çº¿å¯ç”¨",
                    "çŸ¥è¯†è´¨é‡å¯æ§"
                ],
                weaknesses=[
                    "çŸ¥è¯†è¦†ç›–é¢æœ‰é™",
                    "æ›´æ–°é¢‘ç‡ä½",
                    "ç¼ºä¹æœ€æ–°ä¿¡æ¯",
                    "åˆ›é€ æ€§æœ‰é™"
                ],
                cost_per_query=0.1,
                avg_latency=0.2,
                coverage_domains=[QueryDomain.FPGA_SPECIFIC],
                freshness_score=0.6
            ),
            
            KnowledgeSourceType.AI_TRAINING_DATA: KnowledgeSourceCapability(
                source_type=KnowledgeSourceType.AI_TRAINING_DATA,
                strengths=[
                    "çŸ¥è¯†è¦†ç›–é¢å¹¿",
                    "æ¨ç†èƒ½åŠ›å¼º",
                    "åˆ›é€ æ€§å¥½",
                    "è¯­è¨€ç†è§£ä½³",
                    "å¯ç”Ÿæˆæ–°å†…å®¹"
                ],
                weaknesses=[
                    "çŸ¥è¯†æˆªæ­¢æ—¶é—´é™åˆ¶",
                    "å¯èƒ½ä¸å¤Ÿç²¾ç¡®",
                    "æˆæœ¬è¾ƒé«˜",
                    "å“åº”æ—¶é—´è¾ƒé•¿"
                ],
                cost_per_query=1.0,
                avg_latency=2.0,
                coverage_domains=[QueryDomain.FPGA_SPECIFIC, QueryDomain.GENERAL_TECH, QueryDomain.CREATIVE_TASK],
                freshness_score=0.4
            ),
            
            KnowledgeSourceType.WEB_SEARCH: KnowledgeSourceCapability(
                source_type=KnowledgeSourceType.WEB_SEARCH,
                strengths=[
                    "ä¿¡æ¯æœ€æ–°",
                    "è¦†ç›–é¢æœ€å¹¿",
                    "å®æ—¶æ›´æ–°",
                    "å¤šæ ·åŒ–æ¥æº"
                ],
                weaknesses=[
                    "è´¨é‡å‚å·®ä¸é½",
                    "éœ€è¦ç­›é€‰",
                    "å»¶è¿Ÿè¾ƒé«˜",
                    "éœ€è¦ç½‘ç»œè¿æ¥"
                ],
                cost_per_query=0.5,
                avg_latency=3.0,
                coverage_domains=[QueryDomain.CURRENT_EVENTS, QueryDomain.GENERAL_TECH],
                freshness_score=1.0
            )
        }
        
        # æŸ¥è¯¢æ¨¡å¼å®šä¹‰
        self.query_patterns = {
            # FPGAä¸“ä¸šæ¨¡å¼
            'fpga_specific': [
                r'verilog|systemverilog|vhdl',
                r'fpga|xilinx|altera|intel',
                r'vivado|quartus|modelsim',
                r'synthesis|simulation|timing',
                r'state\s+machine|pipeline|fifo',
                r'clock|reset|constraint'
            ],
            
            # éœ€è¦æœ€æ–°ä¿¡æ¯çš„æ¨¡å¼
            'latest_info': [
                r'æœ€æ–°|latest|new|recent',
                r'2024|2025|ä»Šå¹´|this\s+year',
                r'æ›´æ–°|update|upgrade',
                r'å‘å¸ƒ|release|announcement'
            ],
            
            # åˆ›é€ æ€§ä»»åŠ¡æ¨¡å¼
            'creative': [
                r'è®¾è®¡|design|create|generate',
                r'å¸®æˆ‘å†™|help.*write|write.*for',
                r'å¦‚ä½•å®ç°|how.*implement',
                r'ä¼˜åŒ–|optimize|improve'
            ],
            
            # ç²¾ç¡®æ€§è¦æ±‚æ¨¡å¼
            'precision': [
                r'å…·ä½“|specific|exact',
                r'å‚æ•°|parameter|specification',
                r'æ ‡å‡†|standard|protocol',
                r'è§„èŒƒ|specification|requirement'
            ]
        }
        
        logger.info("ğŸ§­ çŸ¥è¯†è·¯ç”±å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def route_query(self, query: str, context: Dict[str, Any] = None) -> KnowledgeSourceDecision:
        """è·¯ç”±æŸ¥è¯¢åˆ°æœ€é€‚åˆçš„çŸ¥è¯†æº"""
        
        logger.info(f"ğŸ§­ è·¯ç”±æŸ¥è¯¢: {query[:100]}...")
        
        # 1. åˆ†ææŸ¥è¯¢
        analysis = await self._analyze_query(query, context or {})
        
        # 2. è¯„ä¼°çŸ¥è¯†æºé€‚ç”¨æ€§
        source_scores = await self._evaluate_sources(analysis)
        
        # 3. åšå‡ºå†³ç­–
        decision = await self._make_decision(analysis, source_scores)
        
        logger.info(f"ğŸ“ è·¯ç”±å†³ç­–: {decision.primary_source.value} (ç½®ä¿¡åº¦: {decision.confidence:.2f})")
        logger.debug(f"   æ¨ç†: {decision.reasoning}")
        
        return decision
    
    async def _analyze_query(self, query: str, context: Dict[str, Any]) -> QueryAnalysis:
        """åˆ†ææŸ¥è¯¢ç‰¹å¾"""
        
        query_lower = query.lower()
        
        # åˆ†æå¤æ‚åº¦
        complexity = self._analyze_complexity(query)
        
        # åˆ†æé¢†åŸŸ
        domain = self._analyze_domain(query)
        
        # æå–å…³é”®è¯
        keywords = self._extract_keywords(query)
        
        # åˆ†æç‰¹æ®Šéœ€æ±‚
        requires_latest_info = self._requires_latest_info(query)
        requires_creativity = self._requires_creativity(query)
        requires_precision = self._requires_precision(query)
        
        analysis = QueryAnalysis(
            query=query,
            complexity=complexity,
            domain=domain,
            keywords=keywords,
            requires_latest_info=requires_latest_info,
            requires_creativity=requires_creativity,
            requires_precision=requires_precision
        )
        
        logger.debug(f"ğŸ“Š æŸ¥è¯¢åˆ†æ: å¤æ‚åº¦={complexity.value}, é¢†åŸŸ={domain.value}")
        return analysis
    
    def _analyze_complexity(self, query: str) -> QueryComplexity:
        """åˆ†ææŸ¥è¯¢å¤æ‚åº¦"""
        query_lower = query.lower()
        
        # åˆ›é€ æ€§æŒ‡æ ‡
        creative_indicators = ['è®¾è®¡', 'ç”Ÿæˆ', 'åˆ›å»º', 'design', 'generate', 'create', 'å¸®æˆ‘å†™']
        if any(indicator in query_lower for indicator in creative_indicators):
            return QueryComplexity.CREATIVE
        
        # å¤æ‚æŸ¥è¯¢æŒ‡æ ‡
        complex_indicators = ['åˆ†æ', 'æ¯”è¾ƒ', 'ä¼˜åŒ–', 'analyze', 'compare', 'optimize', 'å¦‚ä½•å®ç°']
        if any(indicator in query_lower for indicator in complex_indicators):
            return QueryComplexity.COMPLEX
        
        # ä¸­ç­‰å¤æ‚åº¦æŒ‡æ ‡
        moderate_indicators = ['ç¤ºä¾‹', 'æ–¹æ³•', 'example', 'method', 'how', 'æ€ä¹ˆ']
        if any(indicator in query_lower for indicator in moderate_indicators):
            return QueryComplexity.MODERATE
        
        # ç®€å•æŸ¥è¯¢ï¼ˆå®šä¹‰ã€æ¦‚å¿µç­‰ï¼‰
        return QueryComplexity.SIMPLE
    
    def _analyze_domain(self, query: str) -> QueryDomain:
        """åˆ†ææŸ¥è¯¢é¢†åŸŸ"""
        query_lower = query.lower()
        
        # FPGAä¸“ä¸šé¢†åŸŸ
        fpga_keywords = [
            'verilog', 'systemverilog', 'vhdl', 'fpga', 'xilinx', 'altera',
            'vivado', 'quartus', 'synthesis', 'timing', 'constraint',
            'state machine', 'pipeline', 'fifo', 'clock', 'reset'
        ]
        
        if any(keyword in query_lower for keyword in fpga_keywords):
            return QueryDomain.FPGA_SPECIFIC
        
        # æ—¶äº‹åŠ¨æ€
        current_keywords = ['æœ€æ–°', '2024', '2025', 'latest', 'recent', 'new']
        if any(keyword in query_lower for keyword in current_keywords):
            return QueryDomain.CURRENT_EVENTS
        
        # åˆ›é€ æ€§ä»»åŠ¡
        creative_keywords = ['è®¾è®¡', 'ç”Ÿæˆ', 'åˆ›å»º', 'design', 'generate', 'create']
        if any(keyword in query_lower for keyword in creative_keywords):
            return QueryDomain.CREATIVE_TASK
        
        return QueryDomain.GENERAL_TECH
    
    def _extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„NLPæ–¹æ³•ï¼‰
        words = re.findall(r'\b\w+\b', query.lower())
        
        # è¿‡æ»¤åœç”¨è¯
        stop_words = {'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'the', 'is', 'in', 'and', 'or', 'a', 'an'}
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        
        return keywords[:10]  # é™åˆ¶æ•°é‡
    
    def _requires_latest_info(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æœ€æ–°ä¿¡æ¯"""
        latest_patterns = self.query_patterns['latest_info']
        return any(re.search(pattern, query, re.IGNORECASE) for pattern in latest_patterns)
    
    def _requires_creativity(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ›é€ æ€§"""
        creative_patterns = self.query_patterns['creative']
        return any(re.search(pattern, query, re.IGNORECASE) for pattern in creative_patterns)
    
    def _requires_precision(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é«˜ç²¾ç¡®æ€§"""
        precision_patterns = self.query_patterns['precision']
        return any(re.search(pattern, query, re.IGNORECASE) for pattern in precision_patterns)
    
    async def _evaluate_sources(self, analysis: QueryAnalysis) -> Dict[KnowledgeSourceType, float]:
        """è¯„ä¼°å„çŸ¥è¯†æºçš„é€‚ç”¨æ€§å¾—åˆ†"""
        
        scores = {}
        
        for source_type, capability in self.source_capabilities.items():
            score = 0.0
            
            # 1. é¢†åŸŸåŒ¹é…åº¦ (40%)
            domain_match = 0.0
            if analysis.domain in capability.coverage_domains:
                domain_match = 1.0
            elif analysis.domain == QueryDomain.GENERAL_TECH:
                domain_match = 0.7  # é€šç”¨æŠ€æœ¯çŸ¥è¯†å¤§éƒ¨åˆ†æºéƒ½èƒ½å¤„ç†
            
            score += domain_match * 0.4
            
            # 2. å¤æ‚åº¦é€‚åº”æ€§ (25%)
            complexity_match = self._evaluate_complexity_match(analysis.complexity, capability)
            score += complexity_match * 0.25
            
            # 3. ç‰¹æ®Šéœ€æ±‚åŒ¹é… (20%)
            special_match = self._evaluate_special_requirements(analysis, capability)
            score += special_match * 0.2
            
            # 4. æˆæœ¬æ•ˆç›Š (10%)
            cost_efficiency = max(0, 1.0 - capability.cost_per_query / 2.0)
            score += cost_efficiency * 0.1
            
            # 5. å“åº”é€Ÿåº¦ (5%)
            speed_score = max(0, 1.0 - capability.avg_latency / 5.0)
            score += speed_score * 0.05
            
            scores[source_type] = score
        
        return scores
    
    def _evaluate_complexity_match(self, complexity: QueryComplexity, capability: KnowledgeSourceCapability) -> float:
        """è¯„ä¼°å¤æ‚åº¦åŒ¹é…åº¦"""
        
        if capability.source_type == KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE:
            # çŸ¥è¯†åº“é€‚åˆç®€å•åˆ°ä¸­ç­‰å¤æ‚åº¦çš„æŸ¥è¯¢
            if complexity in [QueryComplexity.SIMPLE, QueryComplexity.MODERATE]:
                return 1.0
            elif complexity == QueryComplexity.COMPLEX:
                return 0.6
            else:  # CREATIVE
                return 0.3
        
        elif capability.source_type == KnowledgeSourceType.AI_TRAINING_DATA:
            # AIè®­ç»ƒæ•°æ®é€‚åˆæ‰€æœ‰å¤æ‚åº¦ï¼Œç‰¹åˆ«æ˜¯åˆ›é€ æ€§ä»»åŠ¡
            if complexity == QueryComplexity.CREATIVE:
                return 1.0
            elif complexity == QueryComplexity.COMPLEX:
                return 0.9
            else:
                return 0.8
        
        elif capability.source_type == KnowledgeSourceType.WEB_SEARCH:
            # ç½‘ç»œæœç´¢é€‚åˆä¸­ç­‰åˆ°å¤æ‚çš„æŸ¥è¯¢
            if complexity in [QueryComplexity.MODERATE, QueryComplexity.COMPLEX]:
                return 0.8
            elif complexity == QueryComplexity.SIMPLE:
                return 0.6
            else:  # CREATIVE
                return 0.4
        
        return 0.5
    
    def _evaluate_special_requirements(self, analysis: QueryAnalysis, capability: KnowledgeSourceCapability) -> float:
        """è¯„ä¼°ç‰¹æ®Šéœ€æ±‚åŒ¹é…åº¦"""
        score = 0.0
        requirements_count = 0
        
        # æœ€æ–°ä¿¡æ¯éœ€æ±‚
        if analysis.requires_latest_info:
            requirements_count += 1
            score += capability.freshness_score
        
        # åˆ›é€ æ€§éœ€æ±‚
        if analysis.requires_creativity:
            requirements_count += 1
            if capability.source_type == KnowledgeSourceType.AI_TRAINING_DATA:
                score += 1.0
            elif capability.source_type == KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE:
                score += 0.3
            else:
                score += 0.5
        
        # ç²¾ç¡®æ€§éœ€æ±‚
        if analysis.requires_precision:
            requirements_count += 1
            if capability.source_type == KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE:
                score += 1.0
            elif capability.source_type == KnowledgeSourceType.AI_TRAINING_DATA:
                score += 0.7
            else:
                score += 0.5
        
        return score / max(1, requirements_count)
    
    async def _make_decision(self, analysis: QueryAnalysis, scores: Dict[KnowledgeSourceType, float]) -> KnowledgeSourceDecision:
        """åšå‡ºæœ€ç»ˆå†³ç­–"""
        
        # æ’åºå¾—åˆ†
        sorted_sources = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        primary_source = sorted_sources[0][0]
        primary_score = sorted_sources[0][1]
        
        # é€‰æ‹©è¾…åŠ©æº
        secondary_sources = []
        for source, score in sorted_sources[1:]:
            if score > 0.6:  # é˜ˆå€¼
                secondary_sources.append(source)
        
        # ç”Ÿæˆæ¨ç†è¯´æ˜
        reasoning = self._generate_reasoning(analysis, primary_source, primary_score)
        
        # ä¼°ç®—æˆæœ¬å’Œå»¶è¿Ÿ
        capability = self.source_capabilities[primary_source]
        estimated_cost = capability.cost_per_query
        expected_latency = capability.avg_latency
        
        return KnowledgeSourceDecision(
            primary_source=primary_source,
            secondary_sources=secondary_sources,
            reasoning=reasoning,
            confidence=primary_score,
            estimated_cost=estimated_cost,
            expected_latency=expected_latency
        )
    
    def _generate_reasoning(self, analysis: QueryAnalysis, source: KnowledgeSourceType, score: float) -> str:
        """ç”Ÿæˆå†³ç­–æ¨ç†"""
        
        capability = self.source_capabilities[source]
        
        reasons = []
        
        # é¢†åŸŸåŒ¹é…
        if analysis.domain in capability.coverage_domains:
            reasons.append(f"é¢†åŸŸåŒ¹é…åº¦é«˜({analysis.domain.value})")
        
        # ç‰¹æ®Šéœ€æ±‚
        if analysis.requires_latest_info and capability.freshness_score > 0.8:
            reasons.append("æ»¡è¶³æœ€æ–°ä¿¡æ¯éœ€æ±‚")
        
        if analysis.requires_creativity and source == KnowledgeSourceType.AI_TRAINING_DATA:
            reasons.append("é€‚åˆåˆ›é€ æ€§ä»»åŠ¡")
        
        if analysis.requires_precision and source == KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE:
            reasons.append("æä¾›é«˜ç²¾ç¡®åº¦ç­”æ¡ˆ")
        
        # æˆæœ¬æ•ˆç›Š
        if capability.cost_per_query < 0.5:
            reasons.append("æˆæœ¬æ•ˆç›Šå¥½")
        
        if capability.avg_latency < 1.0:
            reasons.append("å“åº”é€Ÿåº¦å¿«")
        
        return f"é€‰æ‹©{source.value}å› ä¸º: {', '.join(reasons)} (ç»¼åˆå¾—åˆ†: {score:.2f})"
    
    def get_source_info(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†æºä¿¡æ¯"""
        return {
            source.value: {
                'strengths': cap.strengths,
                'weaknesses': cap.weaknesses,
                'cost': cap.cost_per_query,
                'latency': cap.avg_latency,
                'domains': [d.value for d in cap.coverage_domains],
                'freshness': cap.freshness_score
            }
            for source, cap in self.source_capabilities.items()
        }


# å…¨å±€è·¯ç”±å™¨å®ä¾‹
_knowledge_router_instance: Optional[KnowledgeRouter] = None


def get_knowledge_router() -> KnowledgeRouter:
    """è·å–çŸ¥è¯†è·¯ç”±å™¨å•ä¾‹"""
    global _knowledge_router_instance
    
    if _knowledge_router_instance is None:
        _knowledge_router_instance = KnowledgeRouter()
    
    return _knowledge_router_instance 