"""
å¢å¼ºç‰ˆçŸ¥è¯†è·¯ç”±å™¨
å®ç°åŠ¨æ€æƒé‡ã€ç”¨æˆ·ç”»åƒã€åé¦ˆå­¦ä¹ ã€å†³ç­–å®¡è®¡ç­‰é«˜çº§åŠŸèƒ½

æ–°å¢ç‰¹æ€§ï¼š
1. åŠ¨æ€æƒé‡ä¸ä¸Šä¸‹æ–‡æ„ŸçŸ¥
2. ç”¨æˆ·ç”»åƒä¸è§’è‰²è¯†åˆ«
3. åé¦ˆå­¦ä¹ ä¸æŒç»­ä¼˜åŒ–
4. å†³ç­–å®¡è®¡æ—¥å¿—
5. é™çº§ç­–ç•¥ä¸æ•…éšœè½¬ç§»
6. æŠ½è±¡è·¯ç”±å™¨æ¥å£
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from abc import ABC, abstractmethod
import json
import hashlib
from pathlib import Path

from .knowledge_router import (
    KnowledgeSourceType, QueryComplexity, QueryDomain, 
    QueryAnalysis, KnowledgeSourceDecision, KnowledgeSourceCapability
)

logger = logging.getLogger(__name__)


class UserRole(Enum):
    """ç”¨æˆ·è§’è‰²"""
    BEGINNER = "beginner"      # åˆå­¦è€…
    INTERMEDIATE = "intermediate"  # ä¸­çº§ç”¨æˆ·
    EXPERT = "expert"          # ä¸“å®¶
    RESEARCHER = "researcher"  # ç ”ç©¶è€…


class ContextType(Enum):
    """å¯¹è¯ä¸Šä¸‹æ–‡ç±»å‹"""
    STANDALONE = "standalone"      # ç‹¬ç«‹æŸ¥è¯¢
    FOLLOW_UP = "follow_up"       # åç»­é—®é¢˜
    DEEP_DIVE = "deep_dive"       # æ·±å…¥æ¢è®¨
    TROUBLESHOOTING = "troubleshooting"  # é—®é¢˜æ’æŸ¥


class FeedbackType(Enum):
    """åé¦ˆç±»å‹"""
    THUMBS_UP = "thumbs_up"
    THUMBS_DOWN = "thumbs_down"
    FOLLOW_UP_QUESTION = "follow_up_question"
    SATISFACTION_RATING = "satisfaction_rating"


@dataclass
class UserProfile:
    """ç”¨æˆ·ç”»åƒ"""
    user_id: str
    role: UserRole = UserRole.INTERMEDIATE
    expertise_domains: List[str] = field(default_factory=list)
    preferred_detail_level: str = "medium"  # low, medium, high
    cost_sensitivity: float = 0.5  # 0-1, è¶Šé«˜è¶Šåœ¨æ„æˆæœ¬
    speed_preference: float = 0.5  # 0-1, è¶Šé«˜è¶Šåœ¨æ„é€Ÿåº¦
    interaction_history: List[Dict] = field(default_factory=list)
    feedback_score: float = 0.8  # å†å²åé¦ˆå¹³å‡åˆ†
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡"""
    conversation_id: str
    context_type: ContextType = ContextType.STANDALONE
    previous_queries: List[str] = field(default_factory=list)
    previous_decisions: List[KnowledgeSourceDecision] = field(default_factory=list)
    topic_thread: Optional[str] = None  # å½“å‰è®¨è®ºçš„ä¸»é¢˜
    knowledge_domain_focus: Optional[QueryDomain] = None
    session_cost_used: float = 0.0
    session_start: datetime = field(default_factory=datetime.now)


@dataclass
class DecisionAuditLog:
    """å†³ç­–å®¡è®¡æ—¥å¿—"""
    log_id: str
    timestamp: datetime
    user_id: str
    query: str
    query_analysis: QueryAnalysis
    all_source_scores: Dict[KnowledgeSourceType, float]
    final_decision: KnowledgeSourceDecision
    router_type: str
    router_version: str
    execution_time_ms: float
    context: Optional[ConversationContext] = None
    user_profile: Optional[UserProfile] = None
    feedback: Optional[Dict] = None
    success: bool = True
    error_message: Optional[str] = None


@dataclass
class RoutingFeedback:
    """è·¯ç”±åé¦ˆ"""
    decision_id: str
    feedback_type: FeedbackType
    rating: Optional[float] = None  # 1-5
    comment: Optional[str] = None
    implicit_signals: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)


class AbstractRouter(ABC):
    """æŠ½è±¡è·¯ç”±å™¨æ¥å£"""
    
    @abstractmethod
    async def route_query(
        self, 
        query: str, 
        user_profile: Optional[UserProfile] = None,
        context: Optional[ConversationContext] = None
    ) -> KnowledgeSourceDecision:
        """è·¯ç”±æŸ¥è¯¢åˆ°æœ€é€‚åˆçš„çŸ¥è¯†æº"""
        pass
    
    @abstractmethod
    def get_router_info(self) -> Dict[str, Any]:
        """è·å–è·¯ç”±å™¨ä¿¡æ¯"""
        pass


class EnhancedKnowledgeRouter(AbstractRouter):
    """
    å¢å¼ºç‰ˆçŸ¥è¯†è·¯ç”±å™¨
    
    æ ¸å¿ƒå¢å¼ºåŠŸèƒ½ï¼š
    1. åŠ¨æ€æƒé‡è°ƒæ•´
    2. ç”¨æˆ·ç”»åƒæ„ŸçŸ¥
    3. ä¸Šä¸‹æ–‡è¿ç»­æ€§
    4. æˆæœ¬é¢„ç®—æ§åˆ¶
    5. å†³ç­–å®¡è®¡æ—¥å¿—
    6. åé¦ˆå­¦ä¹ å¾ªç¯
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–å¢å¼ºè·¯ç”±å™¨"""
        self.config = config or {}
        
        # åŸºç¡€æƒé‡é…ç½®ï¼ˆå¯åŠ¨æ€è°ƒæ•´ï¼‰
        self.base_weights = {
            'domain_match': 0.40,
            'complexity_match': 0.25,
            'special_requirements': 0.20,
            'cost_efficiency': 0.10,
            'response_speed': 0.05
        }
        
        # ç”¨æˆ·è§’è‰²æƒé‡è°ƒæ•´
        self.role_weight_adjustments = {
            UserRole.BEGINNER: {
                'domain_match': 0.45,      # æ›´é‡è§†é¢†åŸŸåŒ¹é…
                'complexity_match': 0.15,  # é™ä½å¤æ‚åº¦æƒé‡
                'cost_efficiency': 0.20,   # æ›´åœ¨æ„æˆæœ¬
                'response_speed': 0.15     # æ›´åœ¨æ„é€Ÿåº¦
            },
            UserRole.EXPERT: {
                'domain_match': 0.35,      # ç¨é™é¢†åŸŸåŒ¹é…
                'complexity_match': 0.35,  # å¤§å¹…æå‡å¤æ‚åº¦æƒé‡
                'special_requirements': 0.25,  # æ›´é‡è§†ç‰¹æ®Šéœ€æ±‚
                'cost_efficiency': 0.05    # ä¸å¤ªåœ¨æ„æˆæœ¬
            },
            UserRole.RESEARCHER: {
                'domain_match': 0.30,
                'complexity_match': 0.30,
                'special_requirements': 0.30,  # æœ€é‡è§†ç‰¹æ®Šéœ€æ±‚
                'cost_efficiency': 0.05,
                'response_speed': 0.05
            }
        }
        
        # ä¸Šä¸‹æ–‡ç±»å‹æƒé‡è°ƒæ•´
        self.context_weight_adjustments = {
            ContextType.FOLLOW_UP: {
                'consistency_bonus': 0.3  # ä¸ä¹‹å‰å†³ç­–ä¿æŒä¸€è‡´çš„å¥–åŠ±
            },
            ContextType.DEEP_DIVE: {
                'domain_match': 0.50,     # æ›´é‡è§†é¢†åŸŸåŒ¹é…
                'consistency_bonus': 0.2
            },
            ContextType.TROUBLESHOOTING: {
                'special_requirements': 0.30,  # æ›´é‡è§†ç²¾ç¡®æ€§
                'response_speed': 0.15     # æ›´åœ¨æ„é€Ÿåº¦
            }
        }
        
        # æˆæœ¬æ§åˆ¶é…ç½®
        self.cost_budget = {
            'daily_limit': 10.0,    # æ¯æ—¥é¢„ç®—
            'monthly_limit': 200.0, # æ¯æœˆé¢„ç®—
            'emergency_threshold': 0.9  # ç´§æ€¥é˜ˆå€¼
        }
        
        # çŸ¥è¯†æºèƒ½åŠ›ï¼ˆç»§æ‰¿åŸºç¡€é…ç½®ï¼‰
        self.source_capabilities = self._load_source_capabilities()
        
        # å†³ç­–æ—¥å¿—å­˜å‚¨
        self.audit_logs: List[DecisionAuditLog] = []
        self.audit_log_file = Path("logs/routing_decisions.jsonl")
        self.audit_log_file.parent.mkdir(exist_ok=True)
        
        # åé¦ˆå­¦ä¹ æ•°æ®
        self.feedback_data: List[RoutingFeedback] = []
        self.learned_weights = self.base_weights.copy()
        
        # é™çº§ç­–ç•¥é…ç½®
        self.fallback_strategies = self._init_fallback_strategies()
        
        logger.info("ğŸ§  å¢å¼ºç‰ˆçŸ¥è¯†è·¯ç”±å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def route_query(
        self, 
        query: str, 
        user_profile: Optional[UserProfile] = None,
        context: Optional[ConversationContext] = None
    ) -> KnowledgeSourceDecision:
        """å¢å¼ºç‰ˆæŸ¥è¯¢è·¯ç”±"""
        
        start_time = datetime.now()
        log_id = self._generate_log_id(query)
        
        try:
            # 1. æŸ¥è¯¢åˆ†æï¼ˆå¢å¼ºç‰ˆï¼‰
            analysis = await self._enhanced_query_analysis(query, user_profile, context)
            
            # 2. åŠ¨æ€æƒé‡è®¡ç®—
            weights = await self._calculate_dynamic_weights(user_profile, context, analysis)
            
            # 3. æˆæœ¬é¢„ç®—æ£€æŸ¥
            await self._check_cost_budget(user_profile, context)
            
            # 4. çŸ¥è¯†æºè¯„ä¼°ï¼ˆè€ƒè™‘ä¸Šä¸‹æ–‡ï¼‰
            source_scores = await self._enhanced_source_evaluation(
                analysis, weights, user_profile, context
            )
            
            # 5. æ™ºèƒ½å†³ç­–ï¼ˆå¸¦é™çº§ç­–ç•¥ï¼‰
            decision = await self._make_enhanced_decision(
                analysis, source_scores, user_profile, context
            )
            
            # 6. è®°å½•å®¡è®¡æ—¥å¿—
            await self._log_decision(
                log_id, query, analysis, source_scores, decision,
                user_profile, context, start_time, True
            )
            
            return decision
            
        except Exception as e:
            # é”™è¯¯å¤„ç†å’Œé™çº§
            logger.error(f"âŒ è·¯ç”±å†³ç­–å¤±è´¥: {e}")
            
            fallback_decision = await self._execute_fallback_strategy(
                query, user_profile, context, str(e)
            )
            
            await self._log_decision(
                log_id, query, None, {}, fallback_decision,
                user_profile, context, start_time, False, str(e)
            )
            
            return fallback_decision
    
    async def _enhanced_query_analysis(
        self, 
        query: str, 
        user_profile: Optional[UserProfile],
        context: Optional[ConversationContext]
    ) -> QueryAnalysis:
        """å¢å¼ºç‰ˆæŸ¥è¯¢åˆ†æ"""
        
        # åŸºç¡€åˆ†æ
        analysis = await self._basic_query_analysis(query)
        
        # ç”¨æˆ·ç”»åƒå¢å¼º
        if user_profile:
            analysis = await self._enhance_with_user_profile(analysis, user_profile)
        
        # ä¸Šä¸‹æ–‡å¢å¼º
        if context:
            analysis = await self._enhance_with_context(analysis, context)
        
        return analysis
    
    async def _calculate_dynamic_weights(
        self,
        user_profile: Optional[UserProfile],
        context: Optional[ConversationContext],
        analysis: QueryAnalysis
    ) -> Dict[str, float]:
        """è®¡ç®—åŠ¨æ€æƒé‡"""
        
        weights = self.learned_weights.copy()
        
        # ç”¨æˆ·è§’è‰²è°ƒæ•´
        if user_profile and user_profile.role in self.role_weight_adjustments:
            role_adj = self.role_weight_adjustments[user_profile.role]
            for key, adjustment in role_adj.items():
                if key in weights:
                    weights[key] = adjustment
        
        # ä¸Šä¸‹æ–‡ç±»å‹è°ƒæ•´
        if context and context.context_type in self.context_weight_adjustments:
            ctx_adj = self.context_weight_adjustments[context.context_type]
            for key, adjustment in ctx_adj.items():
                if key in weights:
                    weights[key] = adjustment
        
        # æˆæœ¬æ•æ„Ÿåº¦è°ƒæ•´
        if user_profile and user_profile.cost_sensitivity > 0.7:
            weights['cost_efficiency'] *= 1.5
            weights['domain_match'] *= 0.9
        
        # é€Ÿåº¦åå¥½è°ƒæ•´
        if user_profile and user_profile.speed_preference > 0.7:
            weights['response_speed'] *= 2.0
            weights['complexity_match'] *= 0.8
        
        # å½’ä¸€åŒ–æƒé‡
        total = sum(weights.values())
        return {k: v/total for k, v in weights.items()}
    
    async def _enhanced_source_evaluation(
        self,
        analysis: QueryAnalysis,
        weights: Dict[str, float],
        user_profile: Optional[UserProfile],
        context: Optional[ConversationContext]
    ) -> Dict[KnowledgeSourceType, float]:
        """å¢å¼ºç‰ˆçŸ¥è¯†æºè¯„ä¼°"""
        
        scores = {}
        
        for source_type, capability in self.source_capabilities.items():
            score = 0.0
            
            # åŸºç¡€è¯„åˆ†
            score += self._calculate_domain_match(analysis, capability) * weights.get('domain_match', 0.4)
            score += self._calculate_complexity_match(analysis, capability) * weights.get('complexity_match', 0.25)
            score += self._calculate_special_match(analysis, capability) * weights.get('special_requirements', 0.2)
            score += self._calculate_cost_efficiency(capability) * weights.get('cost_efficiency', 0.1)
            score += self._calculate_speed_score(capability) * weights.get('response_speed', 0.05)
            
            # ä¸Šä¸‹æ–‡è¿ç»­æ€§å¥–åŠ±
            if context and context.previous_decisions:
                consistency_bonus = self._calculate_consistency_bonus(
                    source_type, context.previous_decisions
                )
                score += consistency_bonus * weights.get('consistency_bonus', 0.0)
            
            # ç”¨æˆ·å†å²åå¥½
            if user_profile:
                preference_bonus = self._calculate_preference_bonus(
                    source_type, user_profile
                )
                score += preference_bonus * 0.1
            
            scores[source_type] = max(0.0, min(1.0, score))
        
        return scores
    
    async def _make_enhanced_decision(
        self,
        analysis: QueryAnalysis,
        scores: Dict[KnowledgeSourceType, float],
        user_profile: Optional[UserProfile],
        context: Optional[ConversationContext]
    ) -> KnowledgeSourceDecision:
        """å¢å¼ºç‰ˆå†³ç­–åˆ¶å®š"""
        
        # æ’åºå¾—åˆ†
        sorted_sources = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        # æ£€æŸ¥ç½®ä¿¡åº¦å·®å¼‚
        if len(sorted_sources) >= 2:
            top_score = sorted_sources[0][1]
            second_score = sorted_sources[1][1]
            confidence_delta = top_score - second_score
            
            # å¦‚æœå·®å¼‚å¾ˆå°ï¼Œè€ƒè™‘èåˆç­–ç•¥
            if confidence_delta < 0.15 and self._should_use_fusion(user_profile):
                return await self._create_fusion_decision(
                    analysis, sorted_sources[:2], user_profile, context
                )
        
        # å¸¸è§„å•æºå†³ç­–
        primary_source = sorted_sources[0][0]
        primary_score = sorted_sources[0][1]
        
        # é€‰æ‹©è¾…åŠ©æº
        secondary_sources = [
            source for source, score in sorted_sources[1:3] 
            if score > 0.6
        ]
        
        # ç”Ÿæˆæ¨ç†
        reasoning = self._generate_enhanced_reasoning(
            analysis, primary_source, primary_score, user_profile, context
        )
        
        # ä¼°ç®—æˆæœ¬å’Œå»¶è¿Ÿ
        capability = self.source_capabilities[primary_source]
        estimated_cost = capability.cost_per_query
        expected_latency = capability.avg_latency
        
        # åº”ç”¨ç”¨æˆ·åå¥½è°ƒæ•´
        if user_profile:
            if user_profile.speed_preference > 0.8:
                expected_latency *= 0.8  # ä¼˜åŒ–å»¶è¿Ÿ
            if user_profile.cost_sensitivity > 0.8:
                estimated_cost *= 0.9   # æˆæœ¬ä¼˜åŒ–
        
        return KnowledgeSourceDecision(
            primary_source=primary_source,
            secondary_sources=secondary_sources,
            reasoning=reasoning,
            confidence=primary_score,
            estimated_cost=estimated_cost,
            expected_latency=expected_latency
        )
    
    async def add_feedback(self, feedback: RoutingFeedback):
        """æ·»åŠ ç”¨æˆ·åé¦ˆ"""
        self.feedback_data.append(feedback)
        
        # è§¦å‘å­¦ä¹ æ›´æ–°
        if len(self.feedback_data) % 10 == 0:  # æ¯10ä¸ªåé¦ˆå­¦ä¹ ä¸€æ¬¡
            await self._update_learned_weights()
        
        logger.info(f"ğŸ“ æ”¶åˆ°åé¦ˆ: {feedback.feedback_type.value}")
    
    async def _update_learned_weights(self):
        """åŸºäºåé¦ˆæ›´æ–°å­¦ä¹ æƒé‡"""
        
        # ç®€å•çš„åé¦ˆå­¦ä¹ ç®—æ³•
        positive_feedback = [f for f in self.feedback_data[-50:] 
                           if f.feedback_type == FeedbackType.THUMBS_UP]
        negative_feedback = [f for f in self.feedback_data[-50:] 
                           if f.feedback_type == FeedbackType.THUMBS_DOWN]
        
        if len(positive_feedback) + len(negative_feedback) < 10:
            return
        
        # è®¡ç®—åé¦ˆæ¯”ä¾‹
        success_rate = len(positive_feedback) / (len(positive_feedback) + len(negative_feedback))
        
        # æ ¹æ®æˆåŠŸç‡è°ƒæ•´æƒé‡
        if success_rate < 0.7:  # å¦‚æœæˆåŠŸç‡ä½äº70%
            # å¢åŠ ä¿å®ˆç­–ç•¥çš„æƒé‡
            self.learned_weights['cost_efficiency'] *= 1.1
            self.learned_weights['domain_match'] *= 1.1
            self.learned_weights['complexity_match'] *= 0.9
        elif success_rate > 0.9:  # å¦‚æœæˆåŠŸç‡é«˜äº90%
            # å¯ä»¥æ›´æ¿€è¿›ä¸€äº›
            self.learned_weights['complexity_match'] *= 1.1
            self.learned_weights['special_requirements'] *= 1.1
        
        # é‡æ–°å½’ä¸€åŒ–
        total = sum(self.learned_weights.values())
        self.learned_weights = {k: v/total for k, v in self.learned_weights.items()}
        
        logger.info(f"ğŸ§  æƒé‡å­¦ä¹ æ›´æ–°å®Œæˆï¼ŒæˆåŠŸç‡: {success_rate:.2%}")
    
    async def _execute_fallback_strategy(
        self,
        query: str,
        user_profile: Optional[UserProfile],
        context: Optional[ConversationContext],
        error: str
    ) -> KnowledgeSourceDecision:
        """æ‰§è¡Œé™çº§ç­–ç•¥"""
        
        logger.warning(f"âš ï¸ æ‰§è¡Œé™çº§ç­–ç•¥ï¼ŒåŸå› : {error}")
        
        # é™çº§ç­–ç•¥1ï¼šå¦‚æœçŸ¥è¯†åº“ä¸å¯ç”¨ï¼Œä½¿ç”¨AIè®­ç»ƒæ•°æ®
        if "knowledge_base" in error.lower():
            return KnowledgeSourceDecision(
                primary_source=KnowledgeSourceType.AI_TRAINING_DATA,
                secondary_sources=[],
                reasoning=f"çŸ¥è¯†åº“ä¸å¯ç”¨ï¼Œé™çº§åˆ°AIè®­ç»ƒæ•°æ®ã€‚åŸå› : {error}",
                confidence=0.6,
                estimated_cost=1.0,
                expected_latency=2.0
            )
        
        # é™çº§ç­–ç•¥2ï¼šå¦‚æœç½‘ç»œæœç´¢å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°çŸ¥è¯†åº“
        elif "web_search" in error.lower():
            return KnowledgeSourceDecision(
                primary_source=KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE,
                secondary_sources=[KnowledgeSourceType.AI_TRAINING_DATA],
                reasoning=f"ç½‘ç»œæœç´¢å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°çŸ¥è¯†åº“ã€‚åŸå› : {error}",
                confidence=0.7,
                estimated_cost=0.1,
                expected_latency=0.2
            )
        
        # é»˜è®¤é™çº§ï¼šä½¿ç”¨æœ€ç¨³å®šçš„æœ¬åœ°çŸ¥è¯†åº“
        return KnowledgeSourceDecision(
            primary_source=KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE,
            secondary_sources=[],
            reasoning=f"ç³»ç»Ÿå¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤é™çº§ç­–ç•¥ã€‚åŸå› : {error}",
            confidence=0.5,
            estimated_cost=0.1,
            expected_latency=0.2
        )
    
    async def _log_decision(
        self,
        log_id: str,
        query: str,
        analysis: Optional[QueryAnalysis],
        source_scores: Dict[KnowledgeSourceType, float],
        decision: KnowledgeSourceDecision,
        user_profile: Optional[UserProfile],
        context: Optional[ConversationContext],
        start_time: datetime,
        success: bool,
        error_message: Optional[str] = None
    ):
        """è®°å½•å†³ç­–å®¡è®¡æ—¥å¿—"""
        
        execution_time = (datetime.now() - start_time).total_seconds() * 1000
        
        audit_log = DecisionAuditLog(
            log_id=log_id,
            timestamp=datetime.now(),
            user_id=user_profile.user_id if user_profile else "anonymous",
            query=query,
            query_analysis=analysis,
            all_source_scores=source_scores,
            final_decision=decision,
            router_type="EnhancedKnowledgeRouter",
            router_version="2.0.0",
            execution_time_ms=execution_time,
            context=context,
            user_profile=user_profile,
            success=success,
            error_message=error_message
        )
        
        self.audit_logs.append(audit_log)
        
        # å†™å…¥æ–‡ä»¶
        await self._write_audit_log(audit_log)
        
        logger.debug(f"ğŸ“Š å†³ç­–æ—¥å¿—å·²è®°å½•: {log_id}")
    
    def get_router_info(self) -> Dict[str, Any]:
        """è·å–è·¯ç”±å™¨ä¿¡æ¯"""
        return {
            "router_type": "EnhancedKnowledgeRouter",
            "version": "2.0.0",
            "features": [
                "dynamic_weights",
                "user_profiling", 
                "context_awareness",
                "feedback_learning",
                "decision_audit",
                "fallback_strategies"
            ],
            "base_weights": self.base_weights,
            "learned_weights": self.learned_weights,
            "total_decisions": len(self.audit_logs),
            "feedback_count": len(self.feedback_data),
            "supported_user_roles": [role.value for role in UserRole],
            "supported_context_types": [ctx.value for ctx in ContextType]
        }
    
    # è¾…åŠ©æ–¹æ³•å®ç°
    def _load_source_capabilities(self) -> Dict[KnowledgeSourceType, KnowledgeSourceCapability]:
        """åŠ è½½çŸ¥è¯†æºèƒ½åŠ›é…ç½®"""
        # è¿™é‡Œå¯ä»¥ä»é…ç½®æ–‡ä»¶æˆ–æ•°æ®åº“åŠ è½½
        # æš‚æ—¶è¿”å›åŸºç¡€é…ç½®
        from .knowledge_router import get_knowledge_router
        basic_router = get_knowledge_router()
        return basic_router.source_capabilities
    
    def _generate_log_id(self, query: str) -> str:
        """ç”Ÿæˆæ—¥å¿—ID"""
        content = f"{query}_{datetime.now().isoformat()}"
        return hashlib.md5(content.encode()).hexdigest()[:12]
    
    async def _basic_query_analysis(self, query: str) -> QueryAnalysis:
        """åŸºç¡€æŸ¥è¯¢åˆ†æ"""
        # å¤ç”¨åŸæœ‰çš„æŸ¥è¯¢åˆ†æé€»è¾‘
        from .knowledge_router import get_knowledge_router
        basic_router = get_knowledge_router()
        return await basic_router._analyze_query(query, {})
    
    # æ›´å¤šè¾…åŠ©æ–¹æ³•...
    async def _enhance_with_user_profile(self, analysis: QueryAnalysis, profile: UserProfile) -> QueryAnalysis:
        """åŸºäºç”¨æˆ·ç”»åƒå¢å¼ºåˆ†æ"""
        # æ ¹æ®ç”¨æˆ·è§’è‰²è°ƒæ•´å¤æ‚åº¦åˆ¤æ–­
        if profile.role == UserRole.EXPERT:
            if analysis.complexity == QueryComplexity.SIMPLE:
                analysis.complexity = QueryComplexity.MODERATE
        elif profile.role == UserRole.BEGINNER:
            if analysis.complexity == QueryComplexity.COMPLEX:
                analysis.complexity = QueryComplexity.MODERATE
        
        return analysis
    
    async def _enhance_with_context(self, analysis: QueryAnalysis, context: ConversationContext) -> QueryAnalysis:
        """åŸºäºå¯¹è¯ä¸Šä¸‹æ–‡å¢å¼ºåˆ†æ"""
        # å¦‚æœæ˜¯åç»­é—®é¢˜ï¼Œç»§æ‰¿ä¹‹å‰çš„é¢†åŸŸç„¦ç‚¹
        if context.context_type == ContextType.FOLLOW_UP and context.knowledge_domain_focus:
            analysis.domain = context.knowledge_domain_focus
        
        return analysis
    
    def _calculate_consistency_bonus(
        self, 
        source_type: KnowledgeSourceType, 
        previous_decisions: List[KnowledgeSourceDecision]
    ) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å¥–åŠ±"""
        if not previous_decisions:
            return 0.0
        
        # å¦‚æœæœ€è¿‘çš„å†³ç­–éƒ½æ˜¯åŒä¸€ä¸ªæºï¼Œç»™äºˆä¸€è‡´æ€§å¥–åŠ±
        recent_sources = [d.primary_source for d in previous_decisions[-3:]]
        if all(s == source_type for s in recent_sources):
            return 0.2
        
        return 0.0
    
    def _calculate_preference_bonus(
        self, 
        source_type: KnowledgeSourceType, 
        user_profile: UserProfile
    ) -> float:
        """è®¡ç®—ç”¨æˆ·åå¥½å¥–åŠ±"""
        # åŸºäºç”¨æˆ·å†å²äº¤äº’è®¡ç®—åå¥½
        if not user_profile.interaction_history:
            return 0.0
        
        # ç»Ÿè®¡ç”¨æˆ·å¯¹ä¸åŒæºçš„æ»¡æ„åº¦
        source_satisfaction = {}
        for interaction in user_profile.interaction_history[-20:]:  # æœ€è¿‘20æ¬¡äº¤äº’
            source = interaction.get('source')
            satisfaction = interaction.get('satisfaction', 0.5)
            if source:
                source_satisfaction[source] = source_satisfaction.get(source, []) + [satisfaction]
        
        if source_type.value in source_satisfaction:
            avg_satisfaction = sum(source_satisfaction[source_type.value]) / len(source_satisfaction[source_type.value])
            return (avg_satisfaction - 0.5) * 0.4  # è½¬æ¢ä¸º-0.2åˆ°0.2çš„å¥–åŠ±
        
        return 0.0
    
    async def _write_audit_log(self, audit_log: DecisionAuditLog):
        """å†™å…¥å®¡è®¡æ—¥å¿—åˆ°æ–‡ä»¶"""
        try:
            log_dict = {
                "log_id": audit_log.log_id,
                "timestamp": audit_log.timestamp.isoformat(),
                "user_id": audit_log.user_id,
                "query": audit_log.query,
                "decision": audit_log.final_decision.primary_source.value,
                "confidence": audit_log.final_decision.confidence,
                "execution_time_ms": audit_log.execution_time_ms,
                "success": audit_log.success,
                "error_message": audit_log.error_message
            }
            
            with open(self.audit_log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_dict, ensure_ascii=False) + '\n')
                
        except Exception as e:
            logger.error(f"âŒ å†™å…¥å®¡è®¡æ—¥å¿—å¤±è´¥: {e}")


# å…·ä½“è·¯ç”±å™¨å®ç°

class CostFirstRouter(AbstractRouter):
    """æˆæœ¬ä¼˜å…ˆè·¯ç”±å™¨"""
    
    async def route_query(
        self, 
        query: str, 
        user_profile: Optional[UserProfile] = None,
        context: Optional[ConversationContext] = None
    ) -> KnowledgeSourceDecision:
        """æ€»æ˜¯é€‰æ‹©æˆæœ¬æœ€ä½çš„çŸ¥è¯†æº"""
        
        return KnowledgeSourceDecision(
            primary_source=KnowledgeSourceType.LOCAL_KNOWLEDGE_BASE,
            secondary_sources=[],
            reasoning="æˆæœ¬ä¼˜å…ˆç­–ç•¥ï¼šé€‰æ‹©æœ¬åœ°çŸ¥è¯†åº“ï¼ˆæˆæœ¬æœ€ä½ï¼‰",
            confidence=0.8,
            estimated_cost=0.1,
            expected_latency=0.2
        )
    
    def get_router_info(self) -> Dict[str, Any]:
        return {
            "router_type": "CostFirstRouter",
            "version": "1.0.0",
            "strategy": "always_choose_lowest_cost"
        }


class MLBasedRouter(AbstractRouter):
    """åŸºäºæœºå™¨å­¦ä¹ çš„è·¯ç”±å™¨ï¼ˆå ä½ç¬¦ï¼‰"""
    
    def __init__(self):
        self.model = None  # è¿™é‡Œå¯ä»¥åŠ è½½é¢„è®­ç»ƒçš„åˆ†ç±»æ¨¡å‹
    
    async def route_query(
        self, 
        query: str, 
        user_profile: Optional[UserProfile] = None,
        context: Optional[ConversationContext] = None
    ) -> KnowledgeSourceDecision:
        """ä½¿ç”¨MLæ¨¡å‹è¿›è¡Œè·¯ç”±å†³ç­–"""
        
        # å ä½ç¬¦å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
        # features = self._extract_features(query, user_profile, context)
        # prediction = self.model.predict(features)
        
        return KnowledgeSourceDecision(
            primary_source=KnowledgeSourceType.AI_TRAINING_DATA,
            secondary_sources=[],
            reasoning="MLæ¨¡å‹é¢„æµ‹ç»“æœï¼ˆå ä½ç¬¦å®ç°ï¼‰",
            confidence=0.75,
            estimated_cost=1.0,
            expected_latency=2.0
        )
    
    def get_router_info(self) -> Dict[str, Any]:
        return {
            "router_type": "MLBasedRouter",
            "version": "1.0.0",
            "model_type": "placeholder",
            "features": ["query_embedding", "user_profile", "context_history"]
        }


# è·¯ç”±å™¨å·¥å‚
class RouterFactory:
    """è·¯ç”±å™¨å·¥å‚"""
    
    _routers = {
        "enhanced": EnhancedKnowledgeRouter,
        "cost_first": CostFirstRouter,
        "ml_based": MLBasedRouter
    }
    
    @classmethod
    def create_router(cls, router_type: str, config: Dict[str, Any] = None) -> AbstractRouter:
        """åˆ›å»ºæŒ‡å®šç±»å‹çš„è·¯ç”±å™¨"""
        
        if router_type not in cls._routers:
            raise ValueError(f"ä¸æ”¯æŒçš„è·¯ç”±å™¨ç±»å‹: {router_type}")
        
        router_class = cls._routers[router_type]
        
        if router_type == "enhanced":
            return router_class(config)
        else:
            return router_class()
    
    @classmethod
    def get_available_routers(cls) -> List[str]:
        """è·å–å¯ç”¨çš„è·¯ç”±å™¨ç±»å‹"""
        return list(cls._routers.keys())


# å…¨å±€å¢å¼ºè·¯ç”±å™¨å®ä¾‹
_enhanced_router_instance: Optional[EnhancedKnowledgeRouter] = None


def get_enhanced_router() -> EnhancedKnowledgeRouter:
    """è·å–å¢å¼ºè·¯ç”±å™¨å•ä¾‹"""
    global _enhanced_router_instance
    
    if _enhanced_router_instance is None:
        _enhanced_router_instance = EnhancedKnowledgeRouter()
    
    return _enhanced_router_instance 