"""
KnowledgeBasedAgentåŸºç±»
åŸºäºZeuså¹³å°çš„çŸ¥è¯†é©±åŠ¨Agentå¼€å‘åŸºç±»

æ ¸å¿ƒç†å¿µï¼š
- ç»§æ‰¿CognitiveAgentï¼Œæä¾›çŸ¥è¯†åº“é©±åŠ¨çš„å¼€å‘æ¨¡å¼
- 80%æ—¶é—´æ„å»ºçŸ¥è¯†åº“ï¼Œ20%æ—¶é—´å†™ä»£ç 
- é…ç½®é©±åŠ¨åˆå§‹åŒ–ï¼Œè£…é¥°å™¨èƒ½åŠ›æ³¨å…¥
- è‡ªåŠ¨RAGé›†æˆå’ŒçŸ¥è¯†ç®¡ç†
"""

import asyncio
import logging
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Callable, Type
from dataclasses import dataclass, field
from pathlib import Path
import yaml
import json
from datetime import datetime

from .cognitive_agent import CognitiveAgent, AgentIdentity
from ..intelligent_context.intelligent_context_layer import IntelligentContextLayer, RAGProcessingMode
from ..intelligent_context.vector_database_service import VectorDatabaseService
from ..intelligent_context.embedding_service import EmbeddingService
from ..framework.abstractions.context import UniversalContext
from ..framework.abstractions.task import UniversalTask, TaskType
from ..framework.abstractions.result import UniversalResult, ResultStatus, ErrorInfo
from ..infrastructure.llm.client_manager import llm_manager
from .self_learning_knowledge_manager import IntelligentKnowledgeEvolutionManager

logger = logging.getLogger(__name__)


@dataclass
class KnowledgeConfig:
    """çŸ¥è¯†åº“é…ç½®"""
    knowledge_base_path: str
    vector_db_collection: str = "agent_knowledge"
    embedding_model: str = "paraphrase-multilingual-MiniLM-L12-v2"
    retrieval_top_k: int = 5
    confidence_threshold: float = 0.7
    enable_semantic_cache: bool = True


@dataclass 
class AgentCapability:
    """Agentèƒ½åŠ›å®šä¹‰"""
    name: str
    description: str
    method_name: str
    enabled: bool = True
    confidence_threshold: float = 0.7
    knowledge_sources: List[str] = field(default_factory=list)
    require_llm: bool = True


@dataclass
class KnowledgeBasedAgentConfig:
    """çŸ¥è¯†é©±åŠ¨Agenté…ç½®"""
    agent_name: str
    agent_description: str
    knowledge_config: KnowledgeConfig
    capabilities: List[AgentCapability] = field(default_factory=list)
    llm_config: Dict[str, Any] = field(default_factory=dict)
    performance_tracking: bool = True


class CapabilityDecorator:
    """èƒ½åŠ›è£…é¥°å™¨å·¥å‚"""
    
    @staticmethod
    def capability(name: str, 
                  description: str,
                  knowledge_sources: List[str] = None,
                  confidence_threshold: float = 0.7,
                  require_llm: bool = True):
        """æ³¨å†Œèƒ½åŠ›è£…é¥°å™¨"""
        def decorator(func: Callable) -> Callable:
            # å°†èƒ½åŠ›ä¿¡æ¯é™„åŠ åˆ°å‡½æ•°
            func._capability_info = AgentCapability(
                name=name,
                description=description, 
                method_name=func.__name__,
                confidence_threshold=confidence_threshold,
                knowledge_sources=knowledge_sources or [],
                require_llm=require_llm
            )
            return func
        return decorator
    
    @staticmethod
    def knowledge_enhanced(sources: List[str] = None,
                          top_k: int = 5,
                          min_confidence: float = 0.7,
                          enable_learning: bool = True):
        """çŸ¥è¯†å¢å¼ºè£…é¥°å™¨ - æ”¯æŒè‡ªå­¦ä¹ """
        def decorator(func: Callable) -> Callable:
            async def wrapper(self, *args, **kwargs):
                query = kwargs.get('query', str(args[0]) if args else '')
                
                # è‡ªåŠ¨æ³¨å…¥ç›¸å…³çŸ¥è¯†
                if hasattr(self, '_inject_knowledge'):
                    knowledge = await self._inject_knowledge(
                        query=query,
                        sources=sources,
                        top_k=top_k,
                        min_confidence=min_confidence
                    )
                    kwargs['injected_knowledge'] = knowledge
                
                # æ‰§è¡ŒåŸå§‹æ–¹æ³•
                result = await func(self, *args, **kwargs)
                
                # è‡ªå­¦ä¹ å¤„ç†
                if (enable_learning and 
                    hasattr(self, 'knowledge_evolution_manager') and 
                    self.knowledge_evolution_manager and
                    hasattr(result, 'data') and 
                    result.data and
                    'answer' in result.data):
                    
                    # å¯åŠ¨çŸ¥è¯†æ¼”åŒ–æµç¨‹
                    try:
                        response_id = await self.knowledge_evolution_manager.process_llm_response(
                            query=query,
                            llm_response=result.data['answer'],
                            user_context=kwargs.get('context', {})
                        )
                        
                        # å°†response_idæ·»åŠ åˆ°ç»“æœä¸­ï¼Œä¾›åç»­åé¦ˆä½¿ç”¨
                        if not result.data:
                            result.data = {}
                        result.data['learning_response_id'] = response_id
                            
                    except Exception as e:
                        logger.warning(f"è‡ªå­¦ä¹ å¤„ç†å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                
                return result
            
            # ä¿ç•™åŸå‡½æ•°çš„å…ƒæ•°æ®
            wrapper.__name__ = func.__name__
            wrapper.__doc__ = func.__doc__
            return wrapper
        return decorator
    
    @staticmethod
    def context_aware(save_context: bool = True):
        """ä¸Šä¸‹æ–‡æ„ŸçŸ¥è£…é¥°å™¨"""
        def decorator(func: Callable) -> Callable:
            async def wrapper(self, *args, **kwargs):
                # æ³¨å…¥ä¸Šä¸‹æ–‡
                if hasattr(self, '_get_context'):
                    context = await self._get_context()
                    kwargs['context'] = context
                
                result = await func(self, *args, **kwargs)
                
                # ä¿å­˜ä¸Šä¸‹æ–‡
                if save_context and hasattr(self, '_save_context'):
                    await self._save_context(result)
                
                return result
            return wrapper
        return decorator


class KnowledgeBasedAgent(CognitiveAgent):
    """
    çŸ¥è¯†é©±åŠ¨AgentåŸºç±»
    
    æä¾›çŸ¥è¯†åº“é©±åŠ¨çš„Agentå¼€å‘æ¨¡å¼ï¼š
    1. é…ç½®é©±åŠ¨åˆå§‹åŒ–
    2. è‡ªåŠ¨çŸ¥è¯†åº“é›†æˆ
    3. è£…é¥°å™¨èƒ½åŠ›æ³¨å…¥
    4. æ™ºèƒ½RAGæ£€ç´¢
    """
    
    def __init__(self, config: KnowledgeBasedAgentConfig, llm_adapter=None):
        """åˆå§‹åŒ–çŸ¥è¯†é©±åŠ¨Agent"""
        
        # åˆå§‹åŒ–è®¤çŸ¥Agent
        identity = AgentIdentity(
            agent_id=f"knowledge_agent_{config.agent_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            name=config.agent_name,
            role=config.agent_description,
            description=f"åŸºäºçŸ¥è¯†é©±åŠ¨çš„{config.agent_description}",
            expertise_domains=["knowledge_retrieval", "rag_processing"]
        )
        super().__init__(identity=identity, config={"llm_adapter": llm_adapter})
        
        self.config = config
        self.capabilities: Dict[str, AgentCapability] = {}
        self.knowledge_stats = {
            "knowledge_base_size": 0,
            "retrieval_count": 0,
            "cache_hit_rate": 0.0,
            "avg_confidence": 0.0
        }
        
        # åˆå§‹åŒ–çŸ¥è¯†ç»„ä»¶
        self.vector_db = None
        self.embedding_service = None
        self.context_layer = None
        
        # åˆå§‹åŒ–è‡ªå­¦ä¹ ç»„ä»¶
        self.memory_system = None
        self.knowledge_evolution_manager = None
        self.integrated_knowledge_service = None
        
        logger.info(f"ğŸ§  åˆå§‹åŒ–çŸ¥è¯†é©±åŠ¨Agent: {config.agent_name}")
    
    async def initialize(self) -> UniversalResult:
        """åˆå§‹åŒ–Agentå’ŒçŸ¥è¯†ç³»ç»Ÿ"""
        try:
            # 1. åˆå§‹åŒ–å‘é‡æ•°æ®åº“
            self.vector_db = VectorDatabaseService(
                collection_name=self.config.knowledge_config.vector_db_collection
            )
            
            # 2. åˆå§‹åŒ–åµŒå…¥æœåŠ¡
            self.embedding_service = EmbeddingService()
            await self.embedding_service.initialize(
                model_name=self.config.knowledge_config.embedding_model
            )
            
            # 3. åˆå§‹åŒ–æ™ºèƒ½ä¸Šä¸‹æ–‡å±‚
            self.context_layer = IntelligentContextLayer()
            
            # 4. åˆå§‹åŒ–é›†æˆçŸ¥è¯†æœåŠ¡
            from ..intelligent_context.integrated_knowledge_service import IntegratedKnowledgeService
            self.integrated_knowledge_service = IntegratedKnowledgeService(
                vector_db_config={"collection_name": self.config.knowledge_config.vector_db_collection},
                embedding_config=None
            )
            
            # 5. åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
            from .memory import MemorySystem
            memory_config = {
                "working": {"capacity": 7, "decay_time": 300},
                "episodic": {},
                "semantic": {},
                "procedural": {},
                "persistence": {
                    "database_path": "memory_database.db",
                    "persistence_mode": "batch",
                    "batch_size": 50
                }
            }
            self.memory_system = MemorySystem(memory_config)
            await self.memory_system.initialize()
            
            # 6. åˆå§‹åŒ–è‡ªå­¦ä¹ çŸ¥è¯†æ¼”åŒ–ç®¡ç†å™¨
            evolution_config = {
                "quality": {
                    "high_quality_threshold": 0.8,
                    "medium_quality_threshold": 0.6
                },
                "consolidation_interval": 1800,  # 30åˆ†é’Ÿ
                "crystallization_interval": 3600  # 1å°æ—¶
            }
            self.knowledge_evolution_manager = IntelligentKnowledgeEvolutionManager(
                memory_system=self.memory_system,
                knowledge_service=self.integrated_knowledge_service,
                config=evolution_config
            )
            
            # 7. åŠ è½½çŸ¥è¯†åº“
            await self._load_knowledge_base()
            
            # 8. å‘ç°å’Œæ³¨å†Œèƒ½åŠ›
            self._discover_capabilities()
            
            # 9. åˆå§‹åŒ–LLMç®¡ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if any(cap.require_llm for cap in self.capabilities.values()):
                await self._initialize_llm()
            
            logger.info(f"âœ… {self.config.agent_name} åˆå§‹åŒ–å®Œæˆ")
            logger.info(f"ğŸ“š çŸ¥è¯†åº“å¤§å°: {self.knowledge_stats['knowledge_base_size']}")
            logger.info(f"ğŸ¯ æ³¨å†Œèƒ½åŠ›: {list(self.capabilities.keys())}")
            
            return UniversalResult(
                data={"initialized_capabilities": list(self.capabilities.keys())},
                status=ResultStatus.SUCCESS,
                content="çŸ¥è¯†é©±åŠ¨Agentåˆå§‹åŒ–æˆåŠŸ"
            )
            
        except Exception as e:
            logger.error(f"âŒ Agentåˆå§‹åŒ–å¤±è´¥: {e}")
            return UniversalResult(
                content="Agentåˆå§‹åŒ–å¤±è´¥",
                status=ResultStatus.FAILURE,
                error=ErrorInfo(
                    error_type="initialization_error",
                    error_message=str(e)
                )
            )
    
    async def _load_knowledge_base(self):
        """åŠ è½½çŸ¥è¯†åº“åˆ°å‘é‡æ•°æ®åº“"""
        knowledge_path = Path(self.config.knowledge_config.knowledge_base_path)
        
        if not knowledge_path.exists():
            logger.warning(f"çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨: {knowledge_path}")
            return
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²åŠ è½½
            current_count = self.vector_db.collection.count()
            if current_count > 0:
                logger.info(f"çŸ¥è¯†åº“å·²å­˜åœ¨ {current_count} ä¸ªæ–‡æ¡£ï¼Œè·³è¿‡åŠ è½½")
                self.knowledge_stats["knowledge_base_size"] = current_count
                return
            
            # åŠ è½½JSONæ ¼å¼çŸ¥è¯†åº“
            with open(knowledge_path, 'r', encoding='utf-8') as f:
                knowledge_data = json.load(f)
            
            documents = []
            metadata_list = []
            
            # å¤„ç†ä¸åŒæ ¼å¼çš„çŸ¥è¯†åº“
            if isinstance(knowledge_data, dict):
                if "documents" in knowledge_data:
                    # æ ‡å‡†æ ¼å¼
                    for doc in knowledge_data["documents"]:
                        content = doc.get("content", "")
                        if content:
                            documents.append(content)
                            metadata_list.append({
                                "source": doc.get("source", "unknown"),
                                "category": doc.get("category", "general"),
                                "title": doc.get("title", "")
                            })
                elif "knowledge_items" in knowledge_data:
                    # FPGAçŸ¥è¯†åº“æ ¼å¼
                    for item in knowledge_data["knowledge_items"]:
                        title = item.get("title", "")
                        if "chunks" in item:
                            for chunk in item["chunks"]:
                                content = chunk.get("content", "")
                                if content:
                                    documents.append(content)
                                    # ChromaDB metadataåªæ”¯æŒåŸºæœ¬ç±»å‹ï¼Œå°†åˆ—è¡¨è½¬ä¸ºå­—ç¬¦ä¸²
                                    tags = item.get("tags", [])
                                    metadata_list.append({
                                        "source": item.get("domain", "unknown"),
                                        "category": item.get("knowledge_type", "general"),
                                        "title": title,
                                        "chunk_id": chunk.get("chunk_id", ""),
                                        "tags": ",".join(tags) if tags else ""
                            })
                else:
                    # ç›´æ¥é”®å€¼å¯¹æ ¼å¼
                    for key, value in knowledge_data.items():
                        if isinstance(value, str):
                            documents.append(value)
                            metadata_list.append({
                                "source": "knowledge_base",
                                "category": key,
                                "title": key
                            })
            
            if documents:
                # æ‰¹é‡ç”ŸæˆåµŒå…¥
                embeddings = await self.embedding_service.embed_texts(documents)
                
                # å‡†å¤‡VectorDocumentå¯¹è±¡
                from layers.intelligent_context.vector_database_service import VectorDocument
                import uuid
                
                vector_docs = []
                for i, (content, metadata, emb) in enumerate(zip(documents, metadata_list, embeddings)):
                    vector_docs.append(VectorDocument(
                        id=str(uuid.uuid4()),
                        content=content,
                        embedding=emb.embedding,
                        metadata=metadata
                    ))
                
                # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
                await self.vector_db.add_documents(vector_docs)
                
                self.knowledge_stats["knowledge_base_size"] = len(documents)
                logger.info(f"âœ… å·²åŠ è½½ {len(documents)} ä¸ªçŸ¥è¯†æ–‡æ¡£")
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}")
    
    def _discover_capabilities(self):
        """å‘ç°å’Œæ³¨å†ŒAgentèƒ½åŠ›"""
        # é€šè¿‡åå°„å‘ç°å¸¦æœ‰_capability_infoçš„æ–¹æ³•
        for attr_name in dir(self):
            attr = getattr(self, attr_name)
            if hasattr(attr, '_capability_info'):
                capability = attr._capability_info
                self.capabilities[capability.name] = capability
                logger.info(f"ğŸ¯ å‘ç°èƒ½åŠ›: {capability.name}")
        
        # ä»é…ç½®ä¸­æ·»åŠ é¢å¤–èƒ½åŠ›
        for cap in self.config.capabilities:
            if cap.name not in self.capabilities:
                self.capabilities[cap.name] = cap
                logger.info(f"ğŸ“‹ é…ç½®èƒ½åŠ›: {cap.name}")
    
    async def _initialize_llm(self):
        """åˆå§‹åŒ–LLMç®¡ç†å™¨"""
        try:
            # å¦‚æœllm_manageræœªåˆå§‹åŒ–ï¼Œåˆ™åˆå§‹åŒ–
            if not hasattr(llm_manager, 'providers') or not llm_manager.providers:
                from ..infrastructure.llm import initialize_llm_manager
                await initialize_llm_manager()
                
            logger.info("âœ… LLMç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ LLMåˆå§‹åŒ–å¤±è´¥: {e}")
    
    async def _inject_knowledge(self, 
                              query: str,
                              sources: List[str] = None,
                              top_k: int = 5,
                              min_confidence: float = 0.7) -> List[Dict[str, Any]]:
        """æ³¨å…¥ç›¸å…³çŸ¥è¯†"""
        try:
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            query_embedding = await self.embedding_service.embed_text(query)
            
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            filter_condition = None
            if sources:
                if isinstance(sources, list) and len(sources) == 1:
                    filter_condition = {"source": sources[0]}
                elif isinstance(sources, list):
                    filter_condition = {"source": {"$in": sources}}
                else:
                    filter_condition = {"source": sources}
            
            results = await self.vector_db.search(
                query=query,
                query_embedding=query_embedding.embedding,
                top_k=top_k,
                filters=filter_condition
            )
            
            logger.debug(f"ğŸ” åŸå§‹æœç´¢ç»“æœæ•°é‡: {len(results)}")
            if results:
                scores = [r.score for r in results]
                logger.debug(f"ğŸ” ç›¸ä¼¼åº¦åˆ†æ•°èŒƒå›´: {min(scores):.3f} - {max(scores):.3f}, é˜ˆå€¼: {min_confidence}")
            
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
            filtered_results = [
                {
                    "content": result.document.content,
                    "metadata": result.document.metadata,
                    "confidence": result.score
                }
                for result in results
                if result.score >= min_confidence
            ]
            
            self.knowledge_stats["retrieval_count"] += 1
            if filtered_results:
                avg_conf = sum(r["confidence"] for r in filtered_results) / len(filtered_results)
                self.knowledge_stats["avg_confidence"] = avg_conf
            
            logger.debug(f"ğŸ” ä¸ºæŸ¥è¯¢ '{query}' æ£€ç´¢åˆ° {len(filtered_results)} ä¸ªç›¸å…³çŸ¥è¯†")
            return filtered_results
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†æ³¨å…¥å¤±è´¥: {e}")
            return []
    
    async def _get_context(self) -> Dict[str, Any]:
        """è·å–å½“å‰ä¸Šä¸‹æ–‡"""
        return {
            "agent_name": self.config.agent_name,
            "timestamp": datetime.now().isoformat(),
            "knowledge_stats": self.knowledge_stats,
            "available_capabilities": list(self.capabilities.keys())
        }
    
    async def _save_context(self, result: Any):
        """ä¿å­˜æ‰§è¡Œç»“æœåˆ°ä¸Šä¸‹æ–‡"""
        # è¿™é‡Œå¯ä»¥å®ç°ä¸Šä¸‹æ–‡ä¿å­˜é€»è¾‘
        pass
    
    async def route_capability(self, query: str, **kwargs) -> UniversalResult:
        """æ™ºèƒ½è·¯ç”±åˆ°åˆé€‚çš„èƒ½åŠ›"""
        try:
            # ç®€å•çš„å…³é”®è¯åŒ¹é…è·¯ç”±ï¼ˆåç»­å¯ä»¥æ”¹è¿›ä¸ºLLMè·¯ç”±ï¼‰
            best_capability = None
            best_score = 0.0
            
            query_lower = query.lower()
            
            for cap_name, capability in self.capabilities.items():
                if not capability.enabled:
                    continue
                    
                # åŸºäºæè¿°çš„å…³é”®è¯åŒ¹é…ï¼ˆæ™ºèƒ½åˆ†è¯ï¼‰
                desc_lower = capability.description.lower()
                
                # ç®€å•æœ‰æ•ˆçš„å…³é”®è¯åŒ¹é…ï¼šç›´æ¥æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨æ–‡æœ¬ä¸­
                import re
                
                # æå–è‹±æ–‡å…³é”®è¯
                desc_en_words = re.findall(r'[a-zA-Z]+', desc_lower)
                query_en_words = re.findall(r'[a-zA-Z]+', query_lower)
                
                # è®¡ç®—åŒ¹é…åˆ†æ•°
                score = 0
                
                # è‹±æ–‡å…³é”®è¯åŒ¹é…
                for word in query_en_words:
                    if word in desc_lower:
                        score += 2  # è‹±æ–‡åŒ¹é…æƒé‡é«˜
                
                for word in desc_en_words:
                    if word in query_lower:
                        score += 2
                
                # ä¸­æ–‡å…³é”®è¯åŒ¹é…ï¼ˆå¸¸è§æŠ€æœ¯è¯æ±‡ï¼‰
                cn_keywords = ['è®¾è®¡', 'ç¼–ç¨‹', 'è¯­æ³•', 'åˆ†æ', 'çº¦æŸ', 'æ—¶åº']
                for keyword in cn_keywords:
                    if keyword in query_lower and keyword in desc_lower:
                        score += 1
                
                # è°ƒè¯•ä¿¡æ¯
                logger.info(f"ğŸ” èƒ½åŠ›åŒ¹é…: {cap_name}")
                logger.info(f"   æŸ¥è¯¢: '{query}' -> è‹±æ–‡è¯: {query_en_words}")
                logger.info(f"   æè¿°: '{capability.description}' -> è‹±æ–‡è¯: {desc_en_words}")
                logger.info(f"   æœ€ç»ˆåˆ†æ•°: {score}")
                
                if score > best_score:
                    best_score = score
                    best_capability = capability
            
            if best_capability and best_score > 0:
                # è°ƒç”¨å¯¹åº”çš„æ–¹æ³•
                method = getattr(self, best_capability.method_name, None)
                if method:
                    logger.info(f"ğŸ¯ è·¯ç”±åˆ°èƒ½åŠ›: {best_capability.name}")
                    return await method(query, **kwargs)
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…çš„èƒ½åŠ›ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†
            return await self.default_capability_handler(query, **kwargs)
            
        except Exception as e:
            logger.error(f"âŒ èƒ½åŠ›è·¯ç”±å¤±è´¥: {e}")
            return UniversalResult(
                content="èƒ½åŠ›è·¯ç”±å¤±è´¥",
                status=ResultStatus.FAILURE,
                error=ErrorInfo(
                    error_type="routing_error",
                    error_message=str(e)
                )
            )
    
    @abstractmethod
    async def default_capability_handler(self, query: str, **kwargs) -> UniversalResult:
        """é»˜è®¤èƒ½åŠ›å¤„ç†å™¨ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰"""
        pass
    
    async def provide_feedback(self, response_id: str, feedback: Dict[str, Any]) -> UniversalResult:
        """æä¾›ç”¨æˆ·åé¦ˆï¼Œæ¨è¿›çŸ¥è¯†æ¼”åŒ–"""
        if not self.knowledge_evolution_manager:
            return UniversalResult(
                content="è‡ªå­¦ä¹ åŠŸèƒ½æœªå¯ç”¨",
                status=ResultStatus.FAILURE,
                error=ErrorInfo(
                    error_type="learning_not_enabled",
                    error_message="Knowledge evolution manager not initialized"
                )
            )
        
        return await self.knowledge_evolution_manager.collect_user_feedback(response_id, feedback)
    
    def get_learning_stats(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡"""
        if not self.knowledge_evolution_manager:
            return {"learning_enabled": False}
        
        return {
            "learning_enabled": True,
            **self.knowledge_evolution_manager.get_evolution_metrics()
        }
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = {
            "knowledge_stats": self.knowledge_stats,
            "capabilities_count": len(self.capabilities),
            "enabled_capabilities": len([c for c in self.capabilities.values() if c.enabled]),
            "llm_required_capabilities": len([c for c in self.capabilities.values() if c.require_llm])
        }
        
        # æ·»åŠ å­¦ä¹ ç»Ÿè®¡
        stats.update(self.get_learning_stats())
        
        return stats


# å¯¼å‡ºè£…é¥°å™¨åˆ°æ¨¡å—çº§åˆ«
capability = CapabilityDecorator.capability
knowledge_enhanced = CapabilityDecorator.knowledge_enhanced  
context_aware = CapabilityDecorator.context_aware 