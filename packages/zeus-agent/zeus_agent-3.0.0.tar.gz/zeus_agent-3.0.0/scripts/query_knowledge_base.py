#!/usr/bin/env python3
"""
çŸ¥è¯†åº“æŸ¥è¯¢å·¥å…·
æ¼”ç¤ºå¦‚ä½•æŸ¥è¯¢å’Œä½¿ç”¨æ„å»ºçš„çŸ¥è¯†åº“
"""

import json
import argparse
from pathlib import Path
from typing import List, Dict, Any
import re


class KnowledgeBaseQuery:
    """çŸ¥è¯†åº“æŸ¥è¯¢å™¨"""
    
    def __init__(self, knowledge_base_path: str):
        self.kb_path = Path(knowledge_base_path)
        self.knowledge_data = self._load_knowledge_base()
        self.knowledge_items = self.knowledge_data.get('knowledge_items', [])
    
    def _load_knowledge_base(self) -> Dict[str, Any]:
        """åŠ è½½çŸ¥è¯†åº“"""
        if not self.kb_path.exists():
            raise FileNotFoundError(f"çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.kb_path}")
        
        with open(self.kb_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        # å…¼å®¹ä¸¤ç§æ ¼å¼çš„çŸ¥è¯†åº“
        metadata = self.knowledge_data.get('metadata', {})
        statistics = self.knowledge_data.get('statistics', {})
        
        # å¦‚æœæ²¡æœ‰statisticså­—æ®µï¼Œä»metadataä¸­è·å–ä¿¡æ¯
        if not statistics and metadata:
            statistics = {
                'total_items': metadata.get('total_items', len(self.knowledge_items)),
                'total_chunks': sum(len(item.get('chunks', [])) for item in self.knowledge_items),
                'processed_files': len(self.knowledge_items),  # ä¼°ç®—å€¼
                'total_files': len(self.knowledge_items)  # ä¼°ç®—å€¼
            }
        
        return {
            'metadata': metadata,
            'statistics': statistics,
            'total_items': len(self.knowledge_items)
        }
    
    def search_by_keyword(self, keyword: str, limit: int = 5) -> List[Dict[str, Any]]:
        """æŒ‰å…³é”®è¯æœç´¢"""
        keyword_lower = keyword.lower()
        results = []
        
        for item in self.knowledge_items:
            relevance_score = 0.0
            
            # æ ‡é¢˜åŒ¹é…
            if keyword_lower in item['title'].lower():
                relevance_score += 2.0
            
            # æ ‡ç­¾åŒ¹é…
            for tag in item.get('tags', []):
                if keyword_lower in tag.lower():
                    relevance_score += 1.0
            
            # å†…å®¹åŒ¹é…
            for chunk in item.get('chunks', []):
                if keyword_lower in chunk['content'].lower():
                    relevance_score += 0.5
                    break
            
            # å…³é”®è¯åŒ¹é…
            for chunk in item.get('chunks', []):
                for kw in chunk.get('keywords', []):
                    if keyword_lower in kw.lower():
                        relevance_score += 0.3
                        break
            
            if relevance_score > 0:
                results.append({
                    'item': item,
                    'relevance_score': relevance_score
                })
        
        # æŒ‰ç›¸å…³åº¦æ’åº
        results.sort(key=lambda x: x['relevance_score'], reverse=True)
        return results[:limit]
    
    def search_by_type(self, knowledge_type: str) -> List[Dict[str, Any]]:
        """æŒ‰çŸ¥è¯†ç±»å‹æœç´¢"""
        results = []
        for item in self.knowledge_items:
            if item.get('knowledge_type') == knowledge_type:
                results.append(item)
        return results
    
    def search_by_tag(self, tag: str) -> List[Dict[str, Any]]:
        """æŒ‰æ ‡ç­¾æœç´¢"""
        tag_lower = tag.lower()
        results = []
        for item in self.knowledge_items:
            for item_tag in item.get('tags', []):
                if tag_lower in item_tag.lower():
                    results.append(item)
                    break
        return results
    
    def get_item_by_id(self, item_id: str) -> Dict[str, Any]:
        """æ ¹æ®IDè·å–çŸ¥è¯†é¡¹"""
        for item in self.knowledge_items:
            if item.get('item_id') == item_id:
                return item
        return None
    
    def list_all_tags(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æ ‡ç­¾"""
        all_tags = set()
        for item in self.knowledge_items:
            all_tags.update(item.get('tags', []))
        return sorted(list(all_tags))
    
    def list_all_types(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†ç±»å‹"""
        all_types = set()
        for item in self.knowledge_items:
            all_types.add(item.get('knowledge_type'))
        return sorted(list(all_types))
    
    def get_chunk_content(self, item_id: str, chunk_id: str = None) -> str:
        """è·å–çŸ¥è¯†å—å†…å®¹"""
        item = self.get_item_by_id(item_id)
        if not item:
            return ""
        
        if chunk_id:
            for chunk in item.get('chunks', []):
                if chunk.get('chunk_id') == chunk_id:
                    return chunk.get('content', '')
            return ""
        else:
            # è¿”å›æ‰€æœ‰å—çš„å†…å®¹
            contents = []
            for chunk in item.get('chunks', []):
                contents.append(chunk.get('content', ''))
            return '\n\n'.join(contents)


def print_search_results(results: List[Dict[str, Any]], show_content: bool = False):
    """æ‰“å°æœç´¢ç»“æœ"""
    if not results:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ")
        return
    
    print(f"ğŸ” æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ:\n")
    
    for i, result in enumerate(results, 1):
        if 'item' in result:  # å…³é”®è¯æœç´¢ç»“æœ
            item = result['item']
            relevance = result['relevance_score']
            print(f"{i}. ğŸ“„ **{item['title']}** (ç›¸å…³åº¦: {relevance:.1f})")
        else:  # ç›´æ¥çš„itemç»“æœ
            item = result
            print(f"{i}. ğŸ“„ **{item['title']}**")
        
        print(f"   ç±»å‹: {item['knowledge_type']}")
        print(f"   æ ‡ç­¾: {', '.join(item.get('tags', []))}")
        print(f"   å—æ•°: {len(item.get('chunks', []))}")
        print(f"   æ¥æº: {item.get('source_file', 'Unknown')}")
        
        if show_content and item.get('chunks'):
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå—çš„æ‘˜è¦
            first_chunk = item['chunks'][0]
            summary = first_chunk.get('summary', '')
            if len(summary) > 200:
                summary = summary[:200] + "..."
            print(f"   æ‘˜è¦: {summary}")
        
        print()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="çŸ¥è¯†åº“æŸ¥è¯¢å·¥å…·")
    parser.add_argument("knowledge_base", help="çŸ¥è¯†åº“JSONæ–‡ä»¶è·¯å¾„")
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ç»Ÿè®¡ä¿¡æ¯å‘½ä»¤
    stats_parser = subparsers.add_parser('stats', help='æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯')
    
    # æœç´¢å‘½ä»¤
    search_parser = subparsers.add_parser('search', help='æœç´¢çŸ¥è¯†')
    search_parser.add_argument('keyword', help='æœç´¢å…³é”®è¯')
    search_parser.add_argument('--limit', '-l', type=int, default=5, help='ç»“æœæ•°é‡é™åˆ¶')
    search_parser.add_argument('--content', '-c', action='store_true', help='æ˜¾ç¤ºå†…å®¹æ‘˜è¦')
    
    # æŒ‰ç±»å‹æœç´¢å‘½ä»¤
    type_parser = subparsers.add_parser('type', help='æŒ‰ç±»å‹æœç´¢')
    type_parser.add_argument('knowledge_type', help='çŸ¥è¯†ç±»å‹')
    type_parser.add_argument('--content', '-c', action='store_true', help='æ˜¾ç¤ºå†…å®¹æ‘˜è¦')
    
    # æŒ‰æ ‡ç­¾æœç´¢å‘½ä»¤
    tag_parser = subparsers.add_parser('tag', help='æŒ‰æ ‡ç­¾æœç´¢')
    tag_parser.add_argument('tag_name', help='æ ‡ç­¾åç§°')
    tag_parser.add_argument('--content', '-c', action='store_true', help='æ˜¾ç¤ºå†…å®¹æ‘˜è¦')
    
    # åˆ—å‡ºæ ‡ç­¾å‘½ä»¤
    list_tags_parser = subparsers.add_parser('list-tags', help='åˆ—å‡ºæ‰€æœ‰æ ‡ç­¾')
    
    # åˆ—å‡ºç±»å‹å‘½ä»¤
    list_types_parser = subparsers.add_parser('list-types', help='åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†ç±»å‹')
    
    # æŸ¥çœ‹å†…å®¹å‘½ä»¤
    content_parser = subparsers.add_parser('content', help='æŸ¥çœ‹çŸ¥è¯†é¡¹å†…å®¹')
    content_parser.add_argument('item_id', help='çŸ¥è¯†é¡¹ID')
    content_parser.add_argument('--chunk', help='ç‰¹å®šå—ID')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæŸ¥è¯¢å™¨
        query = KnowledgeBaseQuery(args.knowledge_base)
        
        if args.command == 'stats':
            stats = query.get_stats()
            metadata = stats['metadata']
            statistics = stats['statistics']
            
            print("ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯")
            print("=" * 40)
            print(f"é¢†åŸŸ: {metadata.get('domain', 'Unknown')}")
            print(f"åˆ›å»ºæ—¶é—´: {metadata.get('created_time', 'Unknown')}")
            print(f"æ„å»ºå™¨ç‰ˆæœ¬: {metadata.get('builder_version', metadata.get('processor_version', 'Unknown'))}")
            print(f"çŸ¥è¯†é¡¹æ€»æ•°: {statistics.get('total_items', statistics.get('total_knowledge_items', len(query.knowledge_items)))}")
            print(f"çŸ¥è¯†å—æ€»æ•°: {statistics.get('total_chunks', sum(len(item.get('chunks', [])) for item in query.knowledge_items))}")
            print(f"å¤„ç†æ–‡æ¡£æ•°: {statistics.get('processed_files', statistics.get('successful_documents', 0))}")
            success_rate = statistics.get('successful_documents', 0) / max(statistics.get('total_documents', 1), 1) * 100
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")
            
        elif args.command == 'search':
            results = query.search_by_keyword(args.keyword, args.limit)
            print(f"ğŸ” æœç´¢å…³é”®è¯: '{args.keyword}'")
            print_search_results(results, args.content)
            
        elif args.command == 'type':
            results = query.search_by_type(args.knowledge_type)
            print(f"ğŸ“‚ çŸ¥è¯†ç±»å‹: '{args.knowledge_type}'")
            print_search_results(results, args.content)
            
        elif args.command == 'tag':
            results = query.search_by_tag(args.tag_name)
            print(f"ğŸ·ï¸  æ ‡ç­¾: '{args.tag_name}'")
            print_search_results(results, args.content)
            
        elif args.command == 'list-tags':
            tags = query.list_all_tags()
            print("ğŸ·ï¸  æ‰€æœ‰æ ‡ç­¾:")
            for tag in tags:
                print(f"  - {tag}")
            
        elif args.command == 'list-types':
            types = query.list_all_types()
            print("ğŸ“‚ æ‰€æœ‰çŸ¥è¯†ç±»å‹:")
            for ktype in types:
                print(f"  - {ktype}")
            
        elif args.command == 'content':
            content = query.get_chunk_content(args.item_id, args.chunk)
            if content:
                print(f"ğŸ“„ çŸ¥è¯†é¡¹å†…å®¹ (ID: {args.item_id}):")
                print("=" * 60)
                print(content)
            else:
                print(f"âŒ æœªæ‰¾åˆ°çŸ¥è¯†é¡¹: {args.item_id}")
                
        else:
            parser.print_help()
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main()) 