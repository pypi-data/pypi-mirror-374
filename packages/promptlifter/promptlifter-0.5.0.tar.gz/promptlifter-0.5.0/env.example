# Custom LLM Configuration (Primary - Local Models)
CUSTOM_LLM_ENDPOINT=http://localhost:11434
CUSTOM_LLM_MODEL=llama3.1
CUSTOM_LLM_API_KEY=

# LLM Provider Configuration
LLM_PROVIDER=custom  # custom, openai, anthropic, google

# Embedding Configuration
EMBEDDING_PROVIDER=custom  # custom, openai, anthropic
EMBEDDING_MODEL=nomic-embed-text  # Ollama embedding model (for custom provider) or OpenAI model name

# Commercial LLM Configuration (Fallback)
OPENAI_API_KEY=your-openai-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here
GOOGLE_API_KEY=your-google-api-key-here

# Search and Vector Configuration
TAVILY_API_KEY=your-tavily-api-key-here
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_INDEX=docs-index
PINECONE_NAMESPACE=research

# Pinecone Search Configuration
PINECONE_TOP_K=10                    # Number of results to retrieve (default: 10)
PINECONE_SIMILARITY_THRESHOLD=0.7    # Minimum similarity score (0.0-1.0, default: 0.7)
PINECONE_INCLUDE_SCORES=true         # Include similarity scores in output (true/false)
PINECONE_FILTER_BY_SCORE=true        # Filter results by similarity threshold (true/false)

# Conversation Context Configuration (NEW)
MAX_HISTORY_TOKENS=4000              # Maximum tokens for conversation history (default: 4000)
MAX_CONTEXT_TOKENS=2000              # Maximum tokens for context assembly (default: 2000)
ENABLE_AUTO_SEARCH=true              # Enable automatic search when needed (true/false)
SEARCH_RELEVANCE_THRESHOLD=0.7       # Minimum relevance score for search results (0.0-1.0, default: 0.7) 