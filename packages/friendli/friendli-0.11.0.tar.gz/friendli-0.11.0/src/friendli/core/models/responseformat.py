"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations

from typing import Annotated, Union

from pydantic import Discriminator, Tag
from typing_extensions import TypeAliasType

from friendli.core.utils import get_discriminator

from .responseformatjsonobject import (
    ResponseFormatJSONObject,
    ResponseFormatJSONObjectTypedDict,
)
from .responseformatjsonschema import (
    ResponseFormatJSONSchema,
    ResponseFormatJSONSchemaTypedDict,
)
from .responseformatregex import ResponseFormatRegex, ResponseFormatRegexTypedDict
from .responseformattext import ResponseFormatText, ResponseFormatTextTypedDict

ResponseFormatTypedDict = TypeAliasType(
    "ResponseFormatTypedDict",
    Union[
        ResponseFormatJSONObjectTypedDict,
        ResponseFormatTextTypedDict,
        ResponseFormatJSONSchemaTypedDict,
        ResponseFormatRegexTypedDict,
    ],
)
"The enforced format of the model's output.\n\nNote that the content of the output message may be truncated if it exceeds the `max_tokens`. You can check this by verifying that the `finish_reason` of the output message is `length`.\n\nFor more detailed information, please refer [here](https://friendli.ai/docs/guides/serverless_endpoints/structured-outputs).\n\n***Important***\nYou must explicitly instruct the model to produce the desired output format using a system prompt or user message (e.g., `You are an API generating a valid JSON as output.`).\nOtherwise, the model may result in an unending stream of whitespace or other characters.\n\n**When `response_format` is specified, `min_tokens` field is unsupported.**\n"
ResponseFormat = Annotated[
    Union[
        Annotated[ResponseFormatJSONObject, Tag("json_object")],
        Annotated[ResponseFormatJSONSchema, Tag("json_schema")],
        Annotated[ResponseFormatRegex, Tag("regex")],
        Annotated[ResponseFormatText, Tag("text")],
    ],
    Discriminator(lambda m: get_discriminator(m, "type", "type")),
]
"The enforced format of the model's output.\n\nNote that the content of the output message may be truncated if it exceeds the `max_tokens`. You can check this by verifying that the `finish_reason` of the output message is `length`.\n\nFor more detailed information, please refer [here](https://friendli.ai/docs/guides/serverless_endpoints/structured-outputs).\n\n***Important***\nYou must explicitly instruct the model to produce the desired output format using a system prompt or user message (e.g., `You are an API generating a valid JSON as output.`).\nOtherwise, the model may result in an unending stream of whitespace or other characters.\n\n**When `response_format` is specified, `min_tokens` field is unsupported.**\n"
