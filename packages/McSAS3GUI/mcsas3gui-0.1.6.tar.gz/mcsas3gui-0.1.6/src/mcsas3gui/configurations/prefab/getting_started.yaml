html_description: |
  <html>
      <head>
          <meta charset="UTF-8">
          <meta name="viewport" content="width=device-width, initial-scale=1.0">
          <title>Don't Panic</title>
          <style>
              .friendly-text {
                  font-size: 48px;
                  color: #4CAF50; /* A friendly green color */
                  text-align: center;
                  margin-top: 20%;
                  font-family: 'Comic Sans MS', 'Arial', sans-serif; /* A playful font */
              }
              p, li {
                  /* font-family: "Times New Roman", Times, serif; */
                  text-indent: 2em;
                  line-height: 1.15;
              }

              li {
                  margin-bottom: 0.5em; /* optional spacing between list items */
              }
          </style>
      </head>
      <body>
          <div class="friendly-text">Don't Panic</div>

          <h1>Welcome to McSAS3 GUI</h1>
          
          <p>It's been a long time coming, but now it's here: the graphical user interface to help you use McSAS3. </p>

          <h3> Get started quickly!!! </h3>
          <p><i>If you cannot wait to get McSASing, you can get started quickly by loading the "Quick Start demo" prefab template from the pulldown menu at the top of this tab. This will pre-populate the fields with a test datafile (the OG from the original McSAS), which you can use directly to run a simple optimization, a 10-repetition optimization and some histogramming. </i></p>

          <h2> McWho? </h2>
          <p> McSAS3 (and its older sibling, McSAS) is a program to analyse small-angle scattering patterns using a Monte Carlo approach. If used right, with the appropriate model, it will fit your data perfectly, that is to say, to within the uncertainty of your datapoints. 
          Underneath, it superimposes a set (300 or so) of identical model instances. 
          The Monte Carlo optimization algorithm then uses an acceptance-rejection method to optimize one parameter on these model instances. In the end, it arrives at a set of parameter values that works best within the constraints given for your data. This can be histogrammed to give parameter distributions. </p>
          <p> Usually, McSAS is used to extract form-free <b><i>size</i></b> distributions and volume fractions assuming, say, spherical scatterers. But it's good that you now understand it's not limited to that. Choose well, and it will make you happy. </p>

          <h2>Getting Started</h2>
          <p>This McSAS3GUI interface guides you through setting up and running McSAS3 optimizations and histogramming. It is not required to run McSAS3, McSAS3 itself can run headlessly and can be integrated in any data pipeline. This UI is just here to help you set that up, or help you deal with fitting small batches</p>

          <h3>Oh my god, it's full of tabs!</h3>
          <p>The UI has a handful of tabs, you nominally run through them from left to right: </p>
          <ul>
              <li>You are now here, in the "Getting Started"-tab. This is where you find help. Also, you can select examples from the pull-down menu at the top which will. prepopulate the fields in the following tabs with working examples.</li>
              <li>The tabs with "Settings" in the titles allow you to interactively configure and test the yaml configurations that configure data loading, McSAS optimization and (re)histogramming. </li>
              <li>The "McSAS3 Optimization ..." tab let you run full McSAS3 optimizations on (batches of) measurement files.</li>
              <li>Lastly, the "(Re)Histogramming ..." tab lets you (re-)histogram previously optimized results..</li>
          </ul>

          <p>Let's go through these tabs one by one...</p>

          <h3> The "Data Settings"-tab </h3>
          <p>In this tab, you can configure how your data should be read. McSAS3 has a very flexible data ingestor, which can read text-based formats (e.g. csv or pdh), as well as HDF5-based formats (such as NeXus or NXCanSAS) very flexibly. Several templates are available to show how this can be done. You can choose one of these templates from the pulldown menu at the top. This will load the template into the YAML editor widget. The YAML editor widget does syntax highlighting and validation for you, and you can load and save YAML files with the two buttons underneath the YAML editor field. Remember to save the configuration once you have tuned it to your wishes, as you'll need the saved data read configuration file later. </p>
          <p>Before you start editing the YAML, however, I would recommend also loading a test datafile of the type you want to read. This can be done by either dragging and dropping into the text line field below the "Load Configuration" and "Save configuration" buttons. You can also use the "Browse" button to browse to a particular test datafile. </p>
          <p>Now that you have a test file and a YAML, the interface will try to read your file. If it can, it will show (graphically) the resulting raw, clipped and binned data in a separate window. Keep this window open, it'll be useful. </p>
          <p>For NeXus files, you'll need to indicate the paths to Q, I and ISigma, the uncertainty estimate on I (the better this uncertainty estimate, the better it'll work). If the NeXus file cannot be read, the information window at the bottom will show the paths to all the datasets in your test file; hopefully you can find there the data you are looking for. </p>
          <p>For ascii/csv files, you can use the "csvargs" section to specify the keyword-value combinations that pandas.read_csv needs to work. For example, you can tell it how many lines to skip, what the separator is, and so on. </p>
          <p>Data units and unit conversions will be implemented before the v1 release (maybe, if I can free up the time). </p>
          <p>You can change the data limits you want to fit by adjusting the "dataRange" in the YAML, and you can use the "omitRanges" list of ranges to skip over data segments you don't want to fit, such as peaks.</p>
          <p>You can set the minimum possible inter-datapoint uncertainty limit for your data using "IEmin", which is a fraction of the intensity, default set to 1%. nBins sets the number of (log-spaced) bins to rebin your data into. 100 bins per decade or two is usually more than sufficient, and ensures proper speed. </p> 
          
          <h3> The "Run Settings"-tab </h3>
          <p>In this tab, you can configure how McSAS3 will run. You can choose a template from the pulldown menu at the top, which will load a template into the YAML editor widget. The YAML editor widget does syntax highlighting and validation for you, and you can load and save YAML files with the two buttons underneath the YAML editor field. Remember to save the configuration once you have tuned it to your wishes, as you'll need the saved run configuration file later. </p>
          <p>In the YAML, you can set the number of iterations to run, the number of model instances to use, and the number of threads to use. It also configures which sasmodel to use, though not all options and combinations are avaiable (more precisely, you are limited only to models that specify a volume...). Once you construct a model name, the information panel will show the possible parameters to enter. Only one should be chosen as a fit parameter, the rest should be static parameters. Undefined parameters are filled with their default values. </p>
          <p>A special note: take care to limit the maximum number of iteration (and optionally the maximum number to accept before completion), as there is no "stop" button at the moment to interrupt the independent workers. You could be waiting for a long time if set incorrectly! </p>
          <p>You can test a single optimization on the test data loaded in the "Data Settings"-tab by clicking the "Test Run" button. This will run a single optimization with the current settings, and show the resulting fit curve in the data plot. </p>
          <p>Once you are happy with the settings, you can save your settings, and run the full optimization on a (batch of) files in the "Optimization..." tab. </p>

          <h3> The "Optimization..."-tab </h3>
          <p>In this tab, you can run a full McSAS3 optimization on a (batch of) files. While drag-and-drop does not work yet, you can add files to the list using the "Load Datafile(s)" button. You will also need to specify the data load and optimization configurations, these can be dragged and dropped into their respective lines. "Run McSAS3 Optimization ... " will then sequentially run the full optimization on all the files in the list. This has been tested with thousands of datafiles (and copious amounts of time). The results are stored in the filename_output.hdf5 files appearing alongside the originals. </p>

          <h3> The "Hist Settings"-tab </h3>
          <p> Now you can configure how the histogramming should be done. You can choose a template from the pulldown menu at the top, with either a single or a dual histogram configured (you can add as many as you want). The configuration should speak for itself. At the moment, only volume-weighted histogramming is implemented, and the "minimum visibility limit" from the OG McSAS has not yet been implemented. Population </p>

          <h3> The "(Re-)Histogramming..."-tab </h3>
          <p>In this tab, you can run the histogramming on the results of optimization(s). You can redo this as many times as you need, no need to re-optimize like in OG McSAS. You will have to populate the list as before in the Optimization tab, but now with the "_output.hdf5" files. Then select the histogramming configuration file. The histogramming will then be run on all the files in the list, and will be stored alongside the optimization in the "_output.hdf5" file. For your convenience, a useful plot is also stored alongside in a PDF file. But if you want to work with the results, the HDF5 file is where you will find *all* the information you would ever want. And then some.. </p>
      </body>
  </html>
