# Phase 3: ë¡œê¹… ë° í…ŒìŠ¤íŒ… í†µí•© êµ¬í˜„

**Phase ì‹œì‘ì¼**: 2025-09-05  
**ì˜ˆìƒ ì™„ë£Œì¼**: 2025-09-07 (3ì¼)  
**í˜„ì¬ ìƒíƒœ**: ğŸ“‹ ê³„íš ìˆ˜ë¦½ ì¤‘

---

## ğŸ“‹ Phase 3 ëª©í‘œ

Phase 1ì˜ MonoResult/FluxResultì™€ Phase 2ì˜ FastAPI í†µí•©ì„ ê¸°ë°˜ìœ¼ë¡œ, í¬ê´„ì ì¸ ë¡œê¹… ì‹œìŠ¤í…œê³¼ í…ŒìŠ¤íŒ… ìœ í‹¸ë¦¬í‹°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ Result íŒ¨í„´ì„ ì™„ë²½í•˜ê²Œ ëª¨ë‹ˆí„°ë§í•˜ê³  í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ì¸í”„ë¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ì„±ê³¼ ëª©í‘œ
- [ ] AsyncResult êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ ì™„ì„±
- [ ] ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë° ëª¨ë‹ˆí„°ë§ í†µí•©
- [ ] í…ŒìŠ¤íŒ… ìœ í‹¸ë¦¬í‹° ë° ëª¨í‚¹ í—¬í¼ ì™„ì„±
- [ ] ì—ëŸ¬ ì¶”ì  ë° ë¶„ì„ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] CI/CD íŒŒì´í”„ë¼ì¸ í†µí•© ì§€ì›

---

## ğŸ¯ ëŒ€ìƒ ì‚¬ìš© íŒ¨í„´

### ê¸°ì¡´ ë¬¸ì œì  (í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë°œê²¬)
```python
# í˜„ì¬ì˜ ì‚°ë°œì ì¸ ë¡œê¹… íŒ¨í„´
@app.get("/users/{user_id}")
async def get_user(user_id: str):
    logger.info(f"Getting user {user_id}")
    try:
        user = await user_service.get_user(user_id)
        logger.info(f"User {user_id} found")
        return user
    except Exception as e:
        logger.error(f"Error getting user {user_id}: {e}")
        raise HTTPException(status_code=500)

# ì¼ê´€ì„± ì—†ëŠ” í…ŒìŠ¤íŠ¸ íŒ¨í„´
def test_get_user():
    # Mock ì„¤ì •ì´ ë³µì¡í•˜ê³  Result íŒ¨í„´ ê³ ë ¤ ì•ˆë¨
    with patch('user_service.get_user') as mock_get:
        mock_get.return_value = mock_user
        response = client.get("/users/123")
        assert response.status_code == 200
```

### ëª©í‘œ íŒ¨í„´ (Phase 3 êµ¬í˜„ í›„)
```python
# ğŸ¯ êµ¬í˜„í•  êµ¬ì¡°í™”ëœ ë¡œê¹… íŒ¨í„´
@app.get("/users/{user_id}")
@handle_result
@log_result_operation("user_retrieval")  # ìë™ ë¡œê¹… ë°ì½”ë ˆì´í„°
async def get_user(user_id: str) -> Result[UserResponse, APIError]:
    return await (
        MonoResult.from_async_result(lambda: user_service.get_user_async(user_id))
        .log_step("user_service_call")  # ì¤‘ê°„ ë‹¨ê³„ ë¡œê¹…
        .bind_result(lambda user: validate_user_response(user))
        .log_step("user_validation") 
        .map_error(lambda e: APIError.from_service_error(e))
        .log_error("user_retrieval_error")  # ì—ëŸ¬ ì „ìš© ë¡œê¹…
        .timeout(5.0)
        .to_result()
    )

# ğŸ¯ êµ¬í˜„í•  Result ê¸°ë°˜ í…ŒìŠ¤íŒ… íŒ¨í„´
@pytest.mark.asyncio
async def test_get_user_success():
    # Result íŒ¨í„´ì„ ê³ ë ¤í•œ ëª¨í‚¹
    with mock_result_service("user_service", "get_user_async") as mock_svc:
        mock_svc.return_success(sample_user)
        
        result = await get_user("123")
        
        assert_result_success(result, UserResponse)
        assert result.unwrap().user_id == "123"
        mock_svc.assert_called_once_with("123")

@pytest.mark.asyncio
async def test_get_user_not_found():
    with mock_result_service("user_service", "get_user_async") as mock_svc:
        mock_svc.return_error(APIError.not_found("ì‚¬ìš©ì", "123"))
        
        result = await get_user("123")
        
        assert_result_error(result, APIError)
        assert result.unwrap_error().code == ErrorCode.NOT_FOUND
```

### ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­ íŒ¨í„´
```python
# ğŸ¯ êµ¬í˜„í•  ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ íŒ¨í„´
@app.get("/analytics/performance")
async def get_performance_metrics() -> FastAPIResult[PerformanceMetrics]:
    return await (
        ResultMetricsCollector.instance()
        .get_operation_metrics("user_retrieval", time_range="1h")
        .bind_result(lambda metrics: format_performance_report(metrics))
    )

# ìë™ ìƒì„±ë˜ëŠ” ë©”íŠ¸ë¦­:
# - Success/Failure ë¹„ìœ¨
# - ì‘ë‹µ ì‹œê°„ ë¶„í¬
# - ì—ëŸ¬ ìœ í˜•ë³„ í†µê³„
# - ì²˜ë¦¬ëŸ‰ (RPS)
```

---

## ğŸ—ï¸ êµ¬í˜„ ê³„íš

### 1ë‹¨ê³„: AsyncResult ë¡œê¹… í™•ì¥ (1ì¼)
**íŒŒì¼**: `src/rfs/monitoring/result_logging.py`

#### í•µì‹¬ ê¸°ëŠ¥
- `@log_result_operation` ë°ì½”ë ˆì´í„°: ì „ì²´ ì‘ì—… ë¡œê¹…
- MonoResult/FluxResult ë¡œê¹… ë©”ì„œë“œ í™•ì¥
- êµ¬ì¡°í™”ëœ ë¡œê·¸ í¬ë§· (JSON ê¸°ë°˜)
- ìƒê´€ê´€ê³„ ID (Correlation ID) ì§€ì›

#### ê³ ê¸‰ ê¸°ëŠ¥
- ë¡œê·¸ ë ˆë²¨ ë™ì  ì¡°ì •
- ë¯¼ê° ì •ë³´ ìë™ ë§ˆìŠ¤í‚¹
- ë¶„ì‚° íŠ¸ë ˆì´ì‹± í†µí•© (OpenTelemetry)

### 2ë‹¨ê³„: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ (1ì¼)
**íŒŒì¼**: `src/rfs/monitoring/metrics.py`

#### í•µì‹¬ ê¸°ëŠ¥
- `ResultMetricsCollector` í´ë˜ìŠ¤: ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
- ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ API
- ì•Œë¦¼ ì„ê³„ê°’ ì„¤ì •

### 3ë‹¨ê³„: í…ŒìŠ¤íŒ… ìœ í‹¸ë¦¬í‹° (1ì¼)
**íŒŒì¼**: `src/rfs/testing/result_helpers.py`

#### í•µì‹¬ ê¸°ëŠ¥
- `mock_result_service()` ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
- `assert_result_success/error()` ê²€ì¦ í—¬í¼
- í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±ê¸°

---

## ğŸ“Š ê¸°ìˆ  ì‚¬ì–‘

### ë¡œê¹… ë°ì´í„° ìŠ¤í‚¤ë§ˆ
```python
@dataclass
class ResultLogEntry:
    """Result íŒ¨í„´ ê¸°ë°˜ ë¡œê·¸ ì—”íŠ¸ë¦¬"""
    timestamp: datetime
    correlation_id: str
    operation_name: str
    step_name: Optional[str]
    
    # Result ì •ë³´
    result_type: Literal["success", "error"]
    processing_time_ms: float
    
    # ì„±ê³µ ì •ë³´
    success_type: Optional[str] = None
    
    # ì—ëŸ¬ ì •ë³´  
    error_type: Optional[str] = None
    error_code: Optional[str] = None
    error_message: Optional[str] = None
    
    # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    user_id: Optional[str] = None
    request_id: Optional[str] = None
    service_name: str = "rfs-framework"
    environment: str = "production"
    
    # ì„±ëŠ¥ ì •ë³´
    memory_usage_mb: Optional[float] = None
    cpu_usage_percent: Optional[float] = None
    
    # ë©”íƒ€ë°ì´í„°
    metadata: Dict[str, Any] = field(default_factory=dict)
```

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìŠ¤í‚¤ë§ˆ
```python
@dataclass  
class OperationMetrics:
    """ì‘ì—…ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    operation_name: str
    time_window: str  # "1h", "1d", "1w"
    
    # ì²˜ë¦¬ëŸ‰ ë©”íŠ¸ë¦­
    total_requests: int
    successful_requests: int
    failed_requests: int
    success_rate: float
    
    # ì‘ë‹µ ì‹œê°„ ë©”íŠ¸ë¦­
    avg_response_time_ms: float
    p50_response_time_ms: float
    p90_response_time_ms: float
    p99_response_time_ms: float
    max_response_time_ms: float
    
    # ì—ëŸ¬ í†µê³„
    error_breakdown: Dict[str, int]  # error_code -> count
    top_errors: List[Tuple[str, int]]  # (error_message, count)
    
    # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
    avg_memory_usage_mb: float
    avg_cpu_usage_percent: float
    
    # ì‹œê°„ëŒ€ë³„ ë¶„í¬
    hourly_distribution: Dict[int, int]  # hour -> request_count
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ í—¬í¼ ì‚¬ì–‘

### Mock í—¬í¼ í´ë˜ìŠ¤
```python
class ResultServiceMocker:
    """Result íŒ¨í„´ì„ ê³ ë ¤í•œ ì„œë¹„ìŠ¤ ëª¨í‚¹"""
    
    def __init__(self, service_name: str, method_name: str):
        self.service_name = service_name
        self.method_name = method_name
        self.call_count = 0
        self.call_args_history = []
        
    def return_success(self, value: Any) -> "ResultServiceMocker":
        """ì„±ê³µ ê²°ê³¼ ì„¤ì •"""
        self._mock_result = Success(value)
        return self
        
    def return_error(self, error: Any) -> "ResultServiceMocker":
        """ì—ëŸ¬ ê²°ê³¼ ì„¤ì •"""
        self._mock_result = Failure(error)
        return self
        
    def return_sequence(self, results: List[Result]) -> "ResultServiceMocker":
        """ìˆœì°¨ì  ê²°ê³¼ ì„¤ì •"""
        self._result_sequence = results
        self._sequence_index = 0
        return self
        
    async def __call__(self, *args, **kwargs) -> Result:
        """ì‹¤ì œ í˜¸ì¶œ ì‹œ ì‹¤í–‰ë˜ëŠ” ë¡œì§"""
        self.call_count += 1
        self.call_args_history.append((args, kwargs))
        
        if hasattr(self, '_result_sequence'):
            if self._sequence_index < len(self._result_sequence):
                result = self._result_sequence[self._sequence_index]
                self._sequence_index += 1
                return result
            else:
                return Failure("Mock sequence exhausted")
        
        return self._mock_result
    
    def assert_called_once_with(self, *args, **kwargs):
        """í˜¸ì¶œ ê²€ì¦"""
        assert self.call_count == 1, f"Expected 1 call, got {self.call_count}"
        assert self.call_args_history[0] == (args, kwargs)
```

### ê²€ì¦ í—¬í¼ í•¨ìˆ˜ë“¤
```python
def assert_result_success(result: Result[T, E], expected_type: Type[T] = None):
    """Result ì„±ê³µ ê²€ì¦"""
    assert result.is_success(), f"Expected success, got error: {result.unwrap_error()}"
    
    if expected_type:
        success_value = result.unwrap()
        assert isinstance(success_value, expected_type), \
            f"Expected {expected_type.__name__}, got {type(success_value).__name__}"

def assert_result_error(result: Result[T, E], expected_error_type: Type[E] = None):
    """Result ì—ëŸ¬ ê²€ì¦"""
    assert result.is_failure(), f"Expected error, got success: {result.unwrap()}"
    
    if expected_error_type:
        error_value = result.unwrap_error()
        assert isinstance(error_value, expected_error_type), \
            f"Expected {expected_error_type.__name__}, got {type(error_value).__name__}"

def assert_flux_result_stats(
    flux_result: FluxResult[T, E], 
    expected_success: int, 
    expected_failures: int
):
    """FluxResult í†µê³„ ê²€ì¦"""
    assert flux_result.count_success() == expected_success
    assert flux_result.count_failures() == expected_failures

async def assert_mono_result_timeout(
    mono_result: MonoResult[T, E], 
    timeout_seconds: float
):
    """MonoResult íƒ€ì„ì•„ì›ƒ ê²€ì¦"""
    start_time = time.time()
    result = await mono_result.to_result()
    elapsed_time = time.time() - start_time
    
    if result.is_failure() and "timeout" in str(result.unwrap_error()).lower():
        assert elapsed_time >= timeout_seconds * 0.9  # 90% ì˜¤ì°¨ í—ˆìš©
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ API

### ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸
```python
# ğŸ¯ êµ¬í˜„í•  ëª¨ë‹ˆí„°ë§ APIë“¤
@app.get("/monitoring/operations/{operation_name}/metrics")
@handle_result
async def get_operation_metrics(
    operation_name: str,
    time_range: str = "1h"
) -> FastAPIResult[OperationMetrics]:
    """íŠ¹ì • ì‘ì—…ì˜ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    pass

@app.get("/monitoring/health/result-patterns")
@handle_result  
async def get_result_pattern_health() -> FastAPIResult[ResultPatternHealth]:
    """Result íŒ¨í„´ ì „ë°˜ì ì¸ ê±´ê°•ë„ ì²´í¬"""
    pass

@app.get("/monitoring/errors/top")
@handle_result
async def get_top_errors(
    limit: int = 10,
    time_range: str = "1h"
) -> FastAPIResult[List[ErrorSummary]]:
    """ìƒìœ„ ì—ëŸ¬ ëª©ë¡ ì¡°íšŒ"""
    pass

@app.post("/monitoring/alerts/configure")
@handle_result
async def configure_alert_thresholds(
    config: AlertConfiguration
) -> FastAPIResult[str]:
    """ì•Œë¦¼ ì„ê³„ê°’ ì„¤ì •"""
    pass
```

---

## ğŸ“ˆ ì„±ê³µ ì§€í‘œ

### ì •ëŸ‰ì  ì§€í‘œ
- [ ] ë¡œê·¸ êµ¬ì¡°í™”ìœ¨ 100% (ëª¨ë“  Result ì‘ì—…)
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 95% ì´ìƒ (í…ŒìŠ¤íŒ… ìœ í‹¸ë¦¬í‹° ì‚¬ìš©)
- [ ] ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì§€ì—°ì‹œê°„ <50ms
- [ ] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì‘ë‹µì‹œê°„ <200ms

### ì •ì„±ì  ì§€í‘œ
- [ ] ìš´ì˜íŒ€ì˜ ì¥ì•  ëŒ€ì‘ ì‹œê°„ 50% ë‹¨ì¶•
- [ ] ê°œë°œíŒ€ì˜ í…ŒìŠ¤íŠ¸ ì‘ì„± ì‹œê°„ 40% ë‹¨ì¶•
- [ ] í”„ë¡œë•ì…˜ ì´ìŠˆ ì¶”ì  ì •í™•ë„ 90% í–¥ìƒ
- [ ] Result íŒ¨í„´ ë„ì… ì €í•­ ìµœì†Œí™”

---

## ğŸš¨ ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘

### ì£¼ìš” ìœ„í—˜ ìš”ì†Œ
1. **ì„±ëŠ¥ ì˜¤ë²„í—¤ë“œ**: ë¡œê¹…ê³¼ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜
2. **ì €ì¥ì†Œ ìš©ëŸ‰**: ëŒ€ëŸ‰ì˜ ë¡œê·¸ì™€ ë©”íŠ¸ë¦­ ë°ì´í„° ì €ì¥
3. **ë³µì¡ì„± ì¦ê°€**: ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ìì²´ì˜ ë³µì¡ì„±

### ëŒ€ì‘ ë°©ì•ˆ
1. **ë¹„ë™ê¸° ì²˜ë¦¬**: ë¡œê¹…ê³¼ ë©”íŠ¸ë¦­ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬
2. **ë°ì´í„° ë³´ê´€ì •ì±…**: ìë™ ì•„ì¹´ì´ë¹™ ë° ì‚­ì œ ì •ì±…
3. **ë‹¨ê³„ì  ë„ì…**: í•µì‹¬ ê¸°ëŠ¥ë¶€í„° ì ì§„ì  ì ìš©

---

## ğŸ“‚ íŒŒì¼ êµ¬ì¡°

```
src/rfs/monitoring/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ result_logging.py         # @log_result_operation, ë¡œê¹… í™•ì¥
â”œâ”€â”€ metrics.py                # ResultMetricsCollector, ì„±ëŠ¥ ìˆ˜ì§‘
â”œâ”€â”€ alerts.py                 # ì„ê³„ê°’ ì•Œë¦¼ ì‹œìŠ¤í…œ
â””â”€â”€ dashboard_api.py          # ëª¨ë‹ˆí„°ë§ API ì—”ë“œí¬ì¸íŠ¸

src/rfs/testing/
â”œâ”€â”€ __init__.py  
â”œâ”€â”€ result_helpers.py         # Mock í—¬í¼, ê²€ì¦ í•¨ìˆ˜
â”œâ”€â”€ fixtures.py               # ê³µí†µ í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜
â”œâ”€â”€ generators.py             # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±ê¸°
â””â”€â”€ performance.py            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹°

examples/monitoring/
â”œâ”€â”€ basic_logging.py          # ê¸°ë³¸ ë¡œê¹… ì‚¬ìš© ì˜ˆì œ
â”œâ”€â”€ metrics_dashboard.py      # ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ êµ¬í˜„ ì˜ˆì œ
â””â”€â”€ testing_patterns.py       # í…ŒìŠ¤íŒ… íŒ¨í„´ ì˜ˆì œ
```

---

**Phase 3 ì„±ê³µ ê¸°ì¤€**: Result íŒ¨í„´ ì™„ì „í•œ ê´€ì¸¡ê°€ëŠ¥ì„±(Observability) + í…ŒìŠ¤íŒ… ì¸í”„ë¼ ì™„ì„± + px í”„ë¡œì íŠ¸ í”„ë¡œë•ì…˜ ì ìš©

*ì´ ë¬¸ì„œëŠ” êµ¬í˜„ ì§„í–‰ ìƒí™©ì— ë”°ë¼ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.*