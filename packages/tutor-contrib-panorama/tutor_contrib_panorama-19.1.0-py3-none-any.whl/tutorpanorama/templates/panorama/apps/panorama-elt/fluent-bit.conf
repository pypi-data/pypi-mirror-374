[SERVICE]
    Parsers_File  parsers.conf
[INPUT]
    Name              tail
    Tag               kube.*
    Path              /var/log/containers/lms*.log
    # We have to exclude lms-worker logs, otherwise they would be captured by the lms*.log Path above
    Exclude_Path      /var/log/containers/lms-worker*.log
    Parser            docker
    DB                /var/log/flb_kube.db
    # Increase the buffer limit
    Mem_Buf_Limit     256MB
    DB.locking        true
    Rotate_Wait       30
    Docker_Mode       On
    Docker_Mode_Flush 10
    Buffer_Max_Size   256k
    Skip_Long_Lines   Off
    Refresh_Interval  10
[FILTER]
    # The kubernetes filter creates a structure with pod name and other metadata around the log entry
    Name             kubernetes
    Match            kube.*
    Kube_URL         https://kubernetes.default.svc:443
    Kube_CA_File     /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    Kube_Token_File  /var/run/secrets/kubernetes.io/serviceaccount/token
    # Remove the kube.var.log.containers. prefix and leave the filename only in the tag.
    Kube_Tag_Prefix  kube.var.log.containers.
    Merge_Log        On
    # https://docs.fluentbit.io/manual/pipeline/filters/kubernetes#optional-feature-using-kubelet-to-get-metadata
    Use_Kubelet      true
    Kubelet_Port     10250
    # Unlimit buffer
    Buffer_Size      0
[FILTER]
    # The grep filter removes all records that do not match the regex, leaving only the tracking logs.
    Name             grep
    Match            *
    Regex            log ^.* INFO .* \[tracking\] .*$
[FILTER]
    # This parser filter calls the 'event' parser (found in the parsers.conf file)
    # After this filter, each line will be a json record with two keys: date and event
    # The event key will have the text of the tracking log entry.
    Name             parser
    Match            *
    Key_Name         log
    Parser           event
[OUTPUT]
    # Upload to s3
    Name             s3
    Match            *
    bucket           {{ PANORAMA_RAW_LOGS_BUCKET }}
    region           {{ PANORAMA_REGION }}
    compression      gzip
    use_put_object   On
    s3_key_format    /tracking_logs/$TAG[1]/year=%Y/month=%m/day=%d/tracking.log-%Y%m%d-%H%M%S-$UUID.gz
    s3_key_format_tag_delimiters  _
    # A file will be uploaded if it reaches the total_file_size, or after upload_timeout, whatever happens first
    total_file_size  {{ PANORAMA_LOGS_TOTAL_FILE_SIZE }}
    upload_timeout   {{ PANORAMA_LOGS_UPLOAD_TIMEOUT }}
    # The log_key will remove the data key and all json formatting and leave only the value of the 'event' key
    log_key          event
# [OUTPUT]
#     # Uncomment this section to see the output of the process in the console of each pod in the daemonset
#     Name             stdout
#     Match            *
#     Format           json_lines