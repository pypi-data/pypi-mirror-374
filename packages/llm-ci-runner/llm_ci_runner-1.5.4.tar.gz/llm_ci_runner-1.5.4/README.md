# AI-First Toolkit: LLM-Powered Automation

[![PyPI version](https://badge.fury.io/py/llm-ci-runner.svg)](https://badge.fury.io/py/llm-ci-runner) [![CI](https://github.com/Nantero1/ai-first-devops-toolkit/actions/workflows/ci.yml/badge.svg)](https://github.com/Nantero1/ai-first-devops-toolkit/actions/workflows/ci.yml) [![Unit Tests](https://github.com/Nantero1/ai-first-devops-toolkit/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/Nantero1/ai-first-devops-toolkit/actions/workflows/unit-tests.yml) [![Coverage badge](https://raw.githubusercontent.com/Nantero1/ai-first-devops-toolkit/python-coverage-comment-action-data/badge.svg)](https://htmlpreview.github.io/?https://github.com/Nantero1/ai-first-devops-toolkit/blob/python-coverage-comment-action-data/htmlcov/index.html) [![CodeQL](https://github.com/Nantero1/ai-first-devops-toolkit/actions/workflows/github-code-scanning/codeql/badge.svg)](https://github.com/Nantero1/ai-first-devops-toolkit/actions/workflows/github-code-scanning/codeql) [![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT) [![MyPy](https://img.shields.io/badge/mypy-checked-brightgreen)](http://mypy-lang.org/) [![Ruff](https://img.shields.io/badge/ruff-checked-brightgreen)](https://github.com/astral-sh/ruff) [![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10922/badge)](https://www.bestpractices.dev/projects/10922) [![Downloads](https://img.shields.io/pypi/dm/llm-ci-runner)](https://www.pepy.tech/projects/llm-ci-runner)

> **ğŸš€ The Future of DevOps is AI-First**  
> This toolkit represents a step
> toward [AI-First DevOps](https://technologyworkroom.blogspot.com/2025/06/building-ai-first-devops.html) - where
> intelligent automation handles the entire development lifecycle. Built for teams ready to embrace the exponential
> productivity gains of AI-powered development. Please
> read [the blog post](https://technologyworkroom.blogspot.com/2025/06/building-ai-first-devops.html) for more details on
> the motivation.

## TLDR: What This Tool Does

**Purpose**: Transform any unstructured business knowledge into reliable, structured data that powers intelligent
automation across your entire organization.

**Perfect For**:

- ğŸ¦ **Financial Operations**: Convert loan applications, audits, and regulatory docs into structured compliance data
- ğŸ¥ **Healthcare Systems**: Transform patient records, clinical notes, and research data into medical formats
- âš–ï¸ **Legal & Compliance**: Process contracts, court docs, and regulatory texts into actionable risk assessments
- ğŸ­ **Supply Chain**: Turn logistics reports, supplier communications, and forecasts into optimization insights
- ğŸ‘¥ **Human Resources**: Convert resumes, performance reviews, and feedback into structured talent analytics
- ğŸ›¡ï¸ **Security Operations**: Transform threat reports, incident logs, and assessments into standard frameworks
- ğŸš€ **DevOps & Engineering**: Use commit logs, deployment reports, and system logs for automated AI actions
- ğŸ”— **Enterprise Integration**: Connect any business process to downstream systems with guaranteed consistency

---

### Simple structured output example

```bash
# Install and use immediately
pip install llm-ci-runner
llm-ci-runner --input-file examples/02-devops/pr-description/input.json --schema-file examples/02-devops/pr-description/schema.json
```

![Structured output of the PR review example](https://github.com/Nantero1/ai-first-devops-toolkit/raw/main/examples/02-devops/pr-description/output.png)

## The AI-First Development Revolution

This toolkit embodies the principles outlined
in [Building AI-First DevOps](https://technologyworkroom.blogspot.com/2025/06/building-ai-first-devops.html):

| Traditional DevOps          | AI-First DevOps (This Tool)                         |
|-----------------------------|-----------------------------------------------------|
| Manual code reviews         | ğŸ¤– AI-powered reviews with structured findings      |
| Human-written documentation | ğŸ“ AI-generated docs with guaranteed consistency    |
| Reactive security scanning  | ğŸ” Proactive AI security analysis                   |
| Manual quality gates        | ğŸ¯ AI-driven validation with schema enforcement     |
| Linear productivity         | ğŸ“ˆ Exponential gains through intelligent automation |

## Features

- ğŸ¯ **100% Schema Enforcement**: Your pipeline never gets invalid data. Token-level schema enforcement with guaranteed
  compliance
- ğŸ”„ **Resilient execution**: Retries with exponential back-off and jitter plus a clear exception hierarchy keep
  transient cloud faults from breaking your CI.
- ğŸš€ **Zero-Friction CLI**: Single script, minimal configuration for pipeline integration and automation
- ğŸ” **Enterprise Security**: Azure RBAC via DefaultAzureCredential with fallback to API Key
- ğŸ“¦ **CI-friendly CLI**: Stateless command that reads JSON/YAML, writes JSON/YAML, and exits with proper codes
- ğŸ¨ **Beautiful Logging**: Rich console output with timestamps and colors
- ğŸ“ **File-based I/O**: CI/CD friendly with JSON/YAML input/output
- ğŸ“‹ **Template-Driven Workflows**: Handlebars, Jinja2, and Microsoft Semantic Kernel YAML templates with YAML variables for dynamic prompt generation
- ğŸ“„ **YAML Support**: Use YAML for schemas, input files, and output files - more readable than JSON
- ğŸ”§ **Simple & Extensible**: Easy to understand and modify for your specific needs
- ğŸ¤– **Semantic Kernel foundation**: async, service-oriented design ready for skills, memories, orchestration, and future
  model upgrades
- ğŸ“š **Documentation**: Comprehensive documentation for all features and usage examples. Use your semantic kernel skills
  to extend the functionality.
- ğŸ§‘â€âš–ï¸ **Acceptance Tests**: pytest framework with the LLM-as-Judge pattern for quality gates. Test your scripts before
  you run them in production.
- ğŸ’° **Coming soon**: token usage and cost estimation appended to each result for budgeting and optimisation

## ğŸš€ The Only Enterprise AI DevOps Tool That Delivers RBAC Security, Robustness and Simplicity

**LLM-CI-Runner stands alone in the market** as the only tool combining **100% schema enforcement**, **enterprise RBAC
authentication**, and robust **Semantic Kernel integration with templates** in a single CLI solution. **No other tool
delivers all three critical enterprise requirements together**.

## Installation

```bash
pip install llm-ci-runner
```

That's it! No complex setup, no dependency management - just install and use. Perfect for CI/CD pipelines and local
development.

## Quick Start

### 1. Install from PyPI

```bash
pip install llm-ci-runner
```

### 2. Set Environment Variables

**Azure OpenAI (Priority 1):**

```bash
export AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com/"
export AZURE_OPENAI_MODEL="gpt-4.1-nano"  # or any other GPT deployment name
export AZURE_OPENAI_API_VERSION="2024-12-01-preview"  # Optional
```

**OpenAI (Fallback):**

```bash
export OPENAI_API_KEY="your-very-secret-api-key"
export OPENAI_CHAT_MODEL_ID="gpt-4.1-nano"  # or any OpenAI model
export OPENAI_ORG_ID="org-your-org-id"  # Optional
```

**Authentication Options:**

- **Azure RBAC (Recommended)**: Uses `DefaultAzureCredential` for Azure RBAC authentication - no API key needed!
  See [Microsoft Docs](https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python)
  for setup.
- **Azure API Key**: Set `AZURE_OPENAI_API_KEY` environment variable if not using RBAC.
- **OpenAI API Key**: Required for OpenAI fallback when Azure is not configured.

**Priority**: Azure OpenAI takes priority when both Azure and OpenAI environment variables are present.

### 3a. Basic Usage

```bash
# Simple chat example
llm-ci-runner --input-file examples/01-basic/simple-chat/input.json

# With structured output schema
llm-ci-runner \
  --input-file examples/01-basic/sentiment-analysis/input.json \
  --schema-file examples/01-basic/sentiment-analysis/schema.json

# Custom output file
llm-ci-runner \
  --input-file examples/02-devops/pr-description/input.json \
  --schema-file examples/02-devops/pr-description/schema.json \
  --output-file pr-analysis.json

# YAML input files (alternative to JSON)
llm-ci-runner \
  --input-file config.yaml \
  --schema-file schema.yaml \
  --output-file result.yaml
```

### 3b. Template-Based Workflows

**Dynamic prompt generation with YAML, Handlebars, Jinja2, or Microsoft Semantic Kernel templates:**

```bash
# Handlebars template example
llm-ci-runner \
  --template-file examples/05-templates/handlebars-template/template.hbs \
  --template-vars examples/05-templates/handlebars-template/template-vars.yaml \
  --schema-file examples/05-templates/handlebars-template/schema.yaml \
  --output-file handlebars-result.yaml
  
# Or using Jinja2 templates
llm-ci-runner \
  --template-file examples/05-templates/jinja2-template/template.j2 \
  --template-vars examples/05-templates/jinja2-template/template-vars.yaml \
  --schema-file examples/05-templates/jinja2-template/schema.yaml \
  --output-file jinja2-result.yaml

# Or using Microsoft Semantic Kernel YAML templates with embedded schemas
llm-ci-runner \
  --template-file examples/05-templates/sem-ker-structured-analysis/template.yaml \
  --template-vars examples/05-templates/sem-ker-structured-analysis/template-vars.yaml \
  --output-file sk-analysis-result.json
```

For more examples see the [examples directory](https://github.com/Nantero1/ai-first-devops-toolkit/tree/main/examples).

**Benefits of Template Approach:**

- ğŸ¯ **Reusable Templates**: Create once, use across multiple scenarios
- ğŸ“ **YAML Configuration**: More readable than JSON for complex setups
- ğŸ”„ **Dynamic Content**: Variables and conditional rendering
- ğŸš€ **CI/CD Ready**: Perfect for parameterized pipeline workflows
- ğŸ¤– **Semantic Kernel Integration**: Microsoft Semantic Kernel YAML templates with embedded schemas and model settings

### 4. Python Library Usage

**You can use LLM CI Runner directly from Python with both file-based and string-based templates, and with either dict
or file-based variables and schemas. The main entrypoint is:**

```python  
from llm_ci_runner.core import run_llm_task  # Adjust import as needed for your package layout  
```  

#### Basic Usage: File-Based Input

```python  
import asyncio  
from llm_ci_runner.core import run_llm_task  
   
async def main():  
    # Run with a traditional JSON input file (messages, etc)  
    response = await run_llm_task(_input_file="examples/01-basic/simple-chat/input.json")  
    print(response)  
   
asyncio.run(main())  
```  

#### File-Based Template Usage

```python  
import asyncio  
from llm_ci_runner.core import run_llm_task  
   
async def main():  
    # Handlebars, Jinja2, or Semantic Kernel YAML template via file  
    response = await run_llm_task(  
        template_file="examples/05-templates/pr-review-template/template.hbs",  
        template_vars_file="examples/05-templates/pr-review-template/template-vars.yaml",  
        schema_file="examples/05-templates/pr-review-template/schema.yaml",  
        output_file="analysis.json"  
    )  
    print(response)  
   
asyncio.run(main())  
```  

#### String-Based Template Usage

```python  
import asyncio  
from llm_ci_runner.core import run_llm_task  
   
async def main():  
    # String template (Handlebars example)  
    response = await run_llm_task(  
        template_content="Hello {{name}}!",  
        template_format="handlebars",  
        template_vars={"name": "World"},  
    )  
    print(response)  
   
asyncio.run(main())  
```  

#### Semantic Kernel YAML Template with Embedded Schema

Microsoft Semantic Kernel YAML templates provide embedded JSON schemas and model settings directly in the template. See [Microsoft Semantic Kernel YAML Template Documentation](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/yaml-schema) for more details.

Please refer to the full example in [examples/05-templates/sem-ker-structured-analysis/README.md](https://github.com/Nantero1/ai-first-devops-toolkit/blob/main/examples/05-templates/sem-ker-structured-analysis/README.md).

```python  
import asyncio  
from llm_ci_runner.core import run_llm_task  
   
async def main():  
    template_content = """  
template: "Analyze: {{input_text}}"  
input_variables:  
  - name: input_text  
execution_settings:  
  azure_openai:  
    temperature: 0.1  
    response_format:  
      type: json_schema  
      json_schema:  
        schema:  
          type: object  
          properties:  
            sentiment: {type: string, enum: [positive, negative, neutral]}  
            confidence: {type: number, minimum: 0, maximum: 1}  
          required: [sentiment, confidence]  
"""  
    response = await run_llm_task(  
        template_content=template_content,  
        template_format="semantic-kernel",  
        template_vars={"input_text": "Sample data"}  
    )  
    print(response)  
   
asyncio.run(main())  
```  

#### Advanced: Dict-based Schema and Variables

```python  
import asyncio  
from llm_ci_runner.core import run_llm_task  
   
async def main():  
    schema = {  
        "type": "object",  
        "properties": {  
            "sentiment": {"type": "string", "enum": ["positive", "negative", "neutral"]},  
            "confidence": {"type": "number", "minimum": 0, "maximum": 1}  
        },  
        "required": ["sentiment", "confidence"]  
    }  
    template = "Analyze this review: {{review}}"  
    variables = {"review": "I love the new update!"}  
  
    response = await run_llm_task(  
        template_content=template,  
        template_format="handlebars",  
        template_vars=variables,  
        schema=schema  
    )  
    print(response)  
   
asyncio.run(main())  
```  

#### Notes & Tips

- **Only one of** `_input_file`, `template_file`, or `template_content` **may be specified** at a time.
- **Template variables**: Use `template_vars` (Python dict or YAML file path), or `template_vars_file` (YAML file path).
- **Schema**: Use `schema` (dict or JSON/YAML file path), or `schema_file` (file path).
- **template_format** is required with `template_content`. Allowed: `"handlebars"`, `"jinja2"`, `"semantic-kernel"`.
- **output_file**: If specified, writes response to file.

**Returns:** String (for text output) or dict (for structured JSON output).

**Errors:** Raises `InputValidationError` or `LLMRunnerError` on invalid input or execution failure.

### 5. Development Setup (Optional)

For contributors or advanced users who want to modify the source:

```bash
# Install UV if you haven't already
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and install for development
git clone https://github.com/Nantero1/ai-first-devops-toolkit.git
cd ai-first-devops-toolkit
uv sync

# Run from source
uv run llm-ci-runner --input-file examples/01-basic/simple-chat/input.json
```

## The AI-First Transformation: Why Unstructured â†’ Structured Matters

LLMs excel at extracting meaning from messy text, logs, documents, and mixed-format data, then emitting *
*schema-compliant JSON/YAML** that downstream systems can trust. This unlocks:

- **ğŸ”„ Straight-Through Processing**: Structured payloads feed BI dashboards, RPA robots, and CI/CD gates without human
  parsing
- **ğŸ¯ Context-Aware Decisions**: LLMs fuse domain knowledge with live telemetry to prioritize incidents, forecast
  demand, and spot security drift
- **ğŸ“‹ Auditable Compliance**: Formal outputs make it easy to track decisions for regulators and ISO/NIST audits
- **âš¡ Rapid Workflow Automation**: Enable automation across customer service, supply-chain planning, HR case handling,
  and security triage
- **ğŸ”— Safe Pipeline Composition**: Structured contracts let AI-first pipelines remain observable and composable while
  capitalizing on unstructured enterprise data

## Input Formats

### Traditional JSON Input

```json
{
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "Your task description here"
    }
  ],
  "context": {
    "session_id": "optional-session-id",
    "metadata": {
      "any": "additional context"
    }
  }
}
```

### Microsoft Semantic Kernel YAML Templates

The toolkit supports Microsoft Semantic Kernel YAML templates with embedded schemas and execution settings. See [examples/05-templates/](examples/05-templates/) for comprehensive examples.

**Simple Question Template** (`template.yaml`):

```yaml
name: SimpleQuestion
description: Simple semantic kernel template for asking questions
template_format: semantic-kernel
template: |
  You are a helpful {{$role}} assistant. 
  Please answer this question: {{$question}}
  
  Provide a clear and concise response.

input_variables:
  - name: role
    description: The role of the assistant (e.g., technical, customer service)
    default: "technical"
    is_required: false
  - name: question  
    description: The question to be answered
    is_required: true

execution_settings:
  azure_openai:
    temperature: 0.7
    max_tokens: 500
    top_p: 1.0
```

**Template Variables** (`template-vars.yaml`):

```yaml
role: expert DevOps engineer
question: What is the difference between continuous integration and continuous deployment?
```

**Structured Analysis Template** with embedded JSON schema:

```yaml
name: StructuredAnalysis
description: SK template with embedded JSON schema for structured output
template_format: semantic-kernel
template: |
  Analyze the following text and provide a structured response: {{$text_to_analyze}}

input_variables:
  - name: text_to_analyze
    description: The text content to analyze
    is_required: true

execution_settings:
  azure_openai:
    model_id: gpt-4.1-stable
    temperature: 0.3
    max_tokens: 800
    response_format:
      type: json_schema
      json_schema:
        name: analysis_result
        schema:
          type: object
          properties:
            sentiment:
              type: string
              enum: ["positive", "negative", "neutral"]
              description: Overall sentiment of the text
            confidence:
              type: number
              minimum: 0.0
              maximum: 1.0
              description: Confidence score for the sentiment analysis
            key_themes:
              type: array
              items:
                type: string
              description: Main themes identified in the text
            summary:
              type: string
              description: Brief summary of the text
            word_count:
              type: integer
              description: Approximate word count
          required: ["sentiment", "confidence", "summary"]
          additionalProperties: false
```

### Template-Based Input (Handlebars & Jinja2)

**Handlebars Template** (`template.hbs`):

```handlebars

<message role="system">
    You are an expert {{expertise.domain}} engineer.
    Focus on {{expertise.focus_areas}}.
</message>

<message role="user">
    Analyze this {{task.type}}:

    {{#each task.items}}
        - {{this}}
    {{/each}}

    Requirements: {{task.requirements}}
</message>
```

**Jinja2 Template** (`template.j2`):

```jinja2
<message role="system">
You are an expert {{expertise.domain}} engineer.
Focus on {{expertise.focus_areas}}.
</message>

<message role="user">
Analyze this {{task.type}}:

{% for item in task.items %}
- {{item}}
{% endfor %}

Requirements: {{task.requirements}}
</message>
```

**Template Variables** (`vars.yaml`):

```yaml
expertise:
  domain: "DevOps"
  focus_areas: "security, performance, maintainability"
task:
  type: "pull request"
  items:
    - "Changed authentication logic"
    - "Updated database queries"
    - "Added input validation"
  requirements: "Focus on security vulnerabilities"
```

## Structured Outputs with 100% Schema Enforcement

When you provide a `--schema-file`, the runner guarantees perfect schema compliance:

```bash
llm-ci-runner \
  --input-file examples/01-basic/sentiment-analysis/input.json \
  --schema-file examples/01-basic/sentiment-analysis/schema.json
```

**Note**: Output defaults to `result.json`. Use `--output-file custom-name.json` for custom output files.

**Supported Schema Features**:
âœ… String constraints (enum, minLength, maxLength, pattern)  
âœ… Numeric constraints (minimum, maximum, multipleOf)  
âœ… Array constraints (minItems, maxItems, items type)  
âœ… Required fields enforced at generation time  
âœ… Type validation (string, number, integer, boolean, array)

## CI/CD Integration

### GitHub Actions Example

```yaml
- name: Setup Python
  uses: actions/setup-python@v5
  with:
    python-version: '3.12'

- name: Install LLM CI Runner
  run: pip install llm-ci-runner

- name: Generate PR Review with Templates
  run: |
    llm-ci-runner \
      --template-file .github/templates/pr-review.j2 \
      --template-vars pr-context.yaml \
      --schema-file .github/schemas/pr-review.yaml \
      --output-file pr-analysis.yaml
  env:
    AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
    AZURE_OPENAI_MODEL: ${{ secrets.AZURE_OPENAI_MODEL }}
```

For complete CI/CD examples, see *
*[examples/uv-usage-example.md](https://github.com/Nantero1/ai-first-devops-toolkit/blob/main/examples/uv-usage-example.md)
**. This repo is also using itself for release note generation, **check it
out [here](https://github.com/Nantero1/ai-first-devops-toolkit/blob/c4066d347ae14d37cb674e36007a678f38b36439/.github/workflows/release.yml#L145-L149)
**.

## Authentication

**Azure OpenAI**: Uses Azure's `DefaultAzureCredential` supporting:

- Environment variables (local development)
- Managed Identity (recommended for Azure CI/CD)
- Azure CLI (local development)
- Service Principal (non-Azure CI/CD)

**OpenAI**: Uses API key authentication with optional organization ID.

## Testing

We maintain comprehensive test coverage with **100% success rate**:

```bash
# For package users - install test dependencies
pip install llm-ci-runner[dev]

# For development - install from source with test dependencies
uv sync --group dev

# Run specific test categories
pytest tests/unit/ -v          # 70 unit tests
pytest tests/integration/ -v   # End-to-end examples
pytest acceptance/ -v          # LLM-as-judge evaluation

# Or with uv for development
uv run pytest tests/unit/ -v
uv run pytest tests/integration/ -v
uv run pytest acceptance/ -v
```

## Architecture

Built on **Microsoft Semantic Kernel** for:

- Enterprise-ready Azure OpenAI and OpenAI integration
- Future-proof model compatibility
- **100% Schema Enforcement**: KernelBaseModel integration with token-level constraints
- **Dynamic Model Creation**: Runtime JSON schema â†’ Pydantic model conversion
- **Azure RBAC**: Azure RBAC via DefaultAzureCredential
- **Automatic Fallback**: Azure-first priority with OpenAI fallback

## The AI-First Development Journey

This toolkit is your first step
toward [AI-First DevOps](https://technologyworkroom.blogspot.com/2025/06/building-ai-first-devops.html). As you
integrate AI into your development workflows, you'll experience:

1. **ğŸš€ Exponential Productivity**: AI handles routine tasks while you focus on architecture
2. **ğŸ¯ Guaranteed Quality**: Schema enforcement eliminates validation errors
3. **ğŸ¤– Autonomous Operations**: AI agents make decisions in your pipelines
4. **ğŸ“ˆ Continuous Improvement**: Every interaction improves your AI system

**The future belongs to teams that master AI-first principles.** This toolkit gives you the foundation to start that
journey today.

## Real-World Examples

You can explore the **[examples directory](https://github.com/Nantero1/ai-first-devops-toolkit/tree/main/examples)** for
a complete collection of self-contained examples organized by category.

For comprehensive real-world CI/CD scenarios, see *
*[examples/uv-usage-example.md](https://github.com/Nantero1/ai-first-devops-toolkit/blob/main/examples/uv-usage-example.md)
**.

### 100 AI Automation Use Cases for AI-First Automation

**DevOps & Engineering** ğŸ”§

1. ğŸ¤– AI-generated PR review â€“ automated pull request analysis with structured review findings
2. ğŸ“ Release note composer â€“ map commits to semantic-version bump rules and structured changelogs
3. ğŸ” Vulnerability scanner â€“ map code vulnerabilities to OWASP standards with actionable remediation
4. â˜¸ï¸ Kubernetes manifest optimizer â€“ produce risk-scored diffs and security hardening recommendations
5. ğŸ“Š Log anomaly triager â€“ convert system logs into OTEL-formatted events for SIEM ingestion
6. ğŸ’° Cloud cost explainer â€“ output tagged spend by team in FinOps schema for budget optimization
7. ğŸ”„ API diff analyzer â€“ produce backward-compatibility scorecards from specification changes
8. ğŸ›¡ï¸ IaC drift detector â€“ turn Terraform plans into CVE-linked security findings
9. ğŸ“‹ Dependency license auditor â€“ emit SPDX-compatible reports for compliance tracking
10. ğŸ¯ SLA breach summarizer â€“ file structured JIRA tickets with SMART action items

**Governance, Risk & Compliance** ğŸ›ï¸

11. ğŸ“Š Regulatory delta analyzer â€“ emit change-impact matrices from new compliance requirements
12. ğŸŒ± ESG report synthesizer â€“ map CSR prose to GRI indicators and sustainability metrics
13. ğŸ“‹ SOX-404 narrative converter â€“ transform controls descriptions into testable audit checklists
14. ğŸ¦ Basel III stress-test interpreter â€“ output capital risk buckets from regulatory scenarios
15. ğŸ•µï¸ AML SAR formatter â€“ convert investigator notes into Suspicious Activity Report structures
16. ğŸ”’ Privacy policy parser â€“ generate GDPR data-processing-activity logs from legal text
17. ğŸ” Internal audit evidence linker â€“ export control traceability graphs for compliance tracking
18. ğŸ“Š Carbon emission disclosure normalizer â€“ structure sustainability data into XBRL taxonomy
19. âš–ï¸ Regulatory update tracker â€“ generate structured compliance action items from guideline changes
20. ğŸ›¡ï¸ Safety inspection checker â€“ transform narratives into OSHA citation checklists

**Financial Services** ğŸ¦

21. ğŸ¦ Loan application analyzer â€“ transform free-text applications into Basel-III risk-model inputs
22. ğŸ“Š Earnings call sentiment quantifier â€“ output KPI deltas and investor sentiment scores
23. ğŸ’¹ Budget variance explainer â€“ produce drill-down pivot JSON for financial analysis
24. ğŸ“ˆ Portfolio risk dashboard builder â€“ feed VaR models with structured investment analysis
25. ğŸ’³ Fraud alert generator â€“ map investigation notes to CVSS-scored security metrics
26. ğŸ’° Treasury cash-flow predictor â€“ ingest email forecasts into structured planning models
27. ğŸ“Š Financial forecaster â€“ summarize reports into structured cash-flow and projection objects
28. ğŸ§¾ Invoice processor â€“ convert receipts into double-entry ledger posts with GAAP tags
29. ğŸ“‹ Stress test scenario packager â€“ structure regulatory submission data for banking compliance
30. ğŸ¦ Insurance claim assessor â€“ return structured claim-decision objects with risk scores

**Healthcare & Life Sciences** ğŸ¥

31. ğŸ¥ Patient intake processor â€“ build HL7/FHIR-compliant patient records from free-form intake forms
32. ğŸ§  Mental health triage assistant â€“ structure referral notes with priority classifications and care pathways
33. ğŸ“Š Radiology report coder â€“ output SNOMED-coded JSON from diagnostic imaging narratives
34. ğŸ’Š Clinical trial note packager â€“ create FDA eCTD modules from research documentation
35. ğŸ“‹ Prescription parser â€“ turn text prescriptions into structured e-Rx objects with dosage validation
36. âš¡ Vital sign anomaly summarizer â€“ generate alert reports with clinical priority rankings
37. ğŸ§ª Lab result organizer â€“ output LOINC-coded tables from diagnostic test narratives
38. ğŸ¥ Medical device log summarizer â€“ generate UDI incident files for regulatory reporting
39. ğŸ“ˆ Patient feedback sentiment analyzer â€“ feed quality-of-care KPIs from satisfaction surveys
40. ğŸ‘©â€âš•ï¸ Clinical observation compiler â€“ convert research notes into structured data for trials

**Legal & Compliance** âš–ï¸

41. ğŸ›ï¸ Legal contract parser â€“ extract clauses and compute risk scores from contract documents
42. ğŸ“ Court opinion digest â€“ summarize judicial opinions into structured precedent and citation graphs
43. ğŸ›ï¸ Legal discovery summarizer â€“ extract key issues and risks from large document sets
44. ğŸ’¼ Contract review summarizer â€“ extract risk factors and key dates from legal contracts
45. ğŸ›ï¸ Policy impact assessor â€“ convert policy proposals into stakeholder impact matrices
46. ğŸ“œ Patent novelty comparator â€“ produce claim-overlap matrices from prior art analysis
47. ğŸ›ï¸ Legal bill auditor â€“ transform billing details into itemized expense and compliance reports
48. ğŸ“‹ Case strategy brainstormer â€“ summarize likely arguments from litigation documentation
49. ğŸ’¼ Legal email analyzer â€“ extract key issues and deadlines from email threads for review
50. âš–ï¸ Expert witness report normalizer â€“ create citation-linked outlines from testimony records

**Customer Experience & Sales** ğŸ›’

51. ğŸ§ Tier-1 support chatbot â€“ convert customer queries into tickets with reproducible troubleshooting steps
52. â­ Review sentiment miner â€“ produce product-feature tallies from customer feedback analysis
53. ğŸ“‰ Churn risk email summarizer â€“ export CRM risk scores from customer communication patterns
54. ğŸ—ºï¸ Omnichannel conversation unifier â€“ generate customer journey maps from multi-platform interactions
55. â“ Dynamic FAQ builder â€“ structure knowledge base content from community forum discussions
56. ğŸ“‹ Proposal auto-grader â€“ output RFP compliance matrices with scoring rubrics
57. ğŸ“ˆ Upsell opportunity extractor â€“ create lead-scoring JSON from customer interaction analysis
58. ğŸ“± Social media crisis detector â€“ feed escalation playbooks with brand sentiment monitoring
59. ğŸŒ Multilingual intent router â€“ tag customer chats to appropriate support queues by language/topic
60. ğŸ¯ Marketing copy generator â€“ create brand-compliant content with tone and messaging constraints

**HR & People Operations** ğŸ‘¥

61. ğŸ“„ CV-to-JD matcher â€“ rank candidates with explainable competency scores and fit analysis
62. ğŸ¤ Interview transcript summarizer â€“ export structured competency rubrics with evaluation criteria
63. âœ… Onboarding policy compliance checker â€“ produce new-hire checklist completion tracking
64. ğŸ“Š Performance review sentiment analyzer â€“ create growth-plan JSON with development recommendations
65. ğŸ’° Payroll inquiry classifier â€“ map employee emails to structured case codes for HR processing
66. ğŸ¥ Benefits Q&A automation â€“ generate eligibility responses from policy documentation
67. ğŸšª Exit interview insight extractor â€“ feed retention dashboards with structured departure analytics
68. ğŸ“š Training content gap mapper â€“ align job roles to skill taxonomies for learning programs
69. ğŸ›¡ï¸ Workplace incident processor â€“ convert safety reports into OSHA 301 compliance records
70. ğŸ“Š Diversity metric synthesizer â€“ summarize inclusion survey data into actionable insights

**Supply Chain & Manufacturing** ğŸ­

71. ğŸ“Š Demand forecast summarizer â€“ output SKU-level predictions from market analysis and sales data
72. ğŸ“‹ Purchase order processor â€“ convert supplier communications into structured ERP line-items
73. ğŸŒ± Supplier risk scanner â€“ generate ESG compliance scores from vendor assessment reports
74. ğŸ”§ Predictive maintenance log analyst â€“ produce work orders from equipment telemetry narratives
75. ğŸš› Logistics delay explainer â€“ return route-change suggestions from transportation disruption reports
76. â™»ï¸ Circular economy return classifier â€“ create refurbishment tags from product return descriptions
77. ğŸŒ Carbon footprint calculator â€“ map transport legs to COâ‚‚e emissions for sustainability reporting
78. ğŸ“¦ Safety stock alert generator â€“ output inventory triggers with lead-time assumptions
79. ğŸ“œ Regulatory import/export harmonizer â€“ produce HS-code sheets from trade documentation
80. ğŸ­ Production yield analyzer â€“ generate efficiency reports from manufacturing floor logs

**Security & Risk Management** ğŸ”’

81. ğŸ›¡ï¸ MITRE ATT&CK mapper â€“ translate IDS alerts into tactic-technique JSON for threat intelligence
82. ğŸ£ Phishing email extractor â€“ produce IOC STIX bundles from security incident reports
83. ğŸ” Zero-trust policy generator â€“ convert narrative access requests into structured policy rules
84. ğŸš¨ SOC alert deduplicator â€“ cluster security tickets by kill-chain stage for efficient triage
85. ğŸ´â€â˜ ï¸ Red team debrief summarizer â€“ export OWASP Top-10 gaps from penetration test reports
86. ğŸ“‹ Data breach notifier â€“ craft GDPR-compliant disclosure packets with timeline and impact data
87. ğŸ§  Threat intel feed normalizer â€“ convert mixed security PDFs into MISP threat objects
88. ğŸ” Secret leak scanner â€“ output GitHub code-owner mentions from repository security scans
89. ğŸ“Š Vendor risk questionnaire scorer â€“ generate SIG Lite security assessment answers
90. ğŸ—ï¸ Security audit tracker â€“ link ISO-27001 controls to evidence artifacts for compliance

**Knowledge & Productivity** ğŸ“š

91. ğŸ™ï¸ Meeting transcript processor â€“ extract action items with owners and deadlines into project tracking JSON
92. ğŸ“š Research paper summarizer â€“ export citation graphs and key findings for literature review databases
93. ğŸ“‹ SOP generator â€“ convert process narratives into step-by-step validation checklists
94. ğŸ”„ Code diff summarizer â€“ generate reviewer hints and impact analysis from version control changes
95. ğŸ“Š API changelog analyzer â€“ produce backward-compatibility scorecards for development teams
96. ğŸ§  Mind map creator â€“ structure brainstorming sessions into hierarchical knowledge trees
97. ğŸ“– Knowledge base gap detector â€“ suggest article stubs from frequently asked questions analysis
98. ğŸ¯ Personal OKR journal parser â€“ output progress dashboards with milestone tracking
99. ğŸ’¼ White paper composer â€“ transform technical discussions into structured thought leadership content
100. ğŸ§© Universal transformer â€“ convert any unstructured domain knowledge into your custom schema-validated JSON

## License

MIT License - See [LICENSE](https://github.com/Nantero1/ai-first-devops-toolkit/blob/main/LICENSE) file for details.
Copyright (c) 2025, Benjamin Linnik.

## Support

**ğŸ› Found a bug? ğŸ’¡ Have a question? ğŸ“š Need help?**

**GitHub is your primary destination for all support:**

- **ğŸ“‹ Issues & Bug Reports**: [Create an issue](https://github.com/Nantero1/ai-first-devops-toolkit/issues)
- **ğŸ“– Documentation**: [Browse examples](https://github.com/Nantero1/ai-first-devops-toolkit/tree/main/examples)
- **ğŸ”§ Source Code**: [View source](https://github.com/Nantero1/ai-first-devops-toolkit)

**Before opening an issue, please:**

1. âœ… Check the [examples directory](https://github.com/Nantero1/ai-first-devops-toolkit/tree/main/examples) for
   solutions
2. âœ… Review the error logs (beautiful output with Rich!)
3. âœ… Validate your Azure authentication and permissions
4. âœ… Ensure your input JSON follows the required format
5. âœ… Search existing [issues](https://github.com/Nantero1/ai-first-devops-toolkit/issues) for similar problems

**Quick Links:**

- ğŸš€ [Getting Started Guide](https://github.com/Nantero1/ai-first-devops-toolkit#quick-start)
- ğŸ“š [Complete Examples](https://github.com/Nantero1/ai-first-devops-toolkit/tree/main/examples)
- ğŸ”§ [CI/CD Integration](https://github.com/Nantero1/ai-first-devops-toolkit#cicd-integration)
- ğŸ¯ [Use Cases](https://github.com/Nantero1/ai-first-devops-toolkit#use-cases)

---

*Ready to embrace the AI-First future? Start with this toolkit and build your path to exponential productivity. Learn
more about the AI-First DevOps revolution
in [Building AI-First DevOps](https://technologyworkroom.blogspot.com/2025/06/building-ai-first-devops.html).*
