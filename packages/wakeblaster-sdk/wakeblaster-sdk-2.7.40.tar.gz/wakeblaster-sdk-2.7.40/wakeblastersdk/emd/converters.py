from xml.etree import ElementTree as et
import tempfile
from datetime import datetime
from contextlib import contextmanager
import shutil
import zipfile
from os import path
import logging
import hashlib
import bisect
import numpy as np
import pandas as pd

LOGGER = logging.getLogger(__name__)

REFERENCE_ID = 'reference'
REF_DESIGN_ID = 'reference'

def to_wtg(turbine_type):
    root = et.Element('WindTurbineGenerator', RotorDiameter=str(turbine_type.RotorDiameter), FormatVersion='1.01', Description='WindReq-WTG')
    et.SubElement(root, 'Comments').text = 'Generated by WakeBlaster SDK from WindPRO WakeReq format'
    et.SubElement(root, 'DefaultOperatingMode').text = str(turbine_type.defaultMode)
    et.SubElement(et.SubElement(root, 'SuggestedHeights'), 'Height').text = str(turbine_type.HubHeight)
    for name, mode in turbine_type.Modes.items():
        perf_table = et.SubElement(
            root,
            'PerformanceTable',
            AirDensity=str(mode.airDensity),
            StationaryThrustCoEfficient=str(mode.stationaryThrustCoefficient),
            OperatingMode=mode.id
        )
        et.SubElement(
            perf_table,
            'StartStopStrategy',
            LowSpeedCutIn=str(turbine_type.CutIn), LowSpeedCutOut=str(turbine_type.CutIn),
            HighSpeedCutIn=str(turbine_type.CutOut), HighSpeedCutOut=str(turbine_type.CutOut)
        )
        data_table = et.SubElement(perf_table, 'DataTable')
        for wind_speed, ct in mode.ctCurve:
            et.SubElement(data_table, 'DataPoint', WindSpeed=str(wind_speed), PowerOutput=str(0.0), ThrustCoEfficient=str(ct))

    return et.tostring(root).decode('utf8')

def to_design_descriptions(wake_req_file):
    for design_id, turbine_type in wake_req_file.TurbineTypes.items():
        yield design_id, to_wtg(turbine_type)

def to_reference_design(wake_req_file):
    return REF_DESIGN_ID, {'height': wake_req_file.Reference.height}

def to_qualified_id(farm_id, design_id):
    return '{}_{}'.format(farm_id, design_id)

def to_turbine_description(farm_id, turbine):
    return {
        'id': turbine.id,
        'design_id': to_qualified_id(farm_id, turbine.Type.id),
        'easting': turbine.x,
        'northing': turbine.y,
        'elevation': turbine.z
    }

def to_wind_farm_description(farm_id, turbines, reference):
    return {'turbine_instances': [to_turbine_description(farm_id, t) for t in turbines],
            'met_mast_instances': [{'id': REFERENCE_ID,
                                    'easting': reference.x,
                                    'northing': reference.y,
                                    'elevation': reference.z,
                                    'design_id': REF_DESIGN_ID}]}

def to_json(etree):
    result = {}
    for child in etree:
        if child.text and child.text.strip():
            result[child.tag] = child.text.strip()
        else:
            result[child.tag] = to_json(child)
    return result

def to_simulation_config(client_configurations):
    for client_configuration in client_configurations:
        if client_configuration.name.lower() == 'wakeblaster':
            config_tree = et.fromstring(client_configuration.contents)
            return to_json(config_tree)
    return {}

def to_wind_farm_turbulence(farm):
    if farm.turbulencesData is None:
        return None
    wind_speeds, wind_directions = set(), set()
    value_lines = []
    for line in farm.turbulencesData.split('\r\n')[1:]:
        values = [float(v) for v in line.strip().split(' ') if v]
        if len(values) != 3:
            continue
        value_lines.append(values)
        wind_speeds.add(values[0])
        wind_directions.add(values[1])
    wind_speeds = sorted(list(wind_speeds))
    wind_directions = sorted(list(wind_directions))
    turbulence_intensities = []
    for _ in wind_speeds:
        turbulence_intensities.append([float('nan')] * len(wind_directions))
    for values in value_lines:
        turbulence_intensities[wind_speeds.index(values[0])][wind_directions.index(values[1])] = values[2]
    return {
        'turbulence_intensity': turbulence_intensities,
        'wind_directions': wind_directions,
        'wind_speeds': wind_speeds
    }


_ReferenceSignalIdLookup = {
    'windSpeed': 'WindSpeed_avg',
    'turbulenceStdDev': 'WindSpeed_std',
    'windSpeedStd': 'WindSpeed_std',
    'windDirection': 'WindDirection_avg',
    'airDensity': 'AirDensity_avg',
    'stability': 'MoninObukhovLength'
}


def turbine_signal_id_lookup(use_wind_speeds):
    lookup = {
        'operationMode': 'OperatingMode',
        'operationState': 'OperatingState'
    }
    if use_wind_speeds:
        lookup['windSpeed'] = 'WindSpeed_avg'
    return lookup


def get_timestamp_param(parameters):
    for param in parameters:
        if param.type == 'dateTime':
            return param
    return None


def to_measurements(flow_cases, use_instance_wind_speed_measurements):
    measurements = []
    if (REFERENCE_ID, 'dateTime') in flow_cases.columns:
        flow_cases = flow_cases.set_index((REFERENCE_ID, 'dateTime'))
        time_series = True
    else:
        time_series = False
    turbine_signal_ids = turbine_signal_id_lookup(use_instance_wind_speed_measurements)
    for idx, series in flow_cases.iterrows():
        if time_series:
            measurement_template = {'timestamp': idx}
        else:
            measurement_template = {'flow_case_id': 'flow_case_{}'.format(idx)}
        for (instance, param), value in series.items():
            if instance == REFERENCE_ID:
                #EMD provides additional signals in some cases, which we can be ignored.
                if param in _ReferenceSignalIdLookup:
                    measurements.append({
                        **measurement_template,
                        'instance_id': REFERENCE_ID,
                        'signal_id': _ReferenceSignalIdLookup[param],
                        'value': value
                    })
            else:
                if param in turbine_signal_ids:  # turbine parameters not in signal ID lookup ignored
                    measurements.append({
                        **measurement_template,
                        'instance_id': instance,
                        'signal_id': turbine_signal_ids[param],
                        'value': value
                    })
    return measurements


def to_flow_case_dataframe(wake_req_file):
    data = pd.DataFrame()
    for param in wake_req_file.Reference.Parameters:
        data[(REFERENCE_ID, param.type)] = param.data
    for turbine in wake_req_file.Turbines:
        for param in turbine.Parameters:
            data[(turbine.id, param.type)] = param.data
    data.columns = pd.MultiIndex.from_tuples(data.columns, names=['Instance', 'Parameter'])
    return data.transform(pd.to_numeric, errors='ignore')


def to_associated_wind_speeds(flow_cases, wake_req_file):
    reference_parameters = {p.type: p.data for p in wake_req_file.Reference.Parameters}
    if 'windSpeed' not in reference_parameters:
        raise ValueError('windSpeed not found in reference data')
    if 'windDirection' not in reference_parameters:
        raise ValueError('windDirection not found in reference data')
    wind_speed_data = flow_cases.xs('windSpeed', level='Parameter', axis='columns')
    ws_ratio_data = pd.DataFrame(index=flow_cases.index)
    ref_ws = flow_cases[(REFERENCE_ID, 'windSpeed')]
    ref_wd = flow_cases[(REFERENCE_ID, 'windDirection')]
    for turbine in wake_req_file.Turbines:
        ws_ratio_data[turbine.id] = flow_cases[(turbine.id, 'windSpeed')] / ref_ws
    if wake_req_file.Configuration.is_time_varying:
        speed_ups = ws_ratio_data.groupby(by=pd.cut(ref_wd, np.linspace(0.0, 360.0, 361, endpoint=True))).median()
        speed_ups = speed_ups.interpolate().bfill().ffill()
        interval_idx = pd.IntervalIndex(speed_ups.index)
        wd_axis = 0.5 * (interval_idx.left + interval_idx.right)
    else:
        speed_ups = ws_ratio_data.groupby(by=ref_wd).median()
        wd_axis = speed_ups.index.values
    wind_speeds = {
        'reference_id': REFERENCE_ID,
        'reference_wind_directions': wd_axis.tolist(),
        'instances': []
    }
    for turbine in wake_req_file.Turbines:
        wind_speeds['instances'].append({
            'instance_id': str(turbine.id),
            'instance_wind_speeds': speed_ups[turbine.id].values.tolist()
        })
    return wind_speeds

def _md5(fname):
    hash_md5 = hashlib.md5()
    with open(fname, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def get_job_info(job_info, simulation_id, version, file_path):
    return {
        'job_id': job_info.jobId,
        'simulation_id': simulation_id,
        'client': {
            'name': job_info.clientInformationName,
            'version': job_info.clientInformationVersion,
            'user_name': job_info.clientInformationUserName
        },
        'coord_sys': {
            'type': job_info.coorSysType,
            'value': job_info.coorSys
        },
        'request_file': {
            'path': path.abspath(file_path),
            'checksum': _md5(file_path)
        },
        'time': datetime.now().isoformat(),
        'version': version
    }

@contextmanager
def tmpdir():
    tmp_dir = tempfile.mkdtemp()
    yield tmp_dir
    shutil.rmtree(tmp_dir)

OUTPUT_SIGNAL_MAP = {
    'windSpeed': 'rotor_wind_speed',
    'turbulenceIntensity': 'turbulence_intensity',
    'wakeSpeedFactor': 'wake_speed_factor',
    'airDensity': 'air_density'
}

def flow_case_order(result):
    flow_case_id = result['flow_case_id']
    if flow_case_id.startswith('flow_case_'):
        return int(flow_case_id.replace('flow_case_', ''))
    else:
        return flow_case_id  # should be ISO-8601 timestamp which naturally sorts

def write_results_csv(results, path):
    header_written = False
    delimiter = ' '
    header = []
    instance_ids = []
    with open(path, 'w') as fp:
        for result in sorted(results, key=flow_case_order):
            values = []
            for turbine_result in sorted(result['turbine_results'], key=lambda v: v['instance_id']):
                instance_id = turbine_result['instance_id']
                if instance_id not in instance_ids:
                    instance_ids.append(instance_id)
                if not header_written:
                    header += [
                        instance_id + '_' + signal_id
                        for signal_id in OUTPUT_SIGNAL_MAP.keys()
                    ]
                values += [
                    turbine_result[signal_id] if turbine_result[signal_id] is not None else float('nan')
                    for signal_id in OUTPUT_SIGNAL_MAP.values()
                ]
            if not header_written:
                fp.write(delimiter.join(header) + '\n')
                header_written = True
            fp.write(delimiter.join(str(v) for v in values) + '\n')
    return instance_ids


def to_wakeres(job_info, results, output_path):
    request_file = job_info.get('request_file')
    request_file_path = None
    if request_file is None:
        LOGGER.warn('Request file not defined in job info - leaving out of result')
    else:
        checksum = request_file['checksum']
        file_path = request_file['path']
        if not path.isfile(file_path):
            LOGGER.warn('Request file not found - leaving out of result')
        elif checksum != _md5(file_path):
            LOGGER.warn('Request file has changed - leaving out of result')
        else:
            request_file_path = file_path

    with tmpdir() as temp_dir:
        instance_ids = write_results_csv(results, path.join(temp_dir, 'output.csv'))
        wake_res = et.Element('WakeResult')
        job_info_node = et.SubElement(wake_res, 'JobInfo')
        et.SubElement(job_info_node, 'JobId').text = job_info['job_id']
        et.SubElement(job_info_node, 'CoorSys', type=job_info['coord_sys']['type']).text = job_info['coord_sys']['value']
        et.SubElement(job_info_node, 'ClientInformation', name=job_info['client']['name'] or '', version=job_info['client']['version'], userName=job_info['client']['user_name'] or '')
        et.SubElement(job_info_node, 'CalculationDateTime').text = job_info['time']
        if request_file_path is not None:
            et.SubElement(wake_res, 'WakeRequest', file='request.wakeReq')
        et.SubElement(wake_res, 'WakeModel', name='WakeBlaster', version=job_info['version'])
        et.SubElement(et.SubElement(wake_res, 'Farm'), 'Scenarios', file='output.csv')
        turbines = et.SubElement(wake_res, 'Turbines')
        for instance_id in instance_ids:
            turbine = et.SubElement(turbines, 'Turbine', id=instance_id)
            for signal_id in OUTPUT_SIGNAL_MAP.keys():
                et.SubElement(turbine, 'Parameter', col=instance_id + '_' + signal_id, type=signal_id)
        with open(path.join(temp_dir, 'WakeResult.xml'), 'w') as fp:
            et.ElementTree(wake_res).write(fp, encoding='unicode', xml_declaration=True)
        with zipfile.ZipFile(output_path, 'w') as zipf:
            zipf.write(path.join(temp_dir, 'output.csv'), arcname='output.csv')
            zipf.write(path.join(temp_dir, 'WakeResult.xml'), arcname='WakeResult.xml')
            if request_file_path is not None:
                zipf.write(request_file_path, arcname='request.wakeReq')
