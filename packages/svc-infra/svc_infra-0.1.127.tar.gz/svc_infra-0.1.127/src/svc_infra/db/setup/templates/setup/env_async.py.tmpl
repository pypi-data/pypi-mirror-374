# Alembic async env.py generated by svc-infra
from __future__ import annotations
import os
import logging
from typing import List

from alembic import context
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy.engine import make_url

# Load logging configuration from alembic.ini
config = context.config
if config.config_file_name is not None:
    import logging.config
    logging.config.fileConfig(config.config_file_name)
logger = logging.getLogger(__name__)

# --- sys.path bootstrap for src-layout projects ---
import sys, pathlib
prepend = config.get_main_option("prepend_sys_path") or ""
if prepend:
    if prepend not in sys.path:
        sys.path.insert(0, prepend)
    src_path = pathlib.Path(prepend) / "src"
    if src_path.exists():
        s = str(src_path)
        if s not in sys.path:
            sys.path.insert(0, s)

DISCOVER_PACKAGES: List[str] = [__PACKAGES_LIST__]
ENV_DISCOVER = os.getenv("ALEMBIC_DISCOVER_PACKAGES")
if ENV_DISCOVER:
    DISCOVER_PACKAGES = [s.strip() for s in ENV_DISCOVER.split(',') if s.strip()]

def _collect_metadata() -> list[object]:
    # 0) Prefer ModelBase.metadata
    try:
        from svc_infra.db.setup.base import ModelBase  # type: ignore
        md = getattr(ModelBase, "metadata", None)
        if md is not None and hasattr(md, "tables") and md.tables:
            return [md]
    except Exception as e:
        logger.debug("ModelBase not available or empty: %s", e)

    # 1) Fallback discovery (same as sync)
    import importlib, pkgutil, pathlib
    found: list[object] = []

    def _maybe_add(obj: object) -> None:
        md = getattr(obj, "metadata", None) or obj
        if hasattr(md, "tables") and hasattr(md, "schema"):
            found.append(md)

    pkgs = list(DISCOVER_PACKAGES)
    if not pkgs:
        roots = []
        if prepend:
            roots.append(pathlib.Path(prepend))
            roots.append(pathlib.Path(prepend) / "src")
        for root in roots:
            if not root or not root.exists():
                continue
            for p in root.iterdir():
                if p.is_dir() and (p / "__init__.py").exists():
                    pkgs.append(p.name)

    for pkg_name in pkgs:
        try:
            pkg = importlib.import_module(pkg_name)
        except Exception as e:
            logger.debug("Failed to import %s: %s", pkg_name, e)
            continue

        for attr in ("metadata", "MetaData", "Base", "base"):
            obj = getattr(pkg, attr, None)
            if obj is not None:
                _maybe_add(obj)

        for subname in ("models",):
            try:
                sub = importlib.import_module(f"{pkg_name}.{subname}")
                for attr in ("metadata", "MetaData", "Base", "base"):
                    obj = getattr(sub, attr, None)
                    if obj is not None:
                        _maybe_add(obj)
            except Exception:
                pass

        mod_path = getattr(pkg, "__path__", None)
        if not mod_path:
            continue
        for _, name, ispkg in pkgutil.walk_packages(mod_path, prefix=pkg_name + "."):
            if ispkg or not any(x in name for x in (".models", ".db", ".orm", ".entities")):
                continue
            try:
                mod = importlib.import_module(name)
            except Exception:
                continue
            for attr in ("metadata", "MetaData", "Base", "base"):
                obj = getattr(mod, attr, None)
                if obj is not None:
                    _maybe_add(obj)

    uniq, seen = [], set()
    for md in found:
        if id(md) not in seen:
            seen.add(id(md))
            uniq.append(md)
    return uniq

target_metadata = _collect_metadata()

def _ensure_ssl_default(url_str: str) -> str:
    u = make_url(url_str)
    backend = (u.get_backend_name() or "").lower()
    if backend not in ("postgresql", "postgres"):
        return url_str
    # asyncpg wants 'ssl=true' via SQLAlchemy param
    if any(k in u.query for k in ("ssl", "sslmode", "sslrootcert", "sslcert", "sslkey")):
        return url_str
    return str(u.set(query={**u.query, "ssl": "true"}))

def _coerce_to_async_url(url_str: str) -> str:
    low = url_str.lower()
    if "+asyncpg" in low or "+aiomysql" in low or "+aiosqlite" in low:
        return url_str
    if low.startswith("postgresql+psycopg2://") or low.startswith("postgresql+psycopg://"):
        return "postgresql+asyncpg://" + url_str.split("://", 1)[1]
    if low.startswith("postgresql://") or low.startswith("postgres://"):
        return "postgresql+asyncpg://" + url_str.split("://", 1)[1]
    if low.startswith("mysql+pymysql://") or low.startswith("mysql://"):
        return "mysql+aiomysql://" + url_str.split("://", 1)[1]
    if low.startswith("sqlite://") and not low.startswith("sqlite+aiosqlite://"):
        return "sqlite+aiosqlite://" + url_str.split("://", 1)[1]
    return url_str

env_db_url = os.getenv("DATABASE_URL")
if env_db_url:
    coerced = _ensure_ssl_default(_coerce_to_async_url(env_db_url))
    config.set_main_option("sqlalchemy.url", coerced)

def _do_run_migrations(connection):
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        compare_type=True,
        compare_server_default=True,
        include_schemas=True,
    )
    with context.begin_transaction():
        context.run_migrations()

async def run_migrations_online() -> None:
    url = config.get_main_option("sqlalchemy.url")
    connectable = create_async_engine(url)
    async with connectable.connect() as connection:
        await connection.run_sync(_do_run_migrations)
    await connectable.dispose()

if context.is_offline_mode():
    raise SystemExit("Run offline migrations with a sync env.py or set offline to False.")
else:
    import asyncio as _asyncio
    _asyncio.run(run_migrations_online())