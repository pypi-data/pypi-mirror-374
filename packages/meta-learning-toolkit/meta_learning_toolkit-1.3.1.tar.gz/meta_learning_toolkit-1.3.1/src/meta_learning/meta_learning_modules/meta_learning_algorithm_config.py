"""
Meta-Learning Algorithm Configuration System

Configuration system for meta-learning algorithms including MAML variants,
prototypical networks, uncertainty methods, and hierarchical approaches.

Provides configuration options for:
- Task adaptation methods (MAML, Fisher Information, Set2Set)
- Uncertainty quantification (Dirichlet, MC Dropout, Deep Ensembles)  
- Hierarchical attention mechanisms
- Level fusion strategies

Based on published meta-learning research.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Union, Callable, Any, Tuple
from enum import Enum
import numpy as np
from abc import ABC, abstractmethod


# ================================
# MASTER SOLUTION ENUMERATIONS
# ================================

class DatasetLoadingMethod(Enum):
    """All dataset loading solutions from cli.py and utilities.py comments"""
    TORCHMETA = "torchmeta"                    # SOLUTION 1: Research-accurate benchmarking
    TORCHVISION = "torchvision"                # SOLUTION 2: Standard datasets  
    HUGGINGFACE = "huggingface"                # SOLUTION 3: Modern datasets
    SKLEARN = "sklearn"                        # SOLUTION 2: Structured demo data
    CUSTOM_LOADER = "custom"                   # SOLUTION 3: Custom dataset loader with caching
    # REMOVED: SYNTHETIC = "synthetic" - violates no fake data policy

class PrototypicalDistanceMethod(Enum):
    """Distance computation options from few_shot_modules/configurations.py"""
    EUCLIDEAN = "euclidean"                    # SOLUTION 1: Original Snell et al. 2017
    COSINE = "cosine"                          # SOLUTION 2: Cosine similarity
    MAHALANOBIS = "mahalanobis"               # SOLUTION 3: Mahalanobis distance
    LEARNABLE = "learnable"                    # SOLUTION 4: Learnable distance metric
    UNCERTAINTY_WEIGHTED = "uncertainty"       # SOLUTION: Uncertainty-aware distance (Allen et al. 2019)

class PrototypeComputationMethod(Enum):
    """Prototype computation options from configurations.py"""
    MEAN = "mean"                              # SOLUTION 1: Simple mean (original)
    WEIGHTED_MEAN = "weighted_mean"            # SOLUTION 2: Support-size weighted
    ATTENTION_POOLING = "attention"            # SOLUTION 3: Attention-based pooling
    HIERARCHICAL = "hierarchical"              # SOLUTION: Hierarchical structures (Rusu et al. 2019)
    TASK_ADAPTIVE = "task_adaptive"            # SOLUTION: Task-specific initialization (Finn et al. 2018)

class HierarchicalAttentionMethod(Enum):
    """Hierarchical attention solutions from hierarchical_components.py"""
    PROTOTYPE_ATTENTION = "prototype"          # SOLUTION 1: Prototype attention (Vinyals et al. 2016)
    FEATURE_POOLING = "pooling"               # SOLUTION 2: Hierarchical feature pooling (Lin et al. 2017)  
    CLUSTERING_SELECTION = "clustering"        # SOLUTION 3: Prototype selection via clustering
    DISTANCE_WEIGHTING = "distance"           # SOLUTION 4: Distance-based hierarchical weighting

class LevelFusionMethod(Enum):
    """Level fusion solutions from hierarchical_components.py"""
    INFORMATION_THEORETIC = "info_theoretic"  # SOLUTION 1: Information-theoretic weighting
    LEARNED_ATTENTION = "learned"             # SOLUTION 2: Learned attention weights (Bahdanau et al. 2015)
    ENTROPY_WEIGHTED = "entropy"              # SOLUTION 3: Entropy-weighted fusion (Shannon 1948)
    BAYESIAN_AVERAGING = "bayesian"           # SOLUTION 4: Hierarchical Bayesian averaging (MacKay 1992)

class TaskAdaptationMethod(Enum):
    """Task adaptation solutions from adaptive_components.py"""
    MAML_STYLE = "maml"                       # SOLUTION 1: MAML-style context encoding
    TASK_STATISTICS = "statistics"            # SOLUTION 2: Task statistics (Hospedales et al. 2020)
    SUPPORT_QUERY_INTERACTION = "interaction" # SOLUTION 3: Support-query interaction (Relation Networks)
    FISHER_INFORMATION = "fisher"             # SOLUTION 1: Fisher information context (Ravi & Larochelle 2017)
    SET2SET_EMBEDDING = "set2set"             # SOLUTION 2: Set2Set embedding (Vinyals et al. 2015)
    RELATIONAL_CONTEXT = "relational"        # SOLUTION 3: Relational context (Sung et al. 2018)

class UncertaintyMethod(Enum):
    """Uncertainty computation solutions from uncertainty_components.py"""
    DIRICHLET = "dirichlet"                   # SOLUTION 1: Dirichlet uncertainty (Sensoy et al. 2018)
    EPISTEMIC_ALEATORIC = "epistemic"         # SOLUTION 2: Epistemic + Aleatoric (Amini et al. 2020)
    SUBJECTIVE_LOGIC = "subjective"           # SOLUTION 3: Subjective logic (J√∏sang 2016)
    RESEARCH_ACCURATE = "research"            # SOLUTION 4: Research-accurate per-class handling
    VARIATIONAL_DROPOUT = "variational"      # SOLUTION 2: Variational dropout (Kingma et al. 2015)
    KL_DIVERGENCE = "kl_divergence"          # SOLUTION 1: Blundell et al. 2015 KL divergence

class LoRAImplementationMethod(Enum):
    """LoRA implementation solutions from maml_variants.py"""
    FORWARD_HOOKS = "hooks"                   # SOLUTION 1: Forward hook-based injection
    PARAMETER_REPLACEMENT = "replacement"     # SOLUTION 2: Parameter replacement method
    CUSTOM_FORWARD = "custom"                 # SOLUTION 3: Custom forward implementation
    PEFT_LIBRARY = "peft"                     # SOLUTION 4: HuggingFace PEFT library

class FunctionalForwardMethod(Enum):
    """Functional forward solutions from maml_variants.py"""
    LEARN2LEARN = "learn2learn"               # Research method: learn2learn-style stateful cloning
    HIGHER_LIBRARY = "higher"                 # Research method: higher-library-style functional
    MANUAL_FUNCTIONAL = "manual"              # Research method: Manual functional implementation
    PYTORCH_COMPILE = "compile"               # Research method: PyTorch 2.0+ compile-optimized

class TestTimeComputeMethod(Enum):
    """Test-time compute solutions from test_time_compute.py"""
    PROCESS_REWARD_MODEL = "prm"              # SOLUTION 1: Process-based reward model
    TEST_TIME_TRAINING = "ttt"                # SOLUTION 2: Test-time training
    CHAIN_OF_THOUGHT = "cot"                  # SOLUTION 3: Chain-of-thought reasoning
    SNELL_2024 = "snell_2024"                # Snell et al. 2024 implementation
    GRADIENT_BASED = "gradient"               # Gradient-based verification
    CONSISTENCY_BASED = "consistency"        # Consistency-based verification

class ChainOfThoughtMethod(Enum):
    """Chain-of-thought solutions from test_time_compute.py"""
    WEI_2022 = "wei_2022"                     # SOLUTION 2: Wei et al. 2022 CoT
    KOJIMA_2022 = "kojima_2022"               # SOLUTION 3: Kojima et al. 2022 CoT
    CONSTITUTIONAL = "constitutional"          # Constitutional AI approach

class DifficultyEstimationMethod(Enum):
    """Difficulty estimation from utils and fixme_solutions_config.py"""
    SILHOUETTE = "silhouette"                 # SOLUTION 1: Silhouette analysis (Rousseeuw 1987)
    ENTROPY = "entropy"                       # SOLUTION 2: Feature entropy
    KNN_ACCURACY = "knn"                      # SOLUTION 3: k-NN classification accuracy
    VARIANCE = "variance"                     # Task-agnostic diversity using feature variance

class ConfidenceIntervalMethod(Enum):
    """Confidence interval solutions from old_archive/utils_original_1632_lines.py"""
    T_DISTRIBUTION = "t_dist"                 # Research method: t-distribution for small samples
    META_LEARNING_STANDARD = "meta_standard"  # Research method: Meta-learning standard evaluation
    BCA_BOOTSTRAP = "bca"                     # Research method: BCa Bootstrap
    BOOTSTRAP = "bootstrap"                   # Bootstrap resampling

class TaskDiversityMethod(Enum):
    """Task diversity solutions from factory_functions.py"""
    FEATURE_VARIANCE = "variance"             # SOLUTION 1: Feature variance diversity (Chen et al. 2020)
    CLASS_SEPARATION = "separation"          # SOLUTION 2: Class separation metric (Rousseeuw 1987)
    INFORMATION_THEORETIC_DIV = "info_div"   # SOLUTION 3: Information-theoretic diversity
    JENSEN_SHANNON = "js_divergence"         # SOLUTION 4: Jensen-Shannon divergence


# ================================
# CONFIGURATION CLASSES
# ================================

@dataclass
class DatasetLoadingConfig:
    """Configuration for all dataset loading solutions"""
    method: DatasetLoadingMethod = DatasetLoadingMethod.TORCHMETA
    fallback_chain: List[DatasetLoadingMethod] = field(default_factory=lambda: [
        DatasetLoadingMethod.TORCHMETA,
        DatasetLoadingMethod.TORCHVISION,
        DatasetLoadingMethod.HUGGINGFACE
    ])
    
    # torchmeta options
    torchmeta_root: str = "./data"
    torchmeta_download: bool = True
    meta_split: str = "train"
    
    # torchvision options
    torchvision_root: str = "./data"
    torchvision_download: bool = True
    torchvision_train: bool = True
    
    # huggingface options
    hf_split: str = "train"
    hf_streaming: bool = False
    
    # sklearn options
    n_informative: int = 100
    n_redundant: int = 50
    class_sep: float = 1.5
    
    # custom loader options
    use_caching: bool = True
    cache_dir: str = "./cache"
    
    # synthetic options (only if explicitly enabled)
    allow_synthetic: bool = False
    require_user_confirmation: bool = True
    synthetic_seed: int = 42

@dataclass  
class PrototypicalNetworksConfig:
    """Configuration for all Prototypical Networks solutions"""
    distance_method: PrototypicalDistanceMethod = PrototypicalDistanceMethod.EUCLIDEAN
    prototype_method: PrototypeComputationMethod = PrototypeComputationMethod.MEAN
    
    # Distance method specific options
    learnable_distance_dim: int = 64
    mahalanobis_regularization: float = 1e-4
    uncertainty_weighting_factor: float = 0.1
    
    # Prototype computation options
    attention_heads: int = 8
    attention_dim: int = 64
    weighted_by_support_size: bool = False
    
    # Hierarchical options
    hierarchy_levels: int = 3
    hierarchical_attention: HierarchicalAttentionMethod = HierarchicalAttentionMethod.PROTOTYPE_ATTENTION
    level_fusion: LevelFusionMethod = LevelFusionMethod.INFORMATION_THEORETIC
    
    # Task adaptation options
    enable_task_adaptation: bool = False
    task_adaptation: TaskAdaptationMethod = TaskAdaptationMethod.MAML_STYLE

@dataclass
class UncertaintyConfig:
    """Configuration for all uncertainty estimation solutions"""
    method: UncertaintyMethod = UncertaintyMethod.DIRICHLET
    
    # Dirichlet options
    evidence_regularization: float = 1e-2
    dirichlet_strength: float = 1.0
    
    # Epistemic/Aleatoric options
    enable_epistemic: bool = True
    enable_aleatoric: bool = True
    
    # Variational options
    dropout_rate: float = 0.1
    kl_weight: float = 1e-4
    
    # Distance-based uncertainty
    uncertainty_distance_method: str = "evidence_weighted"

@dataclass
class MAMLVariantsConfig:
    """Configuration for all MAML variant solutions"""
    lora_method: LoRAImplementationMethod = LoRAImplementationMethod.PARAMETER_REPLACEMENT
    functional_forward: FunctionalForwardMethod = FunctionalForwardMethod.HIGHER_LIBRARY
    
    # LoRA options
    lora_rank: int = 8
    lora_alpha: float = 32.0
    lora_dropout: float = 0.1
    target_modules: List[str] = field(default_factory=lambda: ["c_attn", "c_proj"])
    
    # Functional forward options
    create_graph: bool = True
    allow_unused: bool = True
    use_torch_compile: bool = False

@dataclass
class TestTimeComputeConfig:
    """Configuration for all test-time compute solutions"""
    scaling_method: TestTimeComputeMethod = TestTimeComputeMethod.PROCESS_REWARD_MODEL
    cot_method: ChainOfThoughtMethod = ChainOfThoughtMethod.WEI_2022
    process_reward_method: str = "snell_2024"  # For research-accurate process rewards
    
    # Chain-of-thought options
    enable_self_consistency: bool = True
    num_reasoning_chains: int = 5
    reasoning_temperature: float = 0.7
    
    # Process reward options
    verification_steps: int = 3
    confidence_threshold: float = 0.85
    max_compute_budget: int = 50
    
    # Test-time training options
    ttt_lr: float = 1e-4
    ttt_steps: int = 10

@dataclass
class UtilitiesConfig:
    """Configuration for all utility function solutions"""
    difficulty_estimation: DifficultyEstimationMethod = DifficultyEstimationMethod.SILHOUETTE
    confidence_interval: ConfidenceIntervalMethod = ConfidenceIntervalMethod.BCA_BOOTSTRAP
    task_diversity: TaskDiversityMethod = TaskDiversityMethod.FEATURE_VARIANCE
    
    # Difficulty estimation options
    knn_neighbors: int = 5
    normalize_features: bool = True
    
    # Confidence interval options
    ci_alpha: float = 0.05
    bootstrap_samples: int = 1000
    
    # Task diversity options
    diversity_threshold: float = 0.5

@dataclass
class ComprehensiveCommentSolutionsConfig:
    """Master configuration containing ALL solutions from code comments"""
    dataset_loading: DatasetLoadingConfig = field(default_factory=DatasetLoadingConfig)
    prototypical_networks: PrototypicalNetworksConfig = field(default_factory=PrototypicalNetworksConfig)
    uncertainty: UncertaintyConfig = field(default_factory=UncertaintyConfig)
    maml_variants: MAMLVariantsConfig = field(default_factory=MAMLVariantsConfig)
    test_time_compute: TestTimeComputeConfig = field(default_factory=TestTimeComputeConfig)
    utilities: UtilitiesConfig = field(default_factory=UtilitiesConfig)
    
    # Global options
    enable_all_solutions: bool = False  # Enable all solutions simultaneously for comparison
    solution_comparison_mode: bool = False  # Run multiple solutions and compare results
    verbose_solution_reporting: bool = True  # Report which solutions are being used
    research_accuracy_mode: bool = True  # Prioritize research accuracy over speed


# ================================
# FACTORY FUNCTIONS FOR COMMON USE CASES
# ================================

def create_research_accurate_config() -> ComprehensiveCommentSolutionsConfig:
    """Factory: Create configuration prioritizing research accuracy"""
    config = ComprehensiveCommentSolutionsConfig()
    
    # Use most research-accurate options
    config.dataset_loading.method = DatasetLoadingMethod.TORCHMETA
    config.prototypical_networks.distance_method = PrototypicalDistanceMethod.EUCLIDEAN
    config.uncertainty.method = UncertaintyMethod.DIRICHLET
    config.maml_variants.lora_method = LoRAImplementationMethod.PEFT_LIBRARY
    config.test_time_compute.scaling_method = TestTimeComputeMethod.PROCESS_REWARD_MODEL
    config.utilities.difficulty_estimation = DifficultyEstimationMethod.SILHOUETTE
    
    config.research_accuracy_mode = True
    return config

def create_performance_optimized_config() -> ComprehensiveCommentSolutionsConfig:
    """Factory: Create configuration prioritizing performance"""
    config = ComprehensiveCommentSolutionsConfig()
    
    # Use fastest options
    config.dataset_loading.method = DatasetLoadingMethod.TORCHVISION
    config.prototypical_networks.distance_method = PrototypicalDistanceMethod.EUCLIDEAN
    config.uncertainty.method = UncertaintyMethod.RESEARCH_ACCURATE
    config.maml_variants.lora_method = LoRAImplementationMethod.FORWARD_HOOKS
    config.maml_variants.use_torch_compile = True
    config.test_time_compute.scaling_method = TestTimeComputeMethod.PROCESS_REWARD_MODEL
    
    return config

def create_comprehensive_comparison_config() -> ComprehensiveCommentSolutionsConfig:
    """Factory: Create configuration that enables multiple solutions for comparison"""
    config = ComprehensiveCommentSolutionsConfig()
    
    config.enable_all_solutions = True
    config.solution_comparison_mode = True
    config.verbose_solution_reporting = True
    
    return config

def create_hierarchical_prototype_config() -> ComprehensiveCommentSolutionsConfig:
    """Factory: Create configuration focusing on hierarchical prototype solutions"""
    config = ComprehensiveCommentSolutionsConfig()
    
    config.prototypical_networks.prototype_method = PrototypeComputationMethod.HIERARCHICAL
    config.prototypical_networks.hierarchical_attention = HierarchicalAttentionMethod.CLUSTERING_SELECTION
    config.prototypical_networks.level_fusion = LevelFusionMethod.BAYESIAN_AVERAGING
    config.prototypical_networks.enable_task_adaptation = True
    config.prototypical_networks.task_adaptation = TaskAdaptationMethod.FISHER_INFORMATION
    
    return config

def create_uncertainty_focused_config() -> ComprehensiveCommentSolutionsConfig:
    """Factory: Create configuration focusing on uncertainty estimation solutions"""
    config = ComprehensiveCommentSolutionsConfig()
    
    config.uncertainty.method = UncertaintyMethod.EPISTEMIC_ALEATORIC
    config.uncertainty.enable_epistemic = True
    config.uncertainty.enable_aleatoric = True
    config.prototypical_networks.distance_method = PrototypicalDistanceMethod.UNCERTAINTY_WEIGHTED
    config.utilities.confidence_interval = ConfidenceIntervalMethod.BCA_BOOTSTRAP
    
    return config

def create_test_time_compute_config() -> ComprehensiveCommentSolutionsConfig:
    """Factory: Create configuration focusing on test-time compute solutions"""
    config = ComprehensiveCommentSolutionsConfig()
    
    config.test_time_compute.scaling_method = TestTimeComputeMethod.CHAIN_OF_THOUGHT
    config.test_time_compute.cot_method = ChainOfThoughtMethod.WEI_2022
    config.test_time_compute.enable_self_consistency = True
    config.test_time_compute.process_reward_method = "snell_2024"
    
    return config


# ================================
# VALIDATION FUNCTIONS
# ================================

def validate_config(config: ComprehensiveCommentSolutionsConfig) -> List[str]:
    """Validate configuration and return list of warnings/errors"""
    warnings = []
    
    # REMOVED: Synthetic data validation - synthetic data is now completely prohibited
    
    # Check for incompatible combinations
    if (config.prototypical_networks.distance_method == PrototypicalDistanceMethod.UNCERTAINTY_WEIGHTED and
        config.uncertainty.method == UncertaintyMethod.RESEARCH_ACCURATE):
        warnings.append("‚ö†Ô∏è  Uncertainty-weighted distance requires uncertainty estimation method")
    
    # Check for performance vs accuracy tradeoffs
    if (config.research_accuracy_mode and 
        config.dataset_loading.method != DatasetLoadingMethod.TORCHMETA):
        warnings.append("‚ö†Ô∏è  Research accuracy mode recommends torchmeta for benchmarking")
    
    return warnings

def print_active_solutions(config: ComprehensiveCommentSolutionsConfig):
    """Print summary of which solutions are active"""
    print("üîß Active Comment Solutions Configuration:")
    print("=" * 50)
    print(f"üìä Dataset Loading: {config.dataset_loading.method.value}")
    print(f"üéØ Prototypical Distance: {config.prototypical_networks.distance_method.value}")  
    print(f"üéØ Prototype Computation: {config.prototypical_networks.prototype_method.value}")
    print(f"üîÆ Uncertainty Method: {config.uncertainty.method.value}")
    print(f"üß† LoRA Implementation: {config.maml_variants.lora_method.value}")
    print(f"‚ö° Test-Time Compute: {config.test_time_compute.scaling_method.value}")
    print(f"üìà Difficulty Estimation: {config.utilities.difficulty_estimation.value}")
    print(f"üìä Confidence Intervals: {config.utilities.confidence_interval.value}")
    
    if config.enable_all_solutions:
        print("üåü ALL SOLUTIONS MODE: Multiple implementations will be compared")
    
    if config.research_accuracy_mode:
        print("üî¨ RESEARCH ACCURACY MODE: Prioritizing research fidelity")
    
    print("=" * 50)


# ================================
# ================================

class SolutionRegistry:
    """Registry for all implemented solutions from code comments"""
    
    def __init__(self):
        self.implementations = {
            # Dataset loading solutions
            'dataset_torchmeta': 'load_few_shot_dataset_torchmeta',
            'dataset_torchvision': 'load_few_shot_dataset_torchvision', 
            'dataset_huggingface': 'load_few_shot_dataset_huggingface',
            'dataset_sklearn': 'load_few_shot_dataset_sklearn',
            # REMOVED: 'dataset_synthetic' - violates no fake data policy
            
            # Prototypical Networks solutions
            'proto_euclidean': 'compute_euclidean_distance',
            'proto_cosine': 'compute_cosine_distance',
            'proto_mahalanobis': 'compute_mahalanobis_distance',
            'proto_uncertainty': 'compute_uncertainty_weighted_distance',
            
            # Uncertainty solutions
            'uncertainty_dirichlet': 'compute_dirichlet_uncertainty',
            'uncertainty_epistemic': 'compute_epistemic_uncertainty',
            'uncertainty_variational': 'compute_variational_uncertainty',
            
            # Test-time compute solutions
            'ttc_process_reward': 'scale_compute_with_process_reward',
            'ttc_chain_of_thought': 'scale_compute_with_cot',
            'ttc_test_time_training': 'scale_compute_with_ttt',
            
            # And many more...
        }
    
    def get_implementation(self, solution_key: str) -> str:
        """Get implementation function name for a solution"""
        return self.implementations.get(solution_key, "not_implemented")
    
    def list_available_solutions(self) -> List[str]:
        """List all available solution implementations"""
        return list(self.implementations.keys())

# Global registry instance
SOLUTION_REGISTRY = SolutionRegistry()


if __name__ == "__main__":
    # Example usage demonstrating configuration system
    print("üöÄ Comprehensive Comment Solutions Configuration System")
    print("=" * 60)
    
    # Create different configuration styles
    configs = {
        "Research Accurate": create_research_accurate_config(),
        "Performance Optimized": create_performance_optimized_config(),
        "Hierarchical Focus": create_hierarchical_prototype_config(),
        "Uncertainty Focus": create_uncertainty_focused_config(),
        "Test-Time Compute": create_test_time_compute_config()
    }
    
    for name, config in configs.items():
        print(f"\nüìã {name} Configuration:")
        print("-" * 30)
        print_active_solutions(config)
        
        warnings = validate_config(config)
        if warnings:
            print("‚ö†Ô∏è  Configuration Warnings:")
            for warning in warnings:
                print(f"  {warning}")
    
    print("\n‚úÖ All comment solutions are now configurable!")
    print("Users can pick and choose from all available implementations.")