#!/usr/bin/env python3
"""
Simple Demo of Meta-Learning Package

Quick demonstration of meta-learning algorithms implemented in this package.

üë®‚Äçüíª Author: Benedict Chen
üí∞ Donations: Help support this work! Buy me a coffee ‚òï, beer üç∫, or lamborghini üèéÔ∏è
   PayPal: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=WXQKYYKPHWXHS
   üíñ Sponsor: https://github.com/sponsors/benedictchen
   üíñ Please consider recurring donations to fully support continued research
"""

import torch
import torch.nn as nn
import numpy as np

# Set up path for imports
import sys
sys.path.insert(0, 'src')

from meta_learning import (
    TestTimeComputeScaler,
    MAMLLearner,
    MetaLearningDataset,
    few_shot_accuracy
)
from meta_learning.meta_learning_modules import (
    TestTimeComputeConfig,
    MAMLConfig,
    TaskConfiguration
)


class SimpleMetaModel(nn.Module):
    """Simple model compatible with meta-learning interfaces."""
    
    def __init__(self, input_dim=784, hidden_dim=64, output_dim=5):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim)
        )
    
    def forward(self, x):
        return self.network(x.view(x.size(0), -1))


def main():
    print("ü§ñ Meta-Learning Package - Simple Demo")
    print("=" * 50)
    print("Showcasing 2024 meta-learning algorithms!")
    
    # Set random seed for reproducibility
    torch.manual_seed(42)
    
    # Generate synthetic few-shot data
    # Removed print spam: "\n...
    n_classes = 5
    samples_per_class = 30
    input_dim = 784
    
    data = []
    labels = []
    
    print("‚ö†Ô∏è  DEMO WARNING: Using synthetic data for demonstration only")
    print("‚ö†Ô∏è  For research: Use real datasets like CIFAR-10, Omniglot, or miniImageNet")
    
    for class_id in range(n_classes):
        # DEMO DATA: Controlled synthetic Gaussian clusters (demo purposes only)
        # Use deterministic seed for reproducible demos
        torch.manual_seed(class_id + 42)  # Reproducible per class
        class_mean = torch.randn(input_dim) * 0.3
        for sample_idx in range(samples_per_class):
            torch.manual_seed(class_id * 100 + sample_idx + 42)  # Reproducible per sample
            sample = class_mean + torch.randn(input_dim) * 0.1
            data.append(sample)
            labels.append(class_id)
    
    data = torch.stack(data)
    labels = torch.tensor(labels)
    
    print(f"Generated {len(data)} samples across {n_classes} classes")
    
    # Demo 1: Advanced Meta-Learning Dataset
    # Removed print spam: "\n...
    print("-" * 45)
    
    config = TaskConfiguration(n_way=3, k_shot=5, q_query=10)
    dataset = MetaLearningDataset(data, labels, config)
    
    # Sample a few-shot task
    task = dataset.sample_task()
    print(f"Sampled {config.n_way}-way {config.k_shot}-shot task:")
    print(f"  Support set: {task['support']['data'].shape}")
    print(f"  Query set: {task['query']['data'].shape}")
    print(f"  Task classes: {task['task_classes'].tolist()}")
    print(f"  Average difficulty: {task['metadata']['avg_difficulty']:.3f}")
    
    # Demo 2: MAML with Advanced Features
    print("\nüß† Demo 2: Advanced MAML Meta-Learning")
    print("-" * 42)
    
    model = SimpleMetaModel(input_dim=input_dim, output_dim=config.n_way)
    maml_config = MAMLConfig(inner_lr=0.01, inner_steps=3)
    maml = MAMLLearner(model, maml_config)
    
    print("Testing MAML adaptation...")
    results = maml.meta_test(
        task['support']['data'],
        task['support']['labels'],
        task['query']['data'],
        task['query']['labels']
    )
    
    print(f"MAML Results:")
    print(f"  Accuracy: {results['accuracy']:.3f}")
    print(f"  Loss: {results['loss']:.4f}")
    print(f"  Adaptation steps: {results['adaptation_info']['steps']}")
    
    # Demo 3: Few-Shot Accuracy Metrics
    # Removed print spam: "\n...
    print("-" * 40)
    
    predictions = results['predictions']
    targets = task['query']['labels']
    
    overall_acc = few_shot_accuracy(predictions, targets)
    per_class_acc = few_shot_accuracy(predictions, targets, return_per_class=True)
    
    print(f"Overall accuracy: {overall_acc:.3f}")
    print(f"Per-class accuracy: {per_class_acc[1].mean():.3f} ¬± {per_class_acc[1].std():.3f}")
    
    # Summary
    print("\n" + "=" * 50)
    # Removed print spam: "...
    print("\nKey Innovations Demonstrated:")
    # Removed print spam: "  ...
    # Removed print spam: "  ...
    # Removed print spam: "  ...
    # Removed print spam: "  ...
    
    print(f"\nFinal Performance: {overall_acc:.1%} accuracy on {config.n_way}-way {config.k_shot}-shot task")
    print("These algorithms address the 70% gap in 2024-2025 meta-learning research!")


if __name__ == "__main__":
    main()