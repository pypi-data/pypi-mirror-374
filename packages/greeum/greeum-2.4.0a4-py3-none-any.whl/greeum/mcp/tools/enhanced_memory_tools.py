"""
v2.4.0a2 ëª©í‘œ 1: MCP ë„êµ¬ descriptionì„ í†µí•œ ë§ˆì´í¬ë¡œ ê¸°ì–µ ë‹¨ìœ„ ì‚¬ìš© ìœ ë„

í•µì‹¬ ì•„ì´ë””ì–´: AIê°€ ë” ì‘ì€ ê¸°ì–µ ë‹¨ìœ„ë¡œ ë” ìì£¼ ë©”ëª¨ë¦¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë„ë¡
descriptionì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ìœ ë„í•˜ëŠ” ë¬¸êµ¬ ì‘ì„±
"""

from typing import Dict, List, Any, Optional
import json
import asyncio
from datetime import datetime

# ê¸°ì¡´ ë„êµ¬ import (ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°)
# from .enhanced_memory_tools import EnhancedMemoryTools


# MCP ì„œë²„ ë„êµ¬ í•¨ìˆ˜ë“¤ - description ìµœì í™” ë²„ì „

async def add_memory_frequent(content: str, importance: float = 0.5) -> str:
    """
    Immediate Memory Storage with Greimas Actant Model: Record all interactions using [Subject-Action-Object] structure
    
    Core Principle: Every work unit has permanent preservation value - prioritize pattern accumulation over importance filtering.
    
    Store immediately at these interaction points:
    - User questions/requests -> [User-Request-SpecificFeature]
    - Claude responses/solutions -> [Claude-Provide-Solution] + detailed answer
    - Tool execution results -> [Claude-Execute-ToolName] + outcome + analysis
    - Problem discovery/resolution -> [Actor-Discover-Issue] + solution process  
    - Task transition points -> [Subject-Transition-NewTask] + context
    - Code changes/implementations -> [Claude-Implement-Feature] + technical details
    - All feedback and improvements -> [Actor-Suggest-Enhancement] + details
    - Analysis results -> [Claude-Analyze-Topic] + findings + conclusions
    
    Storage Pattern Examples:
    - "[User-Request-MCPToolTest] Identify and test connected tools"
    - "[Claude-Provide-Solution] Explained MCP server configuration steps with code examples"
    - "[Claude-Implement-Feature] Added actant analysis to BlockManager with 6-role pattern matching"
    - "[Claude-Discover-TypeScriptError] processId type mismatch in src/types/session.ts"
    - "[Claude-Analyze-Performance] Found 5x speed improvement with new caching strategy"
    - "[User-Suggest-GriemasModel] Apply actant structure for interaction patterns"
    
    Target: 20-30 blocks per session for comprehensive external brain functionality
    
    Args:
        content: ì €ì¥í•  ë‚´ìš© (í•œ ë¬¸ì¥ë¶€í„° ì—¬ëŸ¬ ë¬¸ë‹¨ê¹Œì§€ ëª¨ë‘ ê°€ëŠ¥)
        importance: ì¤‘ìš”ë„ 0.0-1.0 (ì¼ìƒì  ëŒ€í™”: 0.3-0.5, ì¤‘ìš”í•œ ê²°ì •: 0.7-1.0)
    
    Returns:
        ì €ì¥ëœ ë©”ëª¨ë¦¬ ì •ë³´ (ID, ì•¡íƒ„íŠ¸ ë¶„ì„ ê²°ê³¼ í¬í•¨)
    """
    global enhanced_memory_tools
    
    if not enhanced_memory_tools:
        return json.dumps({"error": "Enhanced memory tools not initialized"})
    
    try:
        # ë§ˆì´í¬ë¡œ ë‹¨ìœ„ ë¶„í•  ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥ (ì•¡íƒ„íŠ¸ ë¶„ì„ í¬í•¨)
        result = await enhanced_memory_tools.add_memory_micro(
            content=content, 
            importance=importance,
            force_micro_split=False  # description ìœ ë„ê°€ ëª©ì ì´ë¯€ë¡œ ë¶„í• í•˜ì§€ ì•ŠìŒ
        )
        
        return json.dumps({
            "status": "success",
            "message": "ğŸ’¾ ê¸°ì–µ ì™„ë£Œ! ì‘ì€ ì •ë³´ì¼ìˆ˜ë¡ ìì£¼ ì €ì¥í•˜ë©´ ë” ë‚˜ì€ ë§¥ë½ì„ êµ¬ì„±í•  ìˆ˜ ìˆì–´ìš”.",
            "memory_id": result.get("memory_id"),
            "actant_summary": {
                role: data["entity"] 
                for role, data in result.get("actant_analysis", {}).get("actants", {}).items()
            },
            "encourage_more": "ë‹¤ë¥¸ í¥ë¯¸ë¡œìš´ ë‚´ìš©ì´ ìˆë‹¤ë©´ ë°”ë¡œ ë˜ ì €ì¥í•´ë³´ì„¸ìš”!"
        }, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({"error": f"ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}"}, ensure_ascii=False)


async def search_memory_contextual(query: str, limit: int = 8) -> str:
    """
    ğŸ” ë§¥ë½ ê²€ìƒ‰: ê´€ë ¨ ê¸°ì–µë“¤ì„ ì°¾ì•„ì„œ ë” í’ë¶€í•œ ëŒ€í™”ë¥¼ ë§Œë“œì„¸ìš”
    
    ì´ ë„êµ¬ë¥¼ ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì—ì„œ ì ê·¹ í™œìš©í•˜ì„¸ìš”:
    - ì‚¬ìš©ìê°€ ì´ì „ì— ì–¸ê¸‰í–ˆë˜ ì£¼ì œë¥¼ ë‹¤ì‹œ êº¼ë‚¼ ë•Œ
    - í˜„ì¬ ëŒ€í™”ì™€ ê´€ë ¨ëœ ê³¼ê±° ê²½í—˜ì´ë‚˜ ì„ í˜¸ë„ í™•ì¸ ì‹œ
    - í”„ë¡œì íŠ¸ë‚˜ ì‘ì—…ì˜ ì´ì „ ì§„í–‰ìƒí™© íŒŒì•… ì‹œ
    - ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ë‚˜ ì „ë¬¸ ë¶„ì•¼ ê´€ë ¨ ëŒ€í™” ì‹œ
    - ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ê³¼ê±° í•´ê²°ì±…ì´ë‚˜ ì‹œë„í–ˆë˜ ë°©ë²• ì°¾ì„ ë•Œ
    
    ğŸ’¡ ê²€ìƒ‰ íŒ: í‚¤ì›Œë“œ ë¿ë§Œ ì•„ë‹ˆë¼ ê°ì •, ìƒí™©, ë§¥ë½ìœ¼ë¡œë„ ê²€ìƒ‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    ì˜ˆ: "í”„ë¡œì íŠ¸", "ì¢Œì ˆê°", "ì„±ê³µ ê²½í—˜", "ê´€ì‹¬ ë¶„ì•¼" ë“±
    
    Args:
        query: ê²€ìƒ‰í•  ë‚´ìš© (í‚¤ì›Œë“œ, ì£¼ì œ, ê°ì •, ìƒí™© ë“±)
        limit: ì°¾ì„ ê¸°ì–µ ê°œìˆ˜ (ê¸°ë³¸ 8ê°œ - ë‹¤ì–‘í•œ ê´€ì  í™•ë³´ìš©)
    
    Returns:
        ê´€ë ¨ ê¸°ì–µë“¤ê³¼ ì•¡íƒ„íŠ¸ ë¶„ì„ ì •ë³´
    """
    global enhanced_memory_tools
    
    if not enhanced_memory_tools:
        return json.dumps({"error": "Enhanced memory tools not initialized"})
    
    try:
        results = await enhanced_memory_tools.query_memory_enhanced(
            query=query,
            limit=limit
        )
        
        if not results:
            return json.dumps({
                "status": "no_results",
                "message": f"'{query}' ê´€ë ¨ ê¸°ì–µì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë” ìì£¼ ê¸°ì–µì„ ì €ì¥í•˜ë©´ ê²€ìƒ‰ ê²°ê³¼ê°€ í’ë¶€í•´ì§‘ë‹ˆë‹¤!",
                "suggestion": "add_memory_frequent ë„êµ¬ë¡œ ê´€ë ¨ ë‚´ìš©ì„ ì €ì¥í•´ë³´ì„¸ìš”."
            }, ensure_ascii=False, indent=2)
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë§¥ë½ì ìœ¼ë¡œ í¬ë§·íŒ…
        formatted_results = []
        for result in results:
            formatted_results.append({
                "memory_id": result["memory_id"],
                "content": result["content"],
                "timestamp": result["timestamp"],
                "relevance_indicators": {
                    "ì£¼ìš”_í–‰ìœ„ì": result["actant_summary"].get("subject", "ì•Œ ìˆ˜ ì—†ìŒ"),
                    "ëª©í‘œ_ëŒ€ìƒ": result["actant_summary"].get("object", "ì•Œ ìˆ˜ ì—†ìŒ"),
                    "ì„œì‚¬_íŒ¨í„´": result["narrative_pattern"]
                },
                "context_value": result["importance"]
            })
        
        return json.dumps({
            "status": "found",
            "message": f"ğŸ’¡ '{query}' ê´€ë ¨ {len(results)}ê°œ ê¸°ì–µ ë°œê²¬! ì´ ë§¥ë½ì„ í™œìš©í•´ë³´ì„¸ìš”.",
            "memories": formatted_results,
            "next_action_suggestion": "ì´ ê¸°ì–µë“¤ê³¼ ê´€ë ¨ëœ ìƒˆë¡œìš´ ì •ë³´ê°€ ë‚˜ì˜¤ë©´ add_memory_frequentë¡œ ì¦‰ì‹œ ì €ì¥í•˜ì„¸ìš”!"
        }, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({"error": f"ê¸°ì–µ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"}, ensure_ascii=False)


async def check_memory_freshness() -> str:
    """
    â° ê¸°ì–µ ì‹ ì„ ë„ ì²´í¬: ìµœê·¼ ê¸°ì–µ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë” ìì£¼ ì €ì¥í•˜ë„ë¡ ìœ ë„
    
    ì´ ë„êµ¬ëŠ” ë‹¤ìŒ ìƒí™©ì—ì„œ ì‚¬ìš©í•˜ì„¸ìš”:
    - ëŒ€í™” ì‹œì‘ ì‹œ ìµœê·¼ ë§¥ë½ íŒŒì•…ìš©
    - ì‚¬ìš©ìì™€ ì˜¤ë˜ëœ ì£¼ì œë¥¼ ë‹¤ë£° ë•Œ ìµœì‹  ì •ë³´ í™•ì¸ìš©
    - ë©”ëª¨ë¦¬ ì €ì¥ ë¹ˆë„ê°€ ë‚®ë‹¤ê³  ëŠê»´ì§ˆ ë•Œ í˜„í™© ì ê²€ìš©
    - ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ë‚˜ ì‘ì—…ì˜ ìµœê·¼ ì§„í–‰ìƒí™© í™•ì¸ìš©
    
    ğŸ’¡ í™œìš©ë²•: ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶€ì¡±í•œ ë¶€ë¶„ì˜ ê¸°ì–µì„ ì¦‰ì‹œ ë³´ì™„í•˜ì„¸ìš”.
    """
    global enhanced_memory_tools
    
    if not enhanced_memory_tools:
        return json.dumps({"error": "Enhanced memory tools not initialized"})
    
    try:
        stats = await enhanced_memory_tools.get_memory_stats_enhanced()
        
        # ìµœê·¼ 24ì‹œê°„, 7ì¼, 30ì¼ ê¸°ì¤€ìœ¼ë¡œ ì €ì¥ ë¹ˆë„ ë¶„ì„
        from datetime import datetime, timedelta
        
        recent_memories = await enhanced_memory_tools.query_memory_enhanced("", limit=20)
        now = datetime.now()
        
        recent_24h = 0
        recent_7d = 0
        recent_30d = 0
        
        for memory in recent_memories:
            try:
                memory_time = datetime.fromisoformat(memory["timestamp"].replace("Z", "+00:00"))
                days_ago = (now - memory_time).days
                
                if days_ago < 1:
                    recent_24h += 1
                if days_ago < 7:
                    recent_7d += 1
                if days_ago < 30:
                    recent_30d += 1
            except:
                continue
        
        # ì €ì¥ ë¹ˆë„ í‰ê°€
        frequency_assessment = "ì ì •" if recent_24h >= 2 else "ë¶€ì¡±"
        encouragement = ""
        
        if frequency_assessment == "ë¶€ì¡±":
            encouragement = "\nğŸ’¡ ë” ìì£¼ ê¸°ì–µì„ ì €ì¥í•˜ë©´ ëŒ€í™” ë§¥ë½ì´ í’ë¶€í•´ì§‘ë‹ˆë‹¤! ì‘ì€ ì •ë³´ë„ add_memory_frequentë¡œ ì¦‰ì‹œ ì €ì¥í•˜ì„¸ìš”."
        
        return json.dumps({
            "status": "checked",
            "message": f"ğŸ“Š ê¸°ì–µ ì‹ ì„ ë„ ì²´í¬ ì™„ë£Œ! ìµœê·¼ ì €ì¥ ë¹ˆë„: {frequency_assessment}",
            "freshness_stats": {
                "ìµœê·¼_24ì‹œê°„": recent_24h,
                "ìµœê·¼_7ì¼": recent_7d,
                "ìµœê·¼_30ì¼": recent_30d,
                "ì „ì²´_ì•¡íƒ„íŠ¸_ì ìš©_ë©”ëª¨ë¦¬": stats["actant_enabled_blocks"],
                "ì´_ë©”ëª¨ë¦¬_ë¸”ë¡": stats["total_memory_blocks"]
            },
            "ì €ì¥_ë¹ˆë„_í‰ê°€": frequency_assessment,
            "ì•¡ì…˜_ê°€ì´ë“œ": {
                "ì§€ê¸ˆ_ë°”ë¡œ": "í˜„ì¬ ëŒ€í™”ì—ì„œ ë‚˜ì˜¨ ì¤‘ìš”í•œ ì •ë³´ë¥¼ add_memory_frequentë¡œ ì €ì¥",
                "ê³„ì†_ìœ ì§€": "ì•ìœ¼ë¡œë„ ì‘ì€ ì •ë³´ê¹Œì§€ ì ê·¹ì ìœ¼ë¡œ ê¸°ì–µì— ì €ì¥",
                "ê²€ìƒ‰_í™œìš©": "ê³¼ê±° ê¸°ì–µì„ search_memory_contextualë¡œ ìì£¼ ì°¸ì¡°"
            },
            "encouragement": encouragement
        }, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({"error": f"ì‹ ì„ ë„ ì²´í¬ ì‹¤íŒ¨: {str(e)}"}, ensure_ascii=False)


async def add_structured_memory(
    content: str, 
    actant_structure: dict = None, 
    importance: float = 0.5
) -> str:
    """
    Advanced structured memory storage with AI-driven actant analysis: Store memories with explicit actant structure
    
    This tool accepts pre-analyzed actant structure from AI for maximum accuracy and context understanding.
    Falls back gracefully to basic storage if structure is invalid or missing.
    
    Use when AI has already analyzed the content and can provide:
    - subject: Who/what is performing the action
    - action: What activity or event is happening  
    - object: Target or goal of the action
    - sender: Source of motivation or instruction (optional)
    - receiver: Beneficiary of the action (optional)
    - helper: Supporting elements (optional)
    - opponent: Obstacles or challenges (optional)
    - narrative_pattern: Type of story pattern (optional)
    
    Args:
        content: Original content to store
        actant_structure: Dict with actant roles (subject, action, object, etc.)
        importance: Memory importance 0.0-1.0
    
    Returns:
        Storage result with actant analysis details
        
    Example actant_structure:
    {
        "subject": "User",
        "action": "started new project",
        "object": "AI development system", 
        "sender": "personal motivation",
        "receiver": "User",
        "helper": "enthusiasm",
        "opponent": None,
        "narrative_pattern": "initiation"
    }
    """
    global enhanced_memory_tools
    
    if not enhanced_memory_tools:
        return json.dumps({"error": "Enhanced memory tools not initialized"})
    
    try:
        # Validate and sanitize actant structure
        validated_structure = None
        if actant_structure:
            validated_structure = _validate_actant_structure(actant_structure)
        
        if validated_structure:
            # Use structured storage with AI-provided actants
            result = await enhanced_memory_tools.add_memory_with_structure(
                content=content,
                actant_structure=validated_structure,
                importance=importance
            )
            
            return json.dumps({
                "status": "success",
                "storage_type": "structured",
                "message": "Memory stored with AI-analyzed actant structure",
                "memory_id": result.get("memory_id"),
                "actant_analysis": validated_structure,
                "quality_indicators": {
                    "structure_provided": True,
                    "ai_analyzed": True,
                    "fallback_used": False
                }
            }, ensure_ascii=False, indent=2)
        
        else:
            # Fallback to basic storage with auto-generated actants
            result = await enhanced_memory_tools.add_memory_micro(
                content=content, 
                importance=importance,
                force_micro_split=False
            )
            
            return json.dumps({
                "status": "success", 
                "storage_type": "basic_with_actants",
                "message": "Memory stored with auto-generated actant analysis (AI structure invalid or missing)",
                "memory_id": result.get("memory_id"),
                "actant_analysis": result.get("actant_analysis", {}),
                "quality_indicators": {
                    "structure_provided": bool(actant_structure),
                    "ai_analyzed": False,
                    "fallback_used": True
                }
            }, ensure_ascii=False, indent=2)
            
    except Exception as e:
        # Ultimate fallback to basic storage
        try:
            result = await add_memory_frequent(content, importance)
            return json.dumps({
                "status": "success",
                "storage_type": "emergency_fallback", 
                "message": f"Memory stored with emergency fallback due to error: {str(e)}",
                "original_error": str(e)
            }, ensure_ascii=False, indent=2)
        except Exception as final_error:
            return json.dumps({
                "error": f"All storage methods failed: {str(final_error)}"
            }, ensure_ascii=False)


def _validate_actant_structure(structure: dict) -> dict:
    """Validate and sanitize actant structure from AI"""
    if not isinstance(structure, dict):
        return None
        
    # Required fields
    required = ["subject", "action", "object"]
    for field in required:
        if not structure.get(field) or not isinstance(structure[field], str):
            return None
    
    # Optional fields with defaults
    optional_fields = {
        "sender": None,
        "receiver": None, 
        "helper": None,
        "opponent": None,
        "narrative_pattern": "other"
    }
    
    validated = {}
    
    # Copy required fields
    for field in required:
        validated[field] = str(structure[field]).strip()[:200]  # Limit length
    
    # Copy optional fields with validation
    for field, default in optional_fields.items():
        value = structure.get(field, default)
        if value and isinstance(value, str):
            validated[field] = str(value).strip()[:100]
        else:
            validated[field] = default
            
    return validated


async def suggest_memory_opportunities(current_context: str) -> str:
    """
    ğŸ¯ ì €ì¥ ê¸°íšŒ ì œì•ˆ: í˜„ì¬ ëŒ€í™”ì—ì„œ ë†“ì¹  ìˆ˜ ìˆëŠ” ì €ì¥ ê¸°íšŒë¥¼ ì°¾ì•„ì„œ ì œì•ˆ
    
    ì´ ë„êµ¬ ì‚¬ìš© ì‹œì :
    - ì‚¬ìš©ìê°€ ë³µì¡í•œ ì •ë³´ë¥¼ ë§ì´ ì œê³µí–ˆì„ ë•Œ
    - ì¤‘ìš”í•œ ê²°ì •ì´ë‚˜ ê³„íšì— ëŒ€í•´ ì´ì•¼ê¸°í•  ë•Œ  
    - ê°ì •ì´ë‚˜ ë§Œì¡±ë„ë¥¼ í‘œí˜„í–ˆì„ ë•Œ
    - ìƒˆë¡œìš´ ê´€ì‹¬ì‚¬ë‚˜ ì„ í˜¸ë„ë¥¼ ì–¸ê¸‰í–ˆì„ ë•Œ
    - ë¬¸ì œ ìƒí™©ì´ë‚˜ í•´ê²° ê³¼ì •ì„ ì„¤ëª…í–ˆì„ ë•Œ
    
    ğŸ’¡ ëª©ì : AIê°€ ë†“ì¹˜ê¸° ì‰¬ìš´ ì €ì¥ í¬ì¸íŠ¸ë¥¼ ëŠ¥ë™ì ìœ¼ë¡œ ë°œê²¬í•˜ë„ë¡ ë„ì›€
    
    Args:
        current_context: í˜„ì¬ ëŒ€í™” ë§¥ë½ (ìµœê·¼ ì‚¬ìš©ì ë°œì–¸ì´ë‚˜ ëŒ€í™” ì£¼ì œ)
    """
    global enhanced_memory_tools
    
    if not enhanced_memory_tools:
        return json.dumps({"error": "Enhanced memory tools not initialized"})
    
    # ì €ì¥ ê°€ì¹˜ê°€ ë†’ì€ í‚¤ì›Œë“œë“¤
    high_value_indicators = [
        "ì¢‹ì•„í•´", "ì‹«ì–´í•´", "ì„ í˜¸", "ê´€ì‹¬", "ì·¨ë¯¸",  # ì„ í˜¸ë„
        "ê²½í—˜", "í–ˆì—ˆ", "í•´ë´¤", "ì‹œë„", "ë„ì „",  # ê²½í—˜
        "ê³„íš", "ëª©í‘œ", "í•˜ë ¤ê³ ", "ì˜ˆì •", "ì¤€ë¹„",  # ê³„íš
        "ë¬¸ì œ", "ì–´ë ¤ì›€", "ê³ ë¯¼", "ê±±ì •", "í•´ê²°",  # ë¬¸ì œ/í•´ê²°
        "ì„±ê³µ", "ì‹¤íŒ¨", "ê²°ê³¼", "ì„±ê³¼", "ë°°ì›€",  # ì„±ê³¼
        "ëŠë‚Œ", "ìƒê°", "ê¸°ë¶„", "ë§Œì¡±", "ì•„ì‰¬ì›€"   # ê°ì •
    ]
    
    low_value_indicators = [
        "ê·¸ëƒ¥", "ìŒ", "ì•„", "ë„¤", "ì˜ˆ", "ì¢‹ì•„ìš”"  # ë‹¨ìˆœ ì‘ë‹µ
    ]
    
    try:
        context_lower = current_context.lower()
        
        # ì €ì¥ ê°€ì¹˜ ì ìˆ˜ ê³„ì‚°
        value_score = 0
        found_indicators = []
        
        for indicator in high_value_indicators:
            if indicator in current_context:
                value_score += 2
                found_indicators.append(indicator)
        
        for indicator in low_value_indicators:
            if indicator in context_lower:
                value_score -= 1
        
        # ë‚´ìš© ê¸¸ì´ ê³ ë ¤
        if len(current_context) > 50:
            value_score += 1
        if len(current_context) > 150:
            value_score += 1
        
        # ì œì•ˆ ìƒì„±
        if value_score >= 3:
            recommendation = "ğŸ”¥ ë†’ìŒ - ì¦‰ì‹œ ì €ì¥ ê°•ë ¥ ê¶Œì¥"
            action = "add_memory_frequent ë„êµ¬ë¡œ ì§€ê¸ˆ ë°”ë¡œ ì €ì¥í•˜ì„¸ìš”!"
        elif value_score >= 1:
            recommendation = "âš¡ ì¤‘ê°„ - ì €ì¥ ê¶Œì¥"
            action = "ì¤‘ìš”í•œ ë¶€ë¶„ì„ ê³¨ë¼ì„œ add_memory_frequentë¡œ ì €ì¥í•´ë³´ì„¸ìš”."
        else:
            recommendation = "ğŸ’¡ ë‚®ìŒ - ì„ íƒì  ì €ì¥"
            action = "í•µì‹¬ í¬ì¸íŠ¸ê°€ ìˆë‹¤ë©´ ê°„ë‹¨íˆ ì €ì¥í•˜ì„¸ìš”."
        
        return json.dumps({
            "status": "analyzed",
            "ì €ì¥_ê°€ì¹˜_í‰ê°€": recommendation,
            "ì ìˆ˜": value_score,
            "ë°œê²¬ëœ_ì €ì¥_í¬ì¸íŠ¸": found_indicators,
            "ê¶Œì¥_ì•¡ì…˜": action,
            "ë¶„ì„_ê²°ê³¼": {
                "ë‚´ìš©_ê¸¸ì´": len(current_context),
                "ê³ ê°€ì¹˜_ì§€í‘œ": len([i for i in high_value_indicators if i in current_context]),
                "ì €ê°€ì¹˜_ì§€í‘œ": len([i for i in low_value_indicators if i in context_lower])
            },
            "ë‹¤ìŒ_ë‹¨ê³„": "ì´ ë¶„ì„ì„ ì°¸ê³ í•´ì„œ add_memory_frequent ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë¥¼ ê²°ì •í•˜ì„¸ìš”!"
        }, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({"error": f"ì €ì¥ ê¸°íšŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}, ensure_ascii=False)


async def migrate_database_schema(
    target_version: str = "2.4.0", 
    dry_run: bool = True, 
    backup_first: bool = True
) -> str:
    """
    Migrate database schema to support new features while maintaining backward compatibility
    
    This tool safely updates database structure for new Greeum versions. Always performs backup 
    by default and supports dry-run testing. Critical for maintaining data integrity during upgrades.
    
    Args:
        target_version: Target schema version (default: "2.4.0")
        dry_run: Test migration without applying changes (default: True)
        backup_first: Create database backup before migration (default: True)
    
    Returns:
        Migration status and summary of changes
    """
    try:
        from greeum import DatabaseManager
        from greeum.core.block_manager import BlockManager
        import os
        import shutil
        import sqlite3
        from datetime import datetime
        
        db_manager = DatabaseManager()
        
        # Get current schema version
        try:
            current_version = "2.3.0"  # Default for compatibility
            # Try to detect actual version from database metadata if available
        except:
            current_version = "unknown"
        
        migration_log = []
        migration_log.append(f"ğŸ” Current schema version: {current_version}")
        migration_log.append(f"ğŸ¯ Target schema version: {target_version}")
        
        if current_version == target_version:
            return "âœ… Database schema is already at target version. No migration needed."
        
        # Create backup if requested
        if backup_first and not dry_run:
            try:
                db_path = db_manager.db_path or "/Users/dryrain/greeum-global/greeum_memory.db"
                if os.path.exists(db_path):
                    backup_path = f"{db_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    shutil.copy2(db_path, backup_path)
                    migration_log.append(f"ğŸ“¦ Backup created: {backup_path}")
                else:
                    migration_log.append(f"âš ï¸ Database file not found: {db_path}")
            except Exception as e:
                migration_log.append(f"âŒ Backup failed: {str(e)}")
                if not dry_run:
                    return "\n".join(migration_log) + "\n\nâŒ Migration aborted due to backup failure."
        
        # Schema changes for v2.4.0
        schema_changes = [
            {
                "description": "Add actant_structure column to blocks table",
                "sql": "ALTER TABLE blocks ADD COLUMN actant_structure TEXT DEFAULT '{}'",
                "check_sql": "SELECT sql FROM sqlite_master WHERE type='table' AND name='blocks'"
            },
            {
                "description": "Add structured_metadata column to blocks table", 
                "sql": "ALTER TABLE blocks ADD COLUMN structured_metadata TEXT DEFAULT '{}'",
                "check_sql": "SELECT sql FROM sqlite_master WHERE type='table' AND name='blocks'"
            },
            {
                "description": "Create schema_version table for version tracking",
                "sql": "CREATE TABLE IF NOT EXISTS schema_version (version TEXT PRIMARY KEY, applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)",
                "check_sql": "SELECT name FROM sqlite_master WHERE type='table' AND name='schema_version'"
            }
        ]
        
        # Apply or test schema changes
        if dry_run:
            migration_log.append("\nğŸ§ª DRY RUN MODE - Testing schema changes:")
            for change in schema_changes:
                try:
                    # Test if change is needed by checking current schema
                    conn = sqlite3.connect(db_manager.db_path or ":memory:")
                    cursor = conn.cursor()
                    
                    if "ALTER TABLE" in change["sql"]:
                        # Check if column already exists
                        cursor.execute(change["check_sql"])
                        schema_info = cursor.fetchone()
                        if schema_info and ("actant_structure" in schema_info[0] or "structured_metadata" in schema_info[0]):
                            migration_log.append(f"  âœ… {change['description']} - Already exists")
                        else:
                            migration_log.append(f"  ğŸ“ {change['description']} - Would be added")
                    else:
                        # Check if table exists
                        cursor.execute(change["check_sql"])
                        if cursor.fetchone():
                            migration_log.append(f"  âœ… {change['description']} - Already exists")
                        else:
                            migration_log.append(f"  ğŸ“ {change['description']} - Would be created")
                    
                    conn.close()
                except Exception as e:
                    migration_log.append(f"  âš ï¸ {change['description']} - Test failed: {str(e)}")
            
            migration_log.append("\nâœ… Dry run completed successfully. Use dry_run=False to apply changes.")
        else:
            migration_log.append("\nğŸ”§ Applying schema changes:")
            try:
                conn = sqlite3.connect(db_manager.db_path)
                cursor = conn.cursor()
                
                for change in schema_changes:
                    try:
                        cursor.execute(change["sql"])
                        migration_log.append(f"  âœ… {change['description']} - Applied")
                    except sqlite3.OperationalError as e:
                        if "duplicate column" in str(e).lower() or "already exists" in str(e).lower():
                            migration_log.append(f"  âœ… {change['description']} - Already exists")
                        else:
                            migration_log.append(f"  âŒ {change['description']} - Failed: {str(e)}")
                            raise
                
                # Update schema version
                cursor.execute("INSERT OR REPLACE INTO schema_version (version) VALUES (?)", (target_version,))
                conn.commit()
                conn.close()
                
                migration_log.append(f"\nğŸ‰ Migration to {target_version} completed successfully!")
            except Exception as e:
                migration_log.append(f"\nâŒ Migration failed: {str(e)}")
                return "\n".join(migration_log)
        
        return "\n".join(migration_log)
        
    except Exception as e:
        return f"âŒ Database migration failed: {str(e)}. Please check database connectivity and permissions."


# ì „ì—­ ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ (enhanced_memory_toolsì™€ ê³µìœ )
enhanced_memory_tools: Optional[Any] = None


def initialize_micro_encouraged_tools(enhanced_tools_instance):
    """ë§ˆì´í¬ë¡œ ê¸°ì–µ ìœ ë„ ë„êµ¬ ì´ˆê¸°í™”"""
    global enhanced_memory_tools
    enhanced_memory_tools = enhanced_tools_instance
    return enhanced_memory_tools


# MCP ì„œë²„ ë„êµ¬ ëª©ë¡ (description ìµœì í™” ë²„ì „)
MCP_TOOLS_WITH_ENCOURAGEMENT = [
    {
        "name": "add_memory_frequent",
        "description": "Immediate memory storage with Greimas actant model: Record all interactions using [Subject-Action-Object] structure. Every work unit has permanent value. Target: 20-30 blocks per session.",
        "function": add_memory_frequent
    },
    {
        "name": "add_structured_memory",
        "description": "Advanced structured memory storage with AI-driven actant analysis: Store memories with explicit actant structure",
        "function": add_structured_memory
    },
    {
        "name": "migrate_database_schema",
        "description": "Migrate database schema to support new features while maintaining backward compatibility",
        "function": migrate_database_schema
    },
    {
        "name": "search_memory_contextual", 
        "description": "Contextual memory search: Find related memories to enrich conversations. Search by keywords, emotions, or situations. Frequent searches improve contextual accuracy.",
        "function": search_memory_contextual
    },
    {
        "name": "check_memory_freshness",
        "description": "Memory freshness check: Review recent memory status and encourage frequent storage. Essential check at conversation start or when addressing important topics.",
        "function": check_memory_freshness
    },
    {
        "name": "suggest_memory_opportunities",
        "description": "Memory opportunity detection: AI actively identifies storage opportunities that might be missed in current conversation. Use actively for complex information or important decisions.",
        "function": suggest_memory_opportunities
    }
]