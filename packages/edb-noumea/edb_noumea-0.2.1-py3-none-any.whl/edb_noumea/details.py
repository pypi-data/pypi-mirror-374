
import pandas as pd
import tabula
import requests
import io
from bs4 import BeautifulSoup

# URL de la page officielle contenant le lien vers le PDF
PAGE_URL = "https://www.noumea.nc/noumea-pratique/salubrite-publique/qualite-eaux-baignade"


def get_latest_pdf_url():
    """
    R√©cup√®re dynamiquement l'URL du dernier PDF d'analyses d√©taill√©es depuis la page officielle.
    """
    print(f"üîó Recherche du lien PDF sur {PAGE_URL} ...")
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
    try:
        resp = requests.get(PAGE_URL, headers=headers)
        resp.raise_for_status()
    except Exception as e:
        print(f"‚ùå Impossible de r√©cup√©rer la page officielle : {e}")
        return None
    soup = BeautifulSoup(resp.text, "lxml")
    # Chercher le premier lien PDF dans la page
    link = soup.find("a", href=lambda h: h and h.endswith(".pdf"))
    if not link:
        print("‚ùå Aucun lien PDF trouv√© sur la page.")
        return None
    pdf_url = link["href"]
    # Si le lien est relatif, le rendre absolu
    if pdf_url.startswith("/"):
        pdf_url = "https://www.noumea.nc" + pdf_url
    print(f"‚úÖ Lien PDF trouv√© : {pdf_url}")
    return pdf_url

def get_detailed_results():
    """
    T√©l√©charge dynamiquement le PDF des r√©sultats d√©taill√©s, en extrait le premier tableau
    et le retourne sous forme de DataFrame pandas.
    """
    pdf_url = get_latest_pdf_url()
    if not pdf_url:
        return None
    print(f"üì• T√©l√©chargement du PDF depuis {pdf_url} ...")
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
        response = requests.get(pdf_url, headers=headers)
        response.raise_for_status()
        print("‚úÖ T√©l√©chargement termin√©.")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erreur lors du t√©l√©chargement du fichier PDF : {e}")
        return None

    pdf_file = io.BytesIO(response.content)

    try:
        print("üîç Extraction des tableaux du PDF...")
        tables = tabula.read_pdf(pdf_file, pages='1', stream=True)
    except Exception as e:
        print(f"‚ùå Une erreur est survenue lors de l'extraction des donn√©es du PDF.")
        print("‚ÑπÔ∏è  Cela peut √™tre d√ª √† l'absence de Java sur votre syst√®me, qui est requis par la biblioth√®que 'tabula-py'.")
        print(f"   Erreur originale : {e}")
        return None

    if not tables:
        print("‚ùå Aucun tableau n'a √©t√© trouv√© dans le PDF.")
        return None

    print(f"‚úÖ {len(tables)} tableau(x) trouv√©(s). Affichage du premier.")
    df = tables[0]

    # --- Nettoyage du DataFrame ---
    columns_to_keep = {
        df.columns[0]: "site",
        df.columns[1]: "point_de_prelevement",
        df.columns[2]: "date",
        df.columns[4]: "heure",
        df.columns[6]: "e_coli_npp_100ml",
        df.columns[9]: "enterocoques_npp_100ml"
    }
    cleaned_df = df[columns_to_keep.keys()].copy()
    cleaned_df.rename(columns=columns_to_keep, inplace=True)
    cleaned_df.replace({'<10': 0}, inplace=True)
    cleaned_df['e_coli_npp_100ml'] = pd.to_numeric(cleaned_df['e_coli_npp_100ml'], errors='coerce')
    cleaned_df['enterocoques_npp_100ml'] = pd.to_numeric(cleaned_df['enterocoques_npp_100ml'], errors='coerce')
    cleaned_df.fillna(0, inplace=True)
    return cleaned_df

if __name__ == "__main__":
    # Obtenir le DataFrame des r√©sultats d√©taill√©s
    detailed_df = get_detailed_results()

    # Afficher le DataFrame s'il a √©t√© cr√©√© avec succ√®s
    if detailed_df is not None:
        print("\nüìã Voici les d√©tails des derniers relev√©s :")
        print(detailed_df.to_string())
